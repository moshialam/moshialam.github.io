[
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation",
    "title": "Panel Data and Fixed Effects",
    "section": "Motivation",
    "text": "Motivation\n\nSo far we have dealt with a single cross-sectional dataset\nThe biggest challenge to causal inference is selection bias because we do not observe the counterfactual\nWe have learned how IVs can help us solve the endogeneity problem\nBut IVs are not always easy to find ‚Äî especially good ones\nOften, data over multiple time periods can reveal interesting patterns and provide additional variation to consistently estimate parameters of interest\n‚Ä¶ especially if the unobservables that make our estimates inconsistent do not change over time"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation-continued",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation-continued",
    "title": "Panel Data and Fixed Effects",
    "section": "Motivation (continued)",
    "text": "Motivation (continued)\nPanel data are additionally important because:\n\nThey are required to understand policy impacts\nThey allow us to study how causal impacts evolve over time\nMany policies are staggered in implementation, necessitating panel data\n\nWill discuss this more details in a couple of classes when we get into Difference-in-Differences\n\nEven when the question of interest is not a policy evaluation, observing the same units over time can be very informative"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#types-of-data-over-time",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#types-of-data-over-time",
    "title": "Panel Data and Fixed Effects",
    "section": "Types of Data Over Time",
    "text": "Types of Data Over Time\n\n\nPanel data\n\nBalanced panel: every unit observed in all time periods\n\nUnbalanced panel: some units missing in certain time periods (attrition)\n\nPSID ‚Äì Panel Study of Income Dynamics\n\nNLSY ‚Äì National Longitudinal Survey of Youth\n\nMost administrative datasets (e.g., tax records) are panel\n\n\nRepeated cross-sections\n\nDifferent units observed in each time period\n\nCPS ‚Äì Current Population Survey\n\nNHIS ‚Äì National Health Interview Survey\n\nTime series"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#panel-data-fixed-effects",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#panel-data-fixed-effects",
    "title": "Panel Data and Fixed Effects",
    "section": "Panel Data & Fixed Effects",
    "text": "Panel Data & Fixed Effects\n\nCredits: Bunch of materials drawn from Florian Oswald; Nick C. Huntington-Klein"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#cross-section-vs-panel",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#cross-section-vs-panel",
    "title": "Panel Data and Fixed Effects",
    "section": "Cross-section vs Panel",
    "text": "Cross-section vs Panel\n\nCross-section: one time snapshot per unit \\(i\\): \\(\\hat{\\beta_{OLS}} = \\frac{\\sum_i (x_i - \\bar x)(y_i - \\bar y)}{\\sum_i (x_i - \\bar x)^2}\\)\nPanel: multiple time periods \\(t\\) per unit \\(\\color{blue}{i}\\): \\(\\hat{\\beta_{FE}} = \\frac{\\sum_{\\color{blue}{i}} \\sum_{\\color{red}{t}} \\left(x_{\\color{blue}{i}\\color{red}{t}} - \\bar x_{\\color{blue}{i}}\\right)\\left(y_{\\color{blue}{i}\\color{red}{t}} - \\bar y_{\\color{blue}{i}}\\right)}{\\sum_{\\color{blue}{i}} \\sum_{\\color{red}{t}} \\left(x_{\\color{blue}{i}\\color{red}{t}} - \\bar x_{\\color{blue}{i}}\\right)^2}\\)\nPanel: index \\((i,t)\\); track units over time\nBenefit: control unobserved time-invariant heterogeneity \\(c_i\\)\nDeterrence question: does higher arrest probability reduce crime?\n\n\ndata(crime4)\ncrime4 %&gt;% select(county, year, crmrte, prbarr) %&gt;% arrange(county, year) %&gt;% head()\n\n  county year    crmrte   prbarr\n1      1   81 0.0398849 0.289696\n2      1   82 0.0383449 0.338111\n3      1   83 0.0303048 0.330449\n4      1   84 0.0347259 0.362525\n5      1   85 0.0365730 0.325395\n6      1   86 0.0347524 0.326062"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#raw-pattern",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#raw-pattern",
    "title": "Panel Data and Fixed Effects",
    "section": "Raw pattern",
    "text": "Raw pattern\n\n\n\ncss = crime4 %&gt;% \n  filter(county %in% c(1,3,145, 23))  # subset to 4 counties\n\nggplot(css,aes(x =  prbarr, y = crmrte)) + \n  geom_point() + \n  theme_bw() +\n  labs(x = 'Probability of Arrest', y = 'Crime Rate')"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#pooled-ols",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#pooled-ols",
    "title": "Panel Data and Fixed Effects",
    "section": "Pooled OLS",
    "text": "Pooled OLS\n\nsummary(lm(crmrte ~ prbarr, data = css))$coef[\"prbarr\",]\n\n    Estimate   Std. Error      t value     Pr(&gt;|t|) \n0.0648010359 0.0159005783 4.0753886238 0.0003839695 \n\n\n\n\n\ncss = crime4 %&gt;% \n  filter(county %in% c(1,3,145, 23))  # subset to 4 counties\n\nggplot(css,aes(x =  prbarr, y = crmrte)) + \n  geom_point() + \n  geom_smooth(method=\"lm\",se=FALSE) + \n  theme_bw() +\n  labs(x = 'Probability of Arrest', y = 'Crime Rate')"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#naive-interpreting-the-cross-section",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#naive-interpreting-the-cross-section",
    "title": "Panel Data and Fixed Effects",
    "section": "Naive Interpreting the Cross-Section",
    "text": "Naive Interpreting the Cross-Section\n\nLiterally: counties with a higher probability of arrest also have a higher crime rate.\n\nDoes this imply that more crime leads to more efficient policing?\n\nOr that higher police presence deters crime ‚Äî but only once it gets bad enough?\n\nWhat determines police efficiency?\n\nCould depend on poverty, local laws, political commitment, or other local factors.\n\n\nü§Ø There are clearly many omitted factors in this simple model ‚Äî we cannot tell whether the estimated relationship makes sense causally."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#what-varies-between-and-within-counties",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#what-varies-between-and-within-counties",
    "title": "Panel Data and Fixed Effects",
    "section": "What Varies Between and Within Counties",
    "text": "What Varies Between and Within Counties\n\nLocalStuff ‚Äî fixed county characteristics (e.g., geography, institutions).\n\nLawAndOrder and CivilRights ‚Äî political and institutional traits that may change slowly, but are mostly fixed over short horizons.\n\nPolice budgets and Poverty levels ‚Äî vary within counties over time, reflecting local and macroeconomic fluctuations (national)\nCan panel data allows us to separate time-invariant county traits from time-varying factors ‚Äî helping us get closer to a causal interpretation?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-patterns",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-patterns",
    "title": "Panel Data and Fixed Effects",
    "section": "Within county patterns",
    "text": "Within county patterns\n\ncss = crime4 %&gt;% \n  filter(county %in% c(1,3,145, 23))  # subset to 4 counties\n\nggplot(css, aes(x = prbarr, y = crmrte, color = factor(county))) + \n    geom_point() + \n    #geom_smooth(method = \"lm\", se = FALSE) + \n    theme_bw() +\n    labs(x = 'Probability of Arrest', y = 'Crime Rate', color = 'County')"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-patterns-1",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-patterns-1",
    "title": "Panel Data and Fixed Effects",
    "section": "Within county patterns",
    "text": "Within county patterns\n\ncss = crime4 %&gt;% \n  filter(county %in% c(1,3,145, 23))  # subset to 4 counties\n\nggplot(css, aes(x = prbarr, y = crmrte, color = factor(county))) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    theme_bw() +\n    labs(x = 'Probability of Arrest', y = 'Crime Rate', color = 'County')"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-means",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#within-county-means",
    "title": "Panel Data and Fixed Effects",
    "section": "Within county means",
    "text": "Within county means"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#panel-model-with-unit-fe",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#panel-model-with-unit-fe",
    "title": "Panel Data and Fixed Effects",
    "section": "Panel Model with Unit FE",
    "text": "Panel Model with Unit FE\n\\[\n  y_{it} = \\beta x_{it} + \\underbrace{c_i + u_{it}}_{\\text{error}}\n  \\] - \\(c_i\\) may correlate with \\(x_{it}\\) ‚Üí OLS biased \\(E(c_i + u_{it} \\mid x_{it}) \\neq 0\\) - Simple OLS mixes within + between; biased if \\(Cov(x_{it}, c_i) \\neq 0\\). - Between: differences across \\(i\\) (time-invariant) ‚Üí drives pooled OLS bias\n- Within: changes over \\(t\\) within \\(i\\) ‚Üí identifies \\(\\beta\\) under FE assumptions\n\ncss &lt;- crime4 %&gt;% filter(county %in% c(1,3,23,145))\nm_cs &lt;- lm(crmrte ~ prbarr, data = css)\ncoef(m_cs)[\"prbarr\"]\n\n    prbarr \n0.06480104 \n\n\n\nFE approach: control for \\(c_i\\) by allowing unit-specific intercepts or FIXED EFFECTS"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fe-assumptions-succinct",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fe-assumptions-succinct",
    "title": "Panel Data and Fixed Effects",
    "section": "FE Assumptions (succinct)",
    "text": "FE Assumptions (succinct)\n\\[\n  y_{it} = \\beta x_{it} + \\underbrace{c_i + u_{it}}_{\\text{error}}\n  \\]\n\nStrict exogeneity: \\(E[u_{it} \\mid x_{i1},‚Ä¶,x_{iT},c_i] = 0\\)\nNo perfect collinearity: time-invariant regressors drop in FE\nErrors: correlation within \\(i\\) ‚Üí cluster by \\(i\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#three-estimators-same-hatbeta",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#three-estimators-same-hatbeta",
    "title": "Panel Data and Fixed Effects",
    "section": "Three Estimators (same \\(\\hat\\beta\\))",
    "text": "Three Estimators (same \\(\\hat\\beta\\))\n\nLSDV (dummies): \\[\ny_{it} = \\beta x_{it} + \\sum_{i=1}^{N-1} \\gamma_i 1\\{i\\} + u_{it}\n\\]\nFirst-difference (FD), \\(T=2\\): \\[\n\\Delta y_i = \\beta \\Delta x_i + \\Delta u_i\n\\]\nWithin (demeaning), \\(T\\ge2\\): \\[\ny_{it} - \\bar y_i = \\beta (x_{it} - \\bar x_i) + (u_{it} - \\bar u_i)\n\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#lsdv-dummy-variable-ols",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#lsdv-dummy-variable-ols",
    "title": "Panel Data and Fixed Effects",
    "section": "LSDV (Dummy-Variable OLS)",
    "text": "LSDV (Dummy-Variable OLS)\n\nm_lsdv &lt;- lm(crmrte ~ prbarr + factor(county), data = css)\nsummary(m_lsdv) \n\n\nCall:\nlm(formula = crmrte ~ prbarr + factor(county), data = css)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0052637 -0.0014554  0.0000986  0.0009928  0.0083848 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.044945   0.004556   9.866 9.85e-10 ***\nprbarr            -0.028376   0.013629  -2.082  0.04865 *  \nfactor(county)3   -0.024996   0.002544  -9.824 1.07e-09 ***\nfactor(county)23  -0.008498   0.001658  -5.126 3.41e-05 ***\nfactor(county)145 -0.006500   0.001596  -4.072  0.00047 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.002912 on 23 degrees of freedom\nMultiple R-squared:  0.8926,    Adjusted R-squared:  0.8739 \nF-statistic: 47.78 on 4 and 23 DF,  p-value: 8.115e-11\n\n\n\nAdds intercept for every county ‚Üí recovers within county slope."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#section",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#section",
    "title": "Panel Data and Fixed Effects",
    "section": "",
    "text": "library(modelsummary)\ncdata &lt;- css %&gt;%\n  group_by(county) %&gt;%\n  mutate(mean_crime = mean(crmrte),\n         mean_prob = mean(prbarr)) %&gt;%\n  mutate(demeaned_crime = crmrte - mean_crime,\n         demeaned_prob = prbarr - mean_prob)\nmod = list()\nmod$dummy &lt;- lm(crmrte ~ prbarr + factor(county), css)  # i is the unit ID\nmod$xsect &lt;- lm(crmrte ~ prbarr, data = cdata)\nmod$demeaned &lt;- lm(demeaned_crime ~ demeaned_prob, data = cdata)\ngom = 'DF|Deviance|AIC|BIC|p.value|se_type|R2 Adj. |statistic|Log.Lik.|Num.Obs.'  # stuff to omit from table\nmodelsummary::modelsummary(mod[c(\"xsect\",\"dummy\",\"demeaned\")],\n                           statistic = 'std.error',\n                           title = \"Comparing (biased) cross-setcional OLS, dummy variable and manual demeaning panel regressions\",\n                           coef_omit = \"factor\",\n                           gof_omit = gom)\n\n\n\n    \n\n    \n    \n      \n        \n        Comparing (biased) cross-setcional OLS, dummy variable and manual demeaning panel regressions\n              \n                 \n                xsect\n                dummy\n                demeaned\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.009\n                  0.045\n                  0.000\n                \n                \n                  \n                  (0.005)\n                  (0.005)\n                  (0.001)\n                \n                \n                  prbarr\n                  0.065\n                  -0.028\n                  \n                \n                \n                  \n                  (0.016)\n                  (0.014)\n                  \n                \n                \n                  demeaned_prob\n                  \n                  \n                  -0.028\n                \n                \n                  \n                  \n                  \n                  (0.013)\n                \n                \n                  R2\n                  0.390\n                  0.893\n                  0.159\n                \n                \n                  R2 Adj.\n                  0.366\n                  0.874\n                  0.126\n                \n                \n                  F\n                  16.609\n                  47.777\n                  4.900\n                \n                \n                  RMSE\n                  0.01\n                  0.00\n                  0.00"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#manual-within-transformation",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#manual-within-transformation",
    "title": "Panel Data and Fixed Effects",
    "section": "Manual Within Transformation",
    "text": "Manual Within Transformation\n\ncdata &lt;- css %&gt;%\n  mutate(y = crmrte, x = prbarr) %&gt;%\n  group_by(county) %&gt;%\n  mutate(y_dm = y - mean(y), x_dm = x - mean(x)) %&gt;%\n  ungroup()\n\nm_within_manual &lt;- lm(y_dm ~ x_dm, data = cdata)\nsummary(m_within_manual) \n\n\nCall:\nlm(formula = y_dm ~ x_dm, data = cdata)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0052637 -0.0014554  0.0000986  0.0009928  0.0083848 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  1.190e-18  5.175e-04   0.000   1.0000  \nx_dm        -2.838e-02  1.282e-02  -2.214   0.0358 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.002739 on 26 degrees of freedom\nMultiple R-squared:  0.1586,    Adjusted R-squared:  0.1262 \nF-statistic:   4.9 on 1 and 26 DF,  p-value: 0.03583\n\n\n\nSame slope as LSDV\nIntercept is 0 by construction."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#first-differencing",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#first-differencing",
    "title": "Panel Data and Fixed Effects",
    "section": "First-Differencing",
    "text": "First-Differencing\n\ndt &lt;- as.data.table(css)[order(county, year)]\ndt[, y := crmrte]; dt[, x := prbarr]\ndt[, `:=`(dy = y - shift(y), dx = x - shift(x)), by = county]\nm_fd &lt;- lm(dy ~ dx, data = dt[!is.na(dy)])\nsummary(m_fd) \n\n\nCall:\nlm(formula = dy ~ dx, data = dt[!is.na(dy)])\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0089587 -0.0015629 -0.0002049  0.0019199  0.0103419 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -0.0002985  0.0008554  -0.349    0.730\ndx          -0.0096765  0.0196879  -0.491    0.628\n\nResidual standard error: 0.00413 on 22 degrees of freedom\nMultiple R-squared:  0.01086,   Adjusted R-squared:  -0.0341 \nF-statistic: 0.2416 on 1 and 22 DF,  p-value: 0.6279\n\n\n\nWith \\(T=2\\), FD \\(\\equiv\\) FE.\nFor \\(T&gt;2\\), FE typically more efficient if errors are not well-behaved in differences.\nLet‚Äôs use a package which can worry for us about efficiency and clustering fixest."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fixestfeols-recommended",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fixestfeols-recommended",
    "title": "Panel Data and Fixed Effects",
    "section": "fixest::feols (recommended)",
    "text": "fixest::feols (recommended)\n\nm_fe_1w &lt;- feols(crmrte ~ prbarr | county, data = css, cluster = ~ county)\n\nmodelsummary::modelsummary(\n  list(\"Pooled (lm)\" = m_cs,\n       \"LSDV (lm)\" = m_lsdv,\n       \"Within (manual lm)\" = m_within_manual,\n       \"FE (fixest)\" = m_fe_1w)\n)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Pooled (lm)\n                LSDV (lm)\n                Within (manual lm)\n                FE (fixest)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.009\n                  0.045\n                  0.000\n                  \n                \n                \n                  \n                  (0.005)\n                  (0.005)\n                  (0.001)\n                  \n                \n                \n                  prbarr\n                  0.065\n                  -0.028\n                  \n                  -0.028\n                \n                \n                  \n                  (0.016)\n                  (0.014)\n                  \n                  (0.005)\n                \n                \n                  factor(county)3\n                  \n                  -0.025\n                  \n                  \n                \n                \n                  \n                  \n                  (0.003)\n                  \n                  \n                \n                \n                  factor(county)23\n                  \n                  -0.008\n                  \n                  \n                \n                \n                  \n                  \n                  (0.002)\n                  \n                  \n                \n                \n                  factor(county)145\n                  \n                  -0.007\n                  \n                  \n                \n                \n                  \n                  \n                  (0.002)\n                  \n                  \n                \n                \n                  x_dm\n                  \n                  \n                  -0.028\n                  \n                \n                \n                  \n                  \n                  \n                  (0.013)\n                  \n                \n                \n                  Num.Obs.\n                  28\n                  28\n                  28\n                  28\n                \n                \n                  R2\n                  0.390\n                  0.893\n                  0.159\n                  0.893\n                \n                \n                  R2 Adj.\n                  0.366\n                  0.874\n                  0.126\n                  0.874\n                \n                \n                  R2 Within\n                  \n                  \n                  \n                  0.159\n                \n                \n                  R2 Within Adj.\n                  \n                  \n                  \n                  0.122\n                \n                \n                  AIC\n                  -198.4\n                  -241.0\n                  -247.0\n                  -243.0\n                \n                \n                  BIC\n                  -194.4\n                  -233.0\n                  -243.0\n                  -236.4\n                \n                \n                  Log.Lik.\n                  102.197\n                  126.516\n                  126.516\n                  \n                \n                \n                  F\n                  16.609\n                  47.777\n                  4.900\n                  \n                \n                \n                  RMSE\n                  0.01\n                  0.00\n                  0.00\n                  0.00\n                \n                \n                  Std.Errors\n                  \n                  \n                  \n                  by: county\n                \n                \n                  FE: county\n                  \n                  \n                  \n                  X\n                \n        \n      \n    \n\n\n\n\nSyntax: y ~ x | FE1 + FE2 + ...\nCluster by the unit for valid SEs with serial correlation."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#interpretation-within-effect",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#interpretation-within-effect",
    "title": "Panel Data and Fixed Effects",
    "section": "Interpretation (within effect)",
    "text": "Interpretation (within effect)\n\n\\(\\hat\\beta_{\\text{FE}}\\): effect of a within-county change in \\(prbarr\\) on \\(crmrte\\), holding time-invariant county traits fixed.\nA change \\(\\Delta prbarr = 0.10\\) implies \\(\\Delta crmrte \\approx 0.10 \\times \\hat\\beta_{\\text{FE}}\\) (within a county over time)."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#so-we-started-from-here-with-pols",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#so-we-started-from-here-with-pols",
    "title": "Panel Data and Fixed Effects",
    "section": "So we started from here with POLS",
    "text": "So we started from here with POLS\nPooled OLS: Mixing Within and Between Variation"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fe-within-transformation",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#fe-within-transformation",
    "title": "Panel Data and Fixed Effects",
    "section": "FE: Within Transformation",
    "text": "FE: Within Transformation\nmultiple time periods \\(t\\) per unit \\(\\color{blue}{i}\\): \\(\\hat{\\beta_{FE}} = \\frac{\\sum_{\\color{blue}{i}} \\sum_{\\color{red}{t}} \\left(x_{\\color{blue}{i}\\color{red}{t}} - \\bar x_{\\color{blue}{i}}\\right)\\left(y_{\\color{blue}{i}\\color{red}{t}} - \\bar y_{\\color{blue}{i}}\\right)}{\\sum_{\\color{blue}{i}} \\sum_{\\color{red}{t}} \\left(x_{\\color{blue}{i}\\color{red}{t}} - \\bar x_{\\color{blue}{i}}\\right)^2}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe within transformation centers the data!\nBy time-demeaning \\(y\\) and \\(x\\), we project out the fixed factors related to county\nOnly within county variation is left.\nMade by Nick C Huntington-Klein. üôè"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#time-invariant-regressors",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#time-invariant-regressors",
    "title": "Panel Data and Fixed Effects",
    "section": "Time-Invariant Regressors",
    "text": "Time-Invariant Regressors\n\n\nVariables constant within \\(i\\) (e.g., geography) are absorbed and not identified in FE.\n\nAbsorbed by \\(c_i\\).\n\nFor example if you have tax panel data of individuals over time and you add an individual fixed effect, what are examples of variables that you cannot estimate the effect of?\nOptions (if you need to udnerstand the efffect of some variable):\n\ninteract with time"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation-1",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#motivation-1",
    "title": "Panel Data and Fixed Effects",
    "section": "Motivation",
    "text": "Motivation\n\n\nOften, we want to control for common shocks that affect all units in a given time period\n\ne.g., national business cycles, federal policy changes, macroeconomic shocks\n\nWe can add time fixed effects \\(\\tau_t\\) to control for these common shocks\nThis leads to the Two-Way Fixed Effects (TWFE) model\n\n\\[\ny_{it} = \\beta x_{it} + c_i + \\tau_t + u_{it}\n\\]\nUnit fixed effects \\(c_i\\) control for time-invariant heterogeneity across units \\(i\\)\nTime fixed effects \\(\\tau_t\\) control for common shocks to all units across time periods \\(t\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#two-way-fixed-effects-twfe",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#two-way-fixed-effects-twfe",
    "title": "Panel Data and Fixed Effects",
    "section": "Two-Way Fixed Effects (TWFE)",
    "text": "Two-Way Fixed Effects (TWFE)\n\nAdd common shocks \\(\\tau_t\\): \\[\ny_{it} = \\beta x_{it} + c_i + \\tau_t + u_{it}\n\\]\n\n\nm_twoway &lt;- feols(crmrte ~ prbarr | county + year, data = crime4, cluster = ~ county)\netable(m_fe_1w, m_twoway, se = \"cluster\")\n\n                          m_fe_1w         m_twoway\nDependent Var.:            crmrte           crmrte\n                                                  \nprbarr          -0.0284* (0.0052) -0.0011 (0.0026)\nFixed-Effects:  ----------------- ----------------\ncounty                        Yes              Yes\nyear                           No              Yes\n_______________ _________________ ________________\nS.E.: Clustered        by: county       by: county\nObservations                   28              630\nR2                        0.89258          0.87735\nWithin R2                 0.15859          0.00034\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterprets \\(\\beta\\) net of unit and time effects.\nIN the next two weeks, we will see how this is a foundational model for policy evaluation"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#comparing-pols-fe-twfe",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#comparing-pols-fe-twfe",
    "title": "Panel Data and Fixed Effects",
    "section": "Comparing POLS, FE, TWFE",
    "text": "Comparing POLS, FE, TWFE\n\nm_pooled &lt;- lm(crmrte ~ prbarr, data = crime4)\nm_fe   &lt;- feols(crmrte ~ prbarr | county, data = crime4)\nm_twfe &lt;- feols(crmrte ~ prbarr | county + year, data = crime4, cluster = ~ county)\n\nmodelsummary::modelsummary(list(\n  \"Pooled\"   = m_pooled,\n  \"FE\"     = m_fe,\n  \"TWFE (fixest)\"   = m_twfe\n))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Pooled\n                FE\n                TWFE (fixest)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.043\n                  \n                  \n                \n                \n                  \n                  (0.001)\n                  \n                  \n                \n                \n                  prbarr\n                  -0.038\n                  -0.002\n                  -0.001\n                \n                \n                  \n                  (0.004)\n                  (0.003)\n                  (0.003)\n                \n                \n                  Num.Obs.\n                  630\n                  630\n                  630\n                \n                \n                  R2\n                  0.129\n                  0.871\n                  0.877\n                \n                \n                  R2 Adj.\n                  0.127\n                  0.849\n                  0.855\n                \n                \n                  R2 Within\n                  \n                  0.001\n                  0.000\n                \n                \n                  R2 Within Adj.\n                  \n                  -0.001\n                  -0.002\n                \n                \n                  AIC\n                  -3347.3\n                  -4373.6\n                  -4394.6\n                \n                \n                  BIC\n                  -3334.0\n                  -3969.1\n                  -3963.4\n                \n                \n                  Log.Lik.\n                  1676.651\n                  \n                  \n                \n                \n                  F\n                  92.646\n                  \n                  \n                \n                \n                  RMSE\n                  0.02\n                  0.01\n                  0.01\n                \n                \n                  Std.Errors\n                  \n                  by: county\n                  by: county\n                \n                \n                  FE: county\n                  \n                  X\n                  X\n                \n                \n                  FE: year\n                  \n                  \n                  X"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/10_panelFE.html#references-credits",
    "href": "teachingmaterials/UG_intro_metrics/10_panelFE.html#references-credits",
    "title": "Panel Data and Fixed Effects",
    "section": "References & Credits",
    "text": "References & Credits\n\nSome slides/materials adapted from Florian Oswald, Nick C. Huntington-Klein"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html",
    "title": "Econometrics PS 1 - Solutions",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-a",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-a",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Part (a)",
    "text": "Part (a)\n\npar(mfrow=c(1,2))\nplot(x, u1, main=\"u1 vs x\", pch=20, col=\"blue\")\nabline(lm(u1~x), col=\"red\", lwd=2)\nplot(x, u2, main=\"u2 vs x\", pch=20, col=\"blue\")\nabline(lm(u2~x), col=\"red\", lwd=2)\n\n\n\n\n\n\n\nIn the first population model, u_1 shows no systematic pattern with x (randomly scattered around zero). However, in the second one, u_2 exhibits a clear positive linear relationship with x, violating the zero conditional mean assumption i.e., E(u_2|x) \\neq 0."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-b",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-b",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Part (b)",
    "text": "Part (b)\nOnly the regression of y_1 on x will produce unbiased estimates.\nProof: For unbiased OLS, we need E(u|x) = 0.\n\nFor model 1: E(u_1|x) = 0 because u_1 is generated as N(0, 0.1) independent of x\n\nFor model 2: E(u_2|x) = E(x + \\text{rnorm}(0, 0.1)|x) = x \\neq 0. This is clear from the plot in part (a) where the average of u_2 increases with x.\n\nSince the zero conditional mean assumption is violated for model 2, OLS estimates will be biased."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-c",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-c",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Part (c)",
    "text": "Part (c)\n\nmodel1 &lt;- lm(y1 ~ x)\nmodel2 &lt;- lm(y2 ~ x)\n\nresults &lt;- data.frame(\n  Model = c(\"y1 ~ x\", \"y2 ~ x\"),\n  True_Beta0 = c(2, 2),\n  Beta0_hat = c(coef(model1)[1], coef(model2)[1]),\n  True_Beta1 = c(3, 3),\n  Beta1_hat = c(coef(model1)[2], coef(model2)[2])\n)\nkable(results, digits=4)\n\n\n\nModel\nTrue_Beta0\nBeta0_hat\nTrue_Beta1\nBeta1_hat\n\n\n\ny1 ~ x\n2\n1.9998\n3\n3.0019\n\n\ny2 ~ x\n2\n1.9991\n3\n4.0002\n\n\n\n\n\nModel 1 estimates are very close to true parameters (2 and 3). Model 2‚Äôs slope estimate is biased upward (~4 instead of 3) because u_2 is positively correlated with x, causing omitted variable bias.\nNot required for credit: ‚Äì&gt;"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-d",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#part-d",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Part (d)",
    "text": "Part (d)\nE(u|\\text{education}) \\neq 0 because ability is in the error term since it affects wages, and is correlated with education.\nSince ability is positively correlated with education and affects wages positively, OLS will overestimate the true return to education leading to upward bias in the estimate of Œ≤_1 because it will give you an estimate of the return to education that confounded by the effect of ability.\n\n\\text{Cov}(\\text{education}, u) &gt; 0, leading to positive bias: E(\\hat{\\beta}_1) = \\beta_1 + \\frac{\\text{Cov}(education,u)}{\\text{Var}(education)} &gt; \\beta_1"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.1",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.1",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Q 3.1",
    "text": "Q 3.1\nPart (a)\n\ndata(wage2)\nggplot(wage2, aes(x = educ, y = wage)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Wages vs Education\", x = \"Years of Education\", y = \"Monthly Wage\")\n\n\n\n\n\n\n\nPositive relationship between education and wages. Observable heteroskedasticity (variance increases with education) and potential outliers at high wage levels.\nPart (b)\n\n# Sample correlation\nrho_xy &lt;- cor(wage2$wage, wage2$educ)\n\n# Standard deviations\nsigma_y &lt;- sd(wage2$wage)\nsigma_x &lt;- sd(wage2$educ)\n\n# Manual calculation of beta1\nbeta1_manual &lt;- rho_xy * (sigma_y / sigma_x)\n\n# Using lm()\nmodel &lt;- lm(wage ~ educ, data = wage2)\nbeta1_lm &lt;- coef(model)[2]\n\n\ncat(\"Beta1 (manual): \", round(beta1_manual, 4), \"\\n\", \"Beta1 (lm): \", round(beta1_lm, 4), \"\\n\")\n\nBeta1 (manual):  60.2143 \n Beta1 (lm):  60.2143 \n\n\nPart (c)\n\nsummary(model)\n\n\nCall:\nlm(formula = wage ~ educ, data = wage2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-877.38 -268.63  -38.38  207.05 2148.26 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  146.952     77.715   1.891   0.0589 .  \neduc          60.214      5.695  10.573   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 382.3 on 933 degrees of freedom\nMultiple R-squared:  0.107, Adjusted R-squared:  0.106 \nF-statistic: 111.8 on 1 and 933 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\\hat{\\beta}_0 = 146.95 gives the average monthly wage with zero education (not meaningful in this context as no one has zero education in the sample, and otherwise we are extrapolating). But that does not mean that we should drop it from the regression. Recall that the intercept is needed to ensure that E(u) = 0 through re-normalization.\n\n\\hat{\\beta}_1 = 60.21: Each additional year of education on average is associated with $60.21 increase in average monthly wages, all else equal.\nPart (d)\n\n# Manual calculations of Fitted values\nbeta0_hat &lt;- coef(model)[1]\nbeta1_hat &lt;- coef(model)[2]\ny_hat &lt;- beta0_hat + beta1_hat * wage2$educ\n\n# Residuals\nu_hat &lt;- wage2$wage - y_hat\n\n# residual at mean_educ, mean_wage\nmean_wage &lt;- mean(wage2$wage)\nmean_educ &lt;- mean(wage2$educ)\nresid_at_mean &lt;- mean_wage - (beta0_hat + beta1_hat * mean_educ)\n\n# Verifications\ncat(\"Mean of residuals: \", round(mean(u_hat), 5), \"\\n\", \n  \"Point (mean_educ, mean_wage): (\", mean(wage2$educ), \", \", mean(wage2$wage), \")\\n\",\n  \"Residual at (mean_educ, mean_wage): \", round(resid_at_mean, 5), \"\\n\",\n  \"Covariance(educ, residuals): \", round(cov(wage2$educ, u_hat), 10), \"\\n\")\n\nMean of residuals:  0 \n Point (mean_educ, mean_wage): ( 13.46845 ,  957.9455 )\n Residual at (mean_educ, mean_wage):  0 \n Covariance(educ, residuals):  0 \n\n\nWhile other parts are obvious, Point (mean_educ, mean_wage) lies on the regression line because the residual at that point is effectively zero."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.2",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.2",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Q 3.2",
    "text": "Q 3.2\nPart (a)\n\nlog_model &lt;- lm(log(wage) ~ educ, data = wage2)\nsummary(log_model)\n\n\nCall:\nlm(formula = log(wage) ~ educ, data = wage2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.94620 -0.24832  0.03507  0.27440  1.28106 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 5.973062   0.081374   73.40   &lt;2e-16 ***\neduc        0.059839   0.005963   10.04   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4003 on 933 degrees of freedom\nMultiple R-squared:  0.09742,   Adjusted R-squared:  0.09645 \nF-statistic: 100.7 on 1 and 933 DF,  p-value: &lt; 2.2e-16\n\n\nPart (b)\nE(\\log(wage)|educ =16) - E(\\log(wage)|educ =12) = 4\\beta_1\n\nbeta1_log &lt;- coef(log_model)[2]\n\n# Exact percentage return\npct_return &lt;- (exp(beta1_log) - 1) * 100\ncat(\"Exact % return to one year of education: \", round(pct_return, 2), \"%\\n\")\n\nExact % return to one year of education:  6.17 %\n\n#  avg Wage difference between 12 and 16 years\nwage_diff &lt;-  (exp(beta1_log * 4) - 1) * 100\ncat(\"% wage difference (16 vs 12 years): \", round(wage_diff, 2), \"%\\n\")\n\n% wage difference (16 vs 12 years):  27.04 %\n\n\nPart (c)\n\npar(mfrow = c(1, 2))\nhist(wage2$wage, main = \"Distribution of Wage\", xlab = \"Wage\", breaks = 30)\nhist(log(wage2$wage), main = \"Distribution of Log(Wage)\", xlab = \"Log(Wage)\", breaks = 30)\n\n\n\n\n\n\n\nLog-level specification is preferred because level wage is right-skewed and log transformation helps in reducing the influence of outliers and for approximate interpretations percentage interpretation which is more intuitive for wage returns"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.3",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps1sol.html#q-3.3",
    "title": "Econometrics PS 1 - Solutions",
    "section": "Q 3.3",
    "text": "Q 3.3\nPart (a)\n\nplot(fitted(log_model), residuals(log_model), \n     main = \"Residual Plot for Log-Level Model\",\n     xlab = \"Fitted Values\", ylab = \"Residuals\")\n\n\n\n\n\n\n\nSome heteroskedasticity visible - residual spread appears to increase slightly with fitted values. Thus variance of residuals changes systematically with fitted values.\nPart (b)\n\nwage2$educ_group &lt;- cut(wage2$educ, \n                        breaks = c(-Inf, 12, 16, Inf),\n                        labels = c(\"Low (&lt;12)\", \"Medium (12-16)\", \"High (‚â•16)\"),\n                        right = FALSE)\n\nresid &lt;- residuals(log_model)\n\nvar_resid_group1 &lt;- var(resid[wage2$educ_group == \"Low (&lt;12)\"])\nvar_resid_group2 &lt;- var(resid[wage2$educ_group == \"Medium (12-16)\"])\nvar_resid_group3 &lt;- var(resid[wage2$educ_group == \"High (‚â•16)\"])\n\nprint(data.frame(\n  Education_Group = c(\"Low (&lt;12)\", \"Medium (12-16)\", \"High (‚â•16)\"),\n  Variance_of_Residuals = c(var_resid_group1, var_resid_group2, var_resid_group3)\n))\n\n  Education_Group Variance_of_Residuals\n1       Low (&lt;12)             0.1360187\n2  Medium (12-16)             0.1631016\n3      High (‚â•16)             0.1624964\n\n# Shorter code using `tapply`:\n# variance_by_group &lt;- tapply(resid, wage2$educ_group, var)\n# print(variance_by_group)\n\nVariances of the residuals differs across education groups, suggesting heteroskedasticity is present (though differences are moderate in the log specification).\nPart (c)\nHeteroskedasticity does not affect the unbiasedness of \\hat{\\beta}_1. The OLS estimator remains unbiased as long as E(u|x) = 0 holds.\nNot for credit\nConsequences of heteroskedasticity:\n\nOLS estimates remain unbiased and consistent as long as E(u|x) = 0 holds\nOLS is no longer BLUE (efficient)\nHomoskedastic Standard errors are typically underestimated\nCosnequently, hypothesis tests and confidence intervals are invalid"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#population-vs.-sample",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#population-vs.-sample",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Population vs.¬†Sample",
    "text": "Population vs.¬†Sample\nSimple linear regression model (SLRM): studies how \\(y\\) changes with changes in \\(x\\)\n\n\nPopulation Model: \\[y_i = Œ≤‚ÇÄ + Œ≤‚ÇÅx_i + u_i\\]\n\nŒ≤‚ÇÄ: Population intercept parameter\nŒ≤‚ÇÅ: Population slope parameter\n\\(u_i\\): Error term (unobserved factors)\nExample: \\(wages_i = Œ≤‚ÇÄ + Œ≤‚ÇÅeducation_i + u_i\\)\n\n\nEstimation from a sample gives: \\[\\hat{y_i} = \\widehat{\\beta_0} + \\widehat{\\beta_1} x_i\\]\n\n\\(\\widehat{\\beta_0}\\): estimated intercept\n\\(\\widehat{\\beta_1}\\): estimated slope\n\\(\\hat{u_i}\\): Residuals = \\(\\hat{y_i} - y_i\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nparameters by defintion are model-defined population constants (not random variables)\n‚Äúhats‚Äù refer to estimates\nIf I write \\(y\\) instead of \\(y_i\\) that means I am referring to the entire vector of all \\(y_i\\)‚Äôs"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Population Model: \\[y_i = Œ≤‚ÇÄ + Œ≤‚ÇÅx_i + u_i\\]\n\n\nIf the other unobserved factors in u are held fixed,\n\nso that the changes in u is zero,\n\nthen x has a linear effect on y\nsimply: \\(\\Delta y_i = \\beta_1 \\Delta x_i\\) iff \\(\\Delta u_i = 0\\)\nFormally, \\(\\frac{\\partial y_i}{\\partial x_i} = \\beta_1\\) iff \\(\\frac{\\partial u_i}{\\partial x_i} = 0\\)\n\n\n\n\n\n\n\nNote\n\n\n\nWe are imposing an assumption on the relation between \\(x\\) and \\(u\\) to be able to interpret \\(\\beta_1\\).\nLets formalize."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#key-assumptions-about-u",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#key-assumptions-about-u",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Key Assumptions About \\(u\\)",
    "text": "Key Assumptions About \\(u\\)\n\nAssumptionsWhy is \\(E(u)=0\\) just a normalization?\n\n\n\n\n\n1. Zero Mean: \\(E(u) = 0\\)\n\nSimple normalization of unobservables\nCan always redefine intercept to make this true\n\nWhy This Works\n\nRequires intercept in the regression\nRedefining intercept absorbs any non-zero mean\n\n\n2. Mean Independence: \\(E(u|x) = E(u)\\)\n\nAverage error same for all values of \\(x\\)\nStronger than zero correlation\nVery strong assumption\n\nImplications\n\nCombines with first assumption to give:\n\\(E(u|x) = 0\\) (Zero Conditional Mean)\nEssential for interpreting \\(\\beta_1\\) as causal effect\n\n\n\n\n\n\n\nOriginal Model\n\\(wage_i = \\beta_0 + \\beta_1educ_i + u_i\\)\nWhere \\(u\\) includes ability:\n\nAverage ability = 100 (IQ points)\nSo \\(E(u) = 100 \\neq 0\\)\n\n\n\nRewritten Model\n\\(wage_i = (\\beta_0 + 100) + \\beta_1educ_i + \\tilde{u_i}\\)\nWhere:\n\n\\(\\tilde{u} = u - 100\\) is deviation from mean\nNow \\(E(\\tilde{u}) = 0\\)\nNew intercept = \\(\\beta_0 + 100\\)\nSame model, different parameterization"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#what-about-eu-mid-x-0",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#what-about-eu-mid-x-0",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "What about \\(E(u \\mid x) = 0\\)?",
    "text": "What about \\(E(u \\mid x) = 0\\)?\n\nLet us go back to the wage and education example\n\n\\[ wage_i = \\beta_0 + \\beta_1 education_i + u_i \\]\n\nwhat does mean independence and thereby zero conditional mean, mean here?\nis it too strong an assumption?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#population-regression-function",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#population-regression-function",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function\n\nPopulation Regression FunctionSample VisualizationComponents of y\n\n\n\n\nZero conditional mean implies:\n\\(E(y_i|x_i) = \\beta_0 + \\beta_1x_i\\)\nInterpretation\n\nLinear function of x\n1 unit \\(\\uparrow\\) in x changes \\(E(y)\\) by \\(\\beta_1\\)\nGiven x, distribution of y centered around \\(E(y|x)\\)\n\n\ngpa1 data\n\\(E(colGPA|hsGPA) = 1.5 + 0.5 \\, hsGPA\\)\nFor \\(hsGPA = 3.6\\):\n\nAverage \\(colGPA = 1.5 + 0.5(3.6) = 3.3\\)\nNot every student gets 3.3\nSome higher, some lower\nDepends on unobserved factors (u)\n\n\n\n\n\nlibrary(wooldridge)\n# gpa_model &lt;- lm(colGPA ~ hsGPA, data = gpa1)\n# summary(gpa_model)\nplot(gpa1$hsGPA, gpa1$colGPA,\n     xlab = \"High school  GPA\",\n     ylab = \"College GPA\",\n     col = \"red\")\nabline(lm(gpa1$colGPA ~ gpa1$hsGPA), col = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\n\nSystematic Part\n\n\\(\\beta_0 + \\beta_1x = E(y|x)\\)\nExplained by \\(x\\)\nPopulation regression line\nBlue line shows \\(E(y|x)\\) assuming linear model\n\n\nUnsystematic Part\n\n\\(u\\) = Deviation from \\(E(y|x)\\)\nNot explained by \\(x\\)\nZero mean at each \\(x\\): \\(E(u \\mid x) = 0\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-1",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "set.seed(123)\nn &lt;- 1e5\nu1 &lt;- rnorm(n, mean=0.0, sd=0.1)\nx &lt;- sin(seq(-5, 5, length.out=n))\nu2 &lt;- x + rnorm(n, mean=0, sd=0.1)\ncat(\"Mean of u1:\", mean(u1), \"\\n\", \"Mean of u2:\", mean(u2), \"\\n\")\n\nMean of u1: 9.767488e-05 \n Mean of u2: 0.0005215476 \n\npar(mfrow=c(1,2))\np1 &lt;- plot(x, u1, main=\"E(u)=0 and E(u|x)=0\")\nabline(lm(u1~x), col=\"red\", lwd=2)\np2 &lt;- plot(u2, x, main=\"E(u)=0 but E(u|x)!=0\")\nabline(lm(u2~x), col=\"red\", lwd=2)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-2",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-2",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Starting assumption to deriving OLS estimators\n\nWe start with two key assumptions:\n\n\\(E(u) = 0\\)\n\\(E(u \\mid x) = 0\\) (zero conditional mean)\n\nUsing this we can show that:\n\n\\(Cov(x,u) = E(xu) - E(x)E(u)\\)\nSince \\(E(u) = 0\\):\n\n\\(Cov(x,u) = E(xu) - E(x) \\cdot 0 = E(xu)\\)\n\nTherefore: \\(Cov(x,u) = 0 \\iff E(xu) = 0\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#derivation",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#derivation",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Derivation",
    "text": "Derivation\nPopulation Model: \\[y_i = Œ≤‚ÇÄ + Œ≤‚ÇÅx_i + u_i\\]\n\n\n\nAssumptions on the population:\n\n\\(E(u) = 0\\)\nCovariance between \\(x\\) and \\(u\\) is zero: \\(\\text{Cov}(x,u) = 0\\)\n\nThese imply: \\(E(xu) = 0\\)\n\n\nImplications:\n\nIn terms of observable variables \\(x\\) and \\(y\\):\n\n\\(E(y - \\beta_0 - \\beta_1x) = 0\\)\n\\(E[x(y - \\beta_0 - \\beta_1x)] = 0\\)\n\nAssumptions give us these moment conditions\n\n\n\nSample counterparts\n\nGiven a sample of data\nestimates \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\) solve the sample counterparts of the moment conditions,\n\nleading to equations:\n\n\n\\[\\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\]\n\\[\\frac{1}{n} \\sum_{i=1}^{n}x_i(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\]\n\nThese equations can be solved for \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\)."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-3",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-3",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Now, \\(\\frac{1}{n}  \\sum_{i=1}^{n}(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\), simplifies to\n\\[\\bar{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}\\bar{x_i}\\]\nWhere \\(\\bar{y_i} = \\frac{1}{n}  \\sum_{i=1}^{n}y_i\\) is the sample average of the \\(y_i\\).\nThus,\n\\[\\hat{\\beta_0} = \\bar{y_i}  - \\hat{\\beta_1}\\bar{x_i}\\]\nPlug in \\(\\hat{\\beta_0}\\) into: \\(\\frac{1}{n}  \\sum_{i=1}^{n}x_i(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\) and simplifying gives us the slope coefficient \\(\\hat{\\beta_1}\\):\n\\[\\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\]\nprovided, \\(\\sum_{i=1}^{n}(x_i - \\bar{x})^2 &gt; 0\\). What‚Äôs this?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-4",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-4",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Note that \\(\\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\) is nothing but\nthe sample covariance divided by the sample variance,\nwhich can be written as,\n\\[\\hat{\\beta}_1=\\hat{\\rho}_{x y} \\cdot\\left(\\frac{\\hat{\\sigma_y}}{\\hat{\\sigma_x}}\\right)\\]\nsince,\n\nsample covariance \\(= \\hat{\\rho}_{x y} \\cdot \\hat{\\sigma_y}\\hat{\\sigma_x}\\)\ncorrelation coeff: \\(\\hat{\\rho}_{x y}\\)\nsample variance \\(= \\hat{\\sigma_x}^2\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#interestingly",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#interestingly",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Interestingly",
    "text": "Interestingly\n\nthe line (characterized by an intercept and a slope) that minimizes: \\[\\sum_{i=1}^n \\hat{u}_i^2= \\underbrace{\\sum_{i=1}^n\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_i\\right)^2}_{\\text{SSR: Squared Sum of Residuals}}\\]\nlead to FOC‚Äôs that are same as what we obtained as the sample counterparts of the moment conditions\n\n\\(\\frac{1}{n}  \\sum_{i=1}^{n}(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\)\n\\(\\frac{1}{n}  \\sum_{i=1}^{n}x_i(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i) = 0\\)\n\nthat we used to derive the OLS estimates\nOLS chooses \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\) to minimize SSR\nLet us implement in R and test with the lm package"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#quick-recap",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#quick-recap",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Quick recap",
    "text": "Quick recap\n\nMain assumptions on the population: \\(E(u) = 0\\) and \\(E(u \\mid x) = 0\\)\nGives us moment conditions which we can convert to sample counterparts invoking LLN\nSolving the sample counterparts gives us the OLS estimates"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#fitted-values-and-residual",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#fitted-values-and-residual",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Fitted values and residual",
    "text": "Fitted values and residual\n\nThe estimates of \\(\\beta_0\\) and \\(\\beta_1\\) thus obtained are called OLS\nCan obtain ‚Äúfitted values‚Äù of \\(y_i\\): \\[\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_i\\]\nObtain residuals: \\(\\hat{u_i} = y_i - \\hat{y_i} = y_i - \\hat{\\beta_0} - \\hat{\\beta_1} x_i\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#properties",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#properties",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Properties",
    "text": "Properties\n\nSample mean of residuals is zero \\(\\frac{1}{n} \\sum_{i=1}^{n} \\hat{u}_i = 0\\)\nSample mean of x and y \\((\\bar{x}, \\bar{y})\\) lies on the regression line\nThe sample covariance between the regressors (\\(x\\)) and the OLS residuals is zero \\(\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})\\hat{u}_i = 0\\)\nPredictions and residuals are uncorrelated \\(\\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})\\hat{u}_i = 0\\)\n\nTry testing these out with this generated data:\n\nset.seed(123)\nx &lt;- seq(1, 100, length.out = 50)\ny &lt;- 2 + 3*x + rnorm(50, 0, 20) #DGP\nplot(x, y, main=\"Linear Relationship Example\")\nabline(lm(y ~ x), col=\"red\", lwd=2)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#decomposition",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#decomposition",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Decomposition",
    "text": "Decomposition\n\n\n\nTotal Sum of Squares (SST): \\[\n\\text{SST} \\equiv \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n\\]\nExplained Sum of Squares (SSE): \\[\n\\text{SSE} \\equiv \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2\n\\]\nResidual Sum of Squares (SSR): \\[\n\\text{SSR} \\equiv \\sum_{i=1}^{n}\\hat{u}_i^2\n\\]\n\n\nRelationship Between Sums of Squares\nTotal variation in \\(y\\) can be expressed as:\n\\[\n\\text{SST} = \\text{SSE} + \\text{SSR}\n\\]\nProof Outline To prove this relationship, we can write:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}[(\\hat{y}_i - \\bar{y}) + (y_i - \\hat{y}_i)]^2\n\\] \\[\n= \\sum_{i=1}^{n}(\\hat{u}_i + (y_i - \\bar{y}))^2\n\\] \\[\n= \\text{SSR} + 2\\sum_{i=1}^{n}\\hat{u}_i(y_i - \\bar{y}) + \\text{SSE}\n\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#r-squared",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#r-squared",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "R-squared",
    "text": "R-squared\n\nMeasures goodness of fit \\[R^2 = \\frac{SSE}{SST} = 1 - \\frac{SSR}{SST}\\]\nRanges from 0 to 1\nInterpretation: Proportion of variance explained by model\n\n\n# Calculate R-squared\nsummary(model)$r.squared\n\n[1] 0.6510794\n\n# Decomposition of variance\nanova(model)\n\nAnalysis of Variance Table\n\nResponse: dist\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nspeed      1  21186 21185.5  89.567 1.49e-12 ***\nResiduals 48  11354   236.5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#overview",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#overview",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Overview",
    "text": "Overview\n\nFor any estimator we want to know two important things\n\nWhether we are getting unbiased estimates\nIf yes, how precisely can we obtain those estimates\n\nWill require assumptions\nFor OLS, we have 5 of them, which will constitute the Gauss-Markov assumptions"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#unbiasedness-of-an-estimator",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#unbiasedness-of-an-estimator",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Unbiasedness of an estimator",
    "text": "Unbiasedness of an estimator\nAn estimator is unbiased if, on average, it produces estimates that are equal to the true value of the parameter being estimated.\n\n\n\nDefinition\n\n\nAn estimator producing an estimate \\(\\hat{\\theta}\\) for a parameter \\(\\theta\\) is considered unbiased if: \\[\n\\mathbb{E}(\\widehat{\\theta}) = \\theta\n\\]\n\n\n\nBasically means that the sampling distribution of \\(\\hat{\\theta}\\) is centered around the true \\(\\theta\\) on average\nWe will now show that the OLS estimator for a SLR model‚Äôs parameters \\((\\beta_0, \\beta_1)\\) is unbiased"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#assumptions-to-prove-unbiasedness-of-ols",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#assumptions-to-prove-unbiasedness-of-ols",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Assumptions to prove unbiasedness of OLS",
    "text": "Assumptions to prove unbiasedness of OLS\n\nSLR 1 - 4SLR1SLR2SLR3SLR4\n\n\n\nLinear in parameters\nRandom sampling\nSample Variation in X\nZero Conditional mean\n\n\n\n\nLinear in parameters:\nIn the population model, the dependent variable, \\(y\\), is related to the independent variable, \\(x\\), and the error (or disturbance), \\(u\\), as: \\[\ny=\\beta_0+\\beta_1 x+u\n\\] where \\(\\beta_0\\) and \\(\\beta_1\\) are the population intercept and slope parameters, respectively.\n\n\n\n\nRandom Sampling\nWe have a random sample of size n,\\(\\left\\{\\left(x_i, y_i\\right): i=1,2, \\ldots, n\\right\\}\\) in the population model\n\n\n\n\nSample variation in X\nThe sample explanatory x variable, namely, \\(x_i\\) , \\(i \\in \\{1, \\cdots, n\\}\\) , are not all the same value \\[\\widehat{Var}(x_i) &gt; 0\\]\n\n\n\n\nZero conditional mean\n\nThe error \\(u\\) has an expected value of zero given any value of the explanatory variable. In other words, \\[E(u \\mid x)=0\\] ."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Theorem",
    "text": "Theorem\n\n\n\nTheorem: Unbiasedness of the OLS estimator\n\n\nUsing Assumptions SLR. 1 through SLR.4,\n\\[\n\\mathrm{E}\\left(\\hat{\\beta}_0\\right)=\\beta_0 \\text { and } \\mathrm{E}\\left(\\hat{\\beta}_1\\right)=\\beta_1\n\\]\n\n\n\n\nIn other words, \\(\\hat{\\beta}_0\\) is unbiased for \\(\\beta_0\\), and \\(\\hat{\\beta}_1\\) is unbiased for \\(\\beta_1\\).\nLet us prove it using our assumptions!\nIn doing so, we will learn some tricks, and I want you to learn the tricks and observe the patterns in the art of going about an econoemtric proof."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#key-patterns-in-the-proof",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#key-patterns-in-the-proof",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Key patterns in the proof",
    "text": "Key patterns in the proof\n\nStart with the OLS estimate \\(\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\) and \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\)\nWrite the OLS estimator in terms of the population parameters\n\nTo do this we have to bring in \\(y_i\\) (population model) and not \\(\\hat{y_i}\\)\n\nThis is what brings in the population parameters \\(\\beta_0\\) and \\(\\beta_1\\) on the RHS\n\nTricks to bring in \\(y_i\\) in the OLS estimator:\n\nWithout any assumptions we showed and used:\n\\(\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) = \\sum_{i=1}^n(x_i - \\bar{x})y_i\\)\n\nCould have written this as \\(\\sum_{i=1}^n(y_i - \\bar{y})x_i\\) but did not to bring in \\(y_i\\)\n\n\nOther tricks: Without any assumptions\n\n\\(\\sum_{i=1}^n(x_i - \\bar{x}) = 0\\)\n\\(\\sum_{i=1}^n(x_i - \\bar{x})x_i = \\sum_{i=1}^n(x_i - \\bar{x})^2\\)\n\n\nTake the expectation conditional on \\(x_i\\)\n\nimpose the SLR assumptions on zero mean and zero conditional mean\nuse LIE"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#sampling-distribution-of-the-ols-estimators",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#sampling-distribution-of-the-ols-estimators",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Sampling distribution of the OLS estimators",
    "text": "Sampling distribution of the OLS estimators\n\npopulation model: \\(y_i = \\beta_0 + \\beta_1 x_i + u_i\\)\nThe OLS estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are random variables because they depend on the random sample \\(\\left\\{\\left(x_i, y_i\\right): i=1,2, \\ldots, n\\right\\}\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#slr-5-homoskedasticity-assumption",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#slr-5-homoskedasticity-assumption",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "SLR 5: Homoskedasticity assumption",
    "text": "SLR 5: Homoskedasticity assumption\nThe population error \\(u_i\\) has the same variance given any value of \\(x_i\\), i.e.,\n\\[\nVar(u \\mid x) = \\sigma^2\n\\]\nSLR 5 further implies that \\(\\sigma^2\\) is also the unconditional variance of \\(u\\).\n\\[\\operatorname{Var}(u \\mid x)=\\mathrm{E}\\left(u^2 \\mid x\\right)-[\\mathrm{E}(u \\mid x)]^2\\]\n\\[ \\text { and since } \\mathrm{E}(u \\mid x)=0, \\sigma^2=\\mathrm{E}\\left(u^2 \\mid x\\right)\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#now-we-have-var-y-mid-x",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#now-we-have-var-y-mid-x",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Now we have \\(Var( y \\mid x)\\)",
    "text": "Now we have \\(Var( y \\mid x)\\)\n\n\nusing Assumptions SLR. 4 and SLR. 5 we can derive the conditional variance of \\(y\\) :\n\\[\n\\begin{gathered}\n\\mathrm{E}(y \\mid x)=\\beta_0+\\beta_1 x \\\\\n\\operatorname{Var}(y \\mid x)=\\sigma^2\n\\end{gathered}\n\\]\nFrom here we can get \\(Var(u \\mid x)\\)\n\n\n\n\nHomoskedasticity"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem-1",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Theorem",
    "text": "Theorem\n\n\n\nSampling variance of OLS estimators\n\n\nUnder Assumptions SLR. 1 through SLR.5,\n\\[\n\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)=\\frac{\\sigma^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} = \\frac{\\sigma^2}{\\mathrm{SST}_x},\n\\]\nand\n\\[\n\\operatorname{Var}\\left(\\hat{\\beta}_0\\right)=\\frac{\\sigma^2 \\frac{1}{n} \\sum_{i=1}^n x_i^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} = \\frac{\\sigma^2 \\frac{1}{n} \\sum_{i=1}^n x_i^2}{\\mathrm{SST}_x}\n\\]\nwhere these are conditional on the sample values \\(\\left\\{x_1, \\ldots, x_n\\right\\}\\).\n\n\n\n\nLet us prove this!"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#proof-of-operatornamevarlefthatbeta_1right",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#proof-of-operatornamevarlefthatbeta_1right",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Proof of \\(\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)\\)",
    "text": "Proof of \\(\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)\\)\n\nLet us work with \\(\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\) \\(\\implies\\) \\(\\hat{\\beta}_1 = \\beta_1 + \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})u_i}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\)\nDenote \\((x_i - \\bar{x})\\) as \\(d_i\\). So \\(\\hat{\\beta}_1 = \\beta_1 + \\frac{\\sum_{i=1}^{n} d_iu_i}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\)\nNow take the variance of \\(\\hat{\\beta}_1\\) conditional on the sample values \\(x_i\\)\n\n\\[\\begin{align*}\n    \\operatorname{Var}\\left(\\hat{\\beta}_1\\right) & = \\operatorname{Var}\\left(\\beta_1 + \\frac{\\sum_{i=1}^{n} d_iu_i}{SST_x}\\right) \\\\\n    & = \\operatorname{Var}\\left(\\frac{\\sum_{i=1}^{n} d_iu_i}{SST_x}\\right) \\quad \\text{skipping 2 steps} \\\\\n    & = \\frac{1}{\\left(SST_x\\right)^2} \\sum_{i=1}^{n} d_i^2 \\operatorname{Var}(u_i) \\quad \\text{skipping 3 steps} \\\\\n    & = \\frac{\\sigma^2}{SST_x}\n\\end{align*}\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#measure-of-precision-of-hatbeta_1",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#measure-of-precision-of-hatbeta_1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Measure of precision of \\(\\hat{\\beta_1}\\)",
    "text": "Measure of precision of \\(\\hat{\\beta_1}\\)\n\n\n\\(sd(\\hat{\\beta}_1) = \\sqrt{\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)}\\) gives a measure of the precision of \\(\\hat{\\beta}_1\\)\nBut we do not know \\(\\sigma^2\\) so we do not know \\(sd(\\hat{\\beta}_1)\\)\nSo we have to estimate \\(\\sigma^2\\) to get an estimate of \\(sd(\\hat{\\beta}_1)\\)\nThe estimate of the \\(sd(\\hat{\\beta}_1)\\) is called the standard error of \\(\\hat{\\beta}_1\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem-2",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#theorem-2",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Theorem",
    "text": "Theorem\n\n\n\nUnbiased estimation of \\(\\sigma^2\\)\n\n\nUnder Assumptions SLR. through SLR.5,\n\\[\\mathrm{E}\\left(\\hat{\\sigma}^2\\right)=\\sigma^2\\]\nwhere \\(\\hat{\\sigma}^2=\\frac{1}{n-2} \\sum_{i=1}^n \\hat{u}_i^2\\), where \\(\\hat{u}_i=y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_i\\)\n\n\n\n\nStudy the proof from 2-5c\nTry to observe the patterns in the proof similar to the unbiasedness proof of the OLS estimates"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#in-essence-we-have-shown",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#in-essence-we-have-shown",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "In essence we have shown",
    "text": "In essence we have shown\n\nAssuming SLR 1-5, and conditional on the sample values \\(\\left\\{x_1, \\ldots, x_n\\right\\}\\), we have shown that:\n\nThe OLS estimators are unbiased\n\n\\(\\mathrm{E}\\left(\\hat{\\beta}_0\\right)=\\beta_0\\) and \\(\\mathrm{E}\\left(\\hat{\\beta}_1\\right)=\\beta_1\\)\n\nWe can obtain the variance of the OLS estimators\n\n\\(\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)=\\frac{\\sigma^2}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} = \\frac{\\sigma^2}{\\mathrm{SST}_x}\\)\n\\(\\operatorname{Var}\\left(\\hat{\\beta}_0\\right)=\\frac{\\sigma^2 \\frac{1}{n} \\sum_{i=1}^n x_i^2}{\\mathrm{SST}_x}\\)\n\nBut we do not know \\(\\sigma^2\\)\n\nThe residual variance \\(\\hat{\\sigma}^2\\) is unbiased for the variance of the population errror \\(\\sigma^2\\)\n\\(\\mathrm{E}\\left(\\hat{\\sigma}^2\\right)=\\sigma^2\\)\n\nAnd we learnt a lot of tricks and pattern recognition in the process\nAnd some stuff about how to work with data"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#heteroskedasticity-in-slr",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#heteroskedasticity-in-slr",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Heteroskedasticity in SLR",
    "text": "Heteroskedasticity in SLR\n\nHeteroskedasticity: \\[Var(u_i \\mid x_i)=\\sigma^2(x_i) \\quad \\text{(not constant)}\\]\nUnder SLR1‚ÄìSLR4 (but not SLR5):\n\nOLS remains unbiased for \\((\\beta_0,\\beta_1)\\)\nUsual variance formulae and standard errors are invalid\nOLS is no longer efficient among linear unbiased estimators\n\nLarge-sample variance (idea): weights depend on \\(u_i^2\\) \nFix (inference): use heteroskedasticity-robust (White/Eicker‚ÄìHuber) SEs\n\nSame point estimates, different (robust) standard errors\n\n\n\n\n\n\n\n\nWarning\n\n\nHeteroskedasticity is common in cross-sectional data (wages, firm sizes, housing prices)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-5",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-5",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "library(lmtest)  # for BP test\nlibrary(sandwich)  # for robust SEs\n\n# Generate data with heteroskedasticity\nset.seed(456)\nn &lt;- 1000\neduc &lt;- rnorm(n, 12, 3)\nexper &lt;- runif(n, 0, 20)\nu &lt;- rnorm(n, 0, sd = 0.5 + 3*educ^2)\nwage &lt;- 10 + 2*educ + u\n\nmodel &lt;- lm(wage ~ educ)\n\n# Breusch-Pagan test for heteroskedasticity\nbptest(model)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model\nBP = 184.4, df = 1, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#section-6",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#section-6",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "plot(fitted(model), residuals(model), \n     main=\"Residuals vs Fitted\", xlab=\"Fitted values\", \n     ylab=\"Residuals\", pch=20, col=\"darkblue\")\nabline(h=0, col=\"red\", lty=2)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#recommendation-to-get-robust-ses",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#recommendation-to-get-robust-ses",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Recommendation to get robust SEs",
    "text": "Recommendation to get robust SEs\nIn the lm function, use:\n\nlibrary(sandwich)\nlibrary(lmtest)\n\nmodel &lt;- lm(wage ~ educ)\ncoeftest(model, vcov = vcovHC(model, type = \"HC1\"))\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   9.4847    76.1247  0.1246   0.9009\neduc          2.3196     7.1087  0.3263   0.7443\n\n# instead of\nsummary(model)\n\n\nCall:\nlm(formula = wage ~ educ)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2058.77  -251.34    -4.47   264.48  2258.63 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    9.485     69.421   0.137    0.891\neduc           2.320      5.545   0.418    0.676\n\nResidual standard error: 515.7 on 998 degrees of freedom\nMultiple R-squared:  0.0001753, Adjusted R-squared:  -0.0008265 \nF-statistic: 0.175 on 1 and 998 DF,  p-value: 0.6758"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#the-four-types",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#the-four-types",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "The Four Types",
    "text": "The Four Types\n\nLevel-level: \\(y = b_0 + b_1x\\)\nLevel-log: \\(y = b_0 + b_1\\log(x)\\)\nLog-level: \\(\\log(y) = b_0 + b_1x\\)\nLog-log: \\(\\log(y) = b_0 + b_1\\log(x)\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#interpreting-log-specifications",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#interpreting-log-specifications",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Interpreting Log Specifications",
    "text": "Interpreting Log Specifications\n\n\n\nSpecification\nChange in x\nEffect on y\n\n\n\n\nLevel-level\n+1 unit\n+\\(b_1\\) units\n\n\nLevel-log\n+1%\n+\\(\\frac{b_1}{100}\\) units\n\n\nLog-level\n+1 unit\n+\\((100 \\times b_1)\\%\\)\n\n\nLog-log\n+1%\n+\\(b_1\\%\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#why-use-logs",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#why-use-logs",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Why Use Logs?",
    "text": "Why Use Logs?\n\nNormalize skewed distributions\nReduce impact of outliers\nInterpret coefficients as elasticities\nTransform multiplicative relationships to additive"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#example-ceo-salaries",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#example-ceo-salaries",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Example: CEO Salaries",
    "text": "Example: CEO Salaries\n\ndata(\"ceosal1\", package = \"wooldridge\")\npar(mfrow=c(1,2))\nplot(salary ~ sales, data = ceosal1, \n     main = \"Raw Values\")\nplot(log(salary) ~ log(sales), data = ceosal1, \n     main = \"Log Transformed\")"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#non-linear-relationships",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#non-linear-relationships",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Non-Linear Relationships",
    "text": "Non-Linear Relationships\n\nNot all relationships are linear\nCan add polynomial terms: \\(y_i = \\beta_0 + \\beta_1x_i^2 + u_i\\)\nVisual inspection is crucial\nAlways plot your data first!\n\n\n\n\n\n\n\nNote\n\n\nLinear in linear regression means linear in parameters not variables"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/03_regression.html#remaining-things-for-you-to-sudy",
    "href": "teachingmaterials/UG_intro_metrics/03_regression.html#remaining-things-for-you-to-sudy",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Remaining things for you to sudy",
    "text": "Remaining things for you to sudy\n\nRead up on the properties of the conditional expectation in Math Refresher B\nRead up:\n\n2-6: Regression through the Origin and Regression on a Constant\n2-7: Regression on a Binary Explanatory Variable\n\n\nnext class we will start chapter 3"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html",
    "title": "Econometrics PS 1",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.1",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.1",
    "title": "Econometrics PS 1",
    "section": "Q 3.1",
    "text": "Q 3.1\n\nLoad the data and create a scatter plot of monthly wages (wage) against years of education (educ). What do you observe about the relationship? Are there any concerning patterns?\nCalculate and report the sample correlation between wages and education. Then manually calculate \\hat{\\beta}_1 using the formula: \\hat{\\beta}_1 = \\hat{\\rho}_{xy} \\cdot \\left(\\frac{\\hat{\\sigma}_y}{\\hat{\\sigma}_x}\\right) by computing each component separately. Show that this matches the OLS estimate from lm().\nEstimate the simple linear regression:\n\n\nwage_i = \\beta_0 + \\beta_1 \\, educ_i + u_i\n\nReport and interpret both coefficients. Is the intercept meaningful in this context?\n\nCalculate the fitted values and residuals manually (without using fitted() or residuals()). Verify that:\n\n\nThe mean of residuals equals zero\n\nThe point (\\bar{educ}, \\bar{wage}) lies on the regression line\n\nThe sample covariance between education and residuals is zero"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.2",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.2",
    "title": "Econometrics PS 1",
    "section": "Q 3.2",
    "text": "Q 3.2\n\nEstimate:\n\n\n\\log(wage_i) = \\beta_0 + \\beta_1 \\, educ_i + u_i\n\n\nUsing the log-level specification:\n\n\nCalculate the exact percentage return to one additional year of education\n\nPredict the percentage wage difference between workers with 12 and 16 years of education\n\n\n\nCreate histograms of wage and log(wage). Which estimation would you prefer to run: level-level or log-level? Justify your choice."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.3",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps1.html#q-3.3",
    "title": "Econometrics PS 1",
    "section": "Q 3.3",
    "text": "Q 3.3\n\nCreate a residual plot (residuals vs.¬†fitted values) for your log-level specification. Do you see evidence of heteroskedasticity? Explain what pattern you would look for.\nGroup the data into three education categories: low (educ &lt; 12), medium (12 \\leq educ &lt; 16), and high (educ \\geq 16).\n\n\nwage2$educ_group &lt;- cut(wage2$educ, \n                        breaks = c(-Inf, 12, 16, Inf),\n                        labels = c(\"Low (&lt;12)\", \"Medium (12-16)\", \"High (‚â•16)\"),\n                        right = FALSE)\n\nCalculate the variance of residuals within each group. What do these variances suggest about the homoskedasticity assumption?\n\nIf heteroskedasticity is present, what are the consequences for the unbiasedness of \\hat{\\beta}_1?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#introduction",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#introduction",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThe idea here would be extend the concepts discussed simple linear regression\nAgain, it is crucial that you make yourself comfortable with the concepts of simple linear regression before moving on here\nConsequently, we will be much faster than the previous topic\nOnce again the big picture will be to extend the assumptions revolving around \\(u_i\\) and \\(x_i\\) to multiple variables\n\nto understand how does the OLS estimator plays out"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#multiple-linear-regression",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#multiple-linear-regression",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\n\nPopulation model: \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_k x_{ki} + u_i\\)\n\n\\(i = 1, 2, \\ldots, n\\) indexes the observations\n\\(y_i\\) is the dependent variable,\n\\(x_{1i}, x_{2i}, \\ldots, x_{ki}\\) are the independent variables, \\(u_i\\) is the error term\n\\(\\beta_0, \\beta_1, \\ldots, \\beta_k\\) are the parameters\n\nThe key assumption will be a generalized versions in SLR \\[E(u_i|x_{1i}, x_{2i}, \\ldots, x_{ki}) = 0\\] \\[E(u_i) = 0\\]\nThese together imply: \\(E(x_{1i}u_i) = E(x_{2i}u_i) = \\ldots = E(x_{ki}u_i) = 0\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#obtaining-the-ols-estimates",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#obtaining-the-ols-estimates",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Obtaining the OLS estimates",
    "text": "Obtaining the OLS estimates\n\nOnce again, we will choose \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_k\\) to minimize the sum of squared residuals : \\[\\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_{1i} - \\hat{\\beta}_2 x_{2i} - \\ldots - \\hat{\\beta}_k x_{ki})^2\\]\n\nThis minimization problem leads to \\(k+1\\) linear equations (F.O.C.s) in \\(k+1\\) unknowns \\(\\hat{\\boldsymbol{\\beta}}_0, \\hat{\\boldsymbol{\\beta}}_1, \\ldots, \\hat{\\boldsymbol{\\beta}}_k\\) :\n\\[\n\\begin{aligned}\n& \\sum_{i=1}^n\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_{i 1}-\\cdots-\\hat{\\beta}_k x_{i k}\\right)=0 \\\\\n& \\sum_{i=1}^n x_{i 1}\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_{i 1}-\\cdots-\\hat{\\beta}_k x_{i k}\\right)=0 \\\\\n% & \\sum_{i=1}^n x_{i 2}\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_{i 1}-\\cdots-\\hat{\\beta}_k x_{i k}\\right)=0 \\\\\n& \\vdots \\\\\n& \\sum_{i=1}^n x_{i k}\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 x_{i 1}-\\cdots-\\hat{\\beta}_k x_{i k}\\right)=0\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#the-focs",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#the-focs",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "The FOCs",
    "text": "The FOCs\n\n\nThe FOCs give us \\(k+1\\) equations in \\(k+1\\) unknowns\nNote that we arrive at this because we assume that any change in \\(x_{1i}\\), \\(x_{2i}\\), \\(\\ldots\\), \\(x_{ki}\\) will not affect the error term \\(u_i\\)\nGives us the sample counterparts of \\(k+1\\) moment conditions\n\nRecall we did something similar in SLR\n\nThe moment conditions are given by: \\[\\begin{aligned}\nE(u_i) &= 0 \\\\\nE(x_{1i}u_i) &= 0 \\\\\nE(x_{2i}u_i) &= 0 \\\\\n\\vdots \\\\\nE(x_{ki}u_i) &= 0\n\\end{aligned}\\]\nNote that we arrive at this because we assume that any change in \\(x_{1i}\\), \\(x_{2i}\\), \\(\\ldots\\), \\(x_{ki}\\) will not affect the error term \\(u_i\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#section",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#section",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "library(wooldridge)\nwage_data &lt;- wage1\n# run a regression of log(wage) on educ, exper, and tenure\nreg1 &lt;- lm(log(wage) ~ educ + exper + tenure, data = wage_data)\nsummary(reg1)\n\n\nCall:\nlm(formula = log(wage) ~ educ + exper + tenure, data = wage_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05802 -0.29645 -0.03265  0.28788  1.42809 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.284360   0.104190   2.729  0.00656 ** \neduc        0.092029   0.007330  12.555  &lt; 2e-16 ***\nexper       0.004121   0.001723   2.391  0.01714 *  \ntenure      0.022067   0.003094   7.133 3.29e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4409 on 522 degrees of freedom\nMultiple R-squared:  0.316, Adjusted R-squared:  0.3121 \nF-statistic: 80.39 on 3 and 522 DF,  p-value: &lt; 2.2e-16\n\n\n\nkeeping educ fixed, what is the effect of changing exper and tenure by one year simultaneously?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-1",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "# keeping educ fixed, what is the effect of changing exper and tenure by one year simultaneously?\n\nreg1$coefficients[3] + reg1$coefficients[4]\n\n     exper \n0.02618833 \n\n\n\nIt returns an object of type Named num\nAlso not easy to read code\nLet us be complete and verbose\n\n\nbeta_exper &lt;- reg1$coefficients[3] \nbeta_tenure &lt;-  reg1$coefficients[4] \ntotal_effect &lt;- as.numeric(beta_exper + beta_tenure)\ntotal_effect\n\n[1] 0.02618833"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#residual-and-fitted-values",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#residual-and-fitted-values",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Residual and fitted values",
    "text": "Residual and fitted values\n\n\n\n\nThe fitted/predicted values are given by: \\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1i} + \\hat{\\beta}_2 x_{2i} + \\ldots + \\hat{\\beta}_k x_{ki}\\]\nThe residuals are given by: \\[\\hat{u}_i = y_i - \\hat{y}_i\\] \\[= y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_{1i} - \\hat{\\beta}_2 x_{2i} - \\ldots - \\hat{\\beta}_k x_{ki}\\]\n\n\n\n# Fitted values\nfitted_values &lt;- reg1$fitted.values\nhead(fitted_values)\n\n       1        2        3        4        5        6 \n1.304921 1.523506 1.304921 1.819802 1.461690 1.970451 \n\n# Residuals\nresiduals &lt;- reg1$residuals\nhead(residuals)\n\n          1           2           3           4           5           6 \n-0.17351855 -0.34793290 -0.20630834 -0.02804287  0.20601726  0.19860264 \n\n\n\n# manual residuals\nobserved_wage &lt;- log(wage_data$wage)\nmanual_residuals &lt;- observed_wage - fitted_values\n# test if manual residuals are approximately the same as residuals\nall.equal(residuals, manual_residuals)\n\n[1] TRUE"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#properties-of-fitted-values-and-residuals",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#properties-of-fitted-values-and-residuals",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Properties of fitted values and residuals",
    "text": "Properties of fitted values and residuals\n\nImmediate extension of SLR and implications from the moment conditions:\n\nSample average of residuals is zero: \\(\\sum_{i=1}^n \\hat{u}_i = 0\\)\nSample covariance between residuals and each of the independent variables is zero: \\(\\sum_{i=1}^n x_{1i} \\hat{u}_i = 0\\) \\(\\sum_{i=1}^n x_{2i} \\hat{u}_i = 0\\) \\(\\vdots\\) \\(\\sum_{i=1}^n x_{ki} \\hat{u}_i = 0\\)\nThe point \\((\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_k, \\bar{y})\\) lies on the regression plane \\[\\bar{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\bar{x}_1 + \\hat{\\beta}_2 \\bar{x}_2 + \\ldots + \\hat{\\beta}_k \\bar{x}_k\\]\nTry them out in R"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#partialing-out-interpretation",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#partialing-out-interpretation",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Partialing out interpretation",
    "text": "Partialing out interpretation\nConsider a population model with k=2, i.e., two independent variables.\n\\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + u_i\\]\nLet us focus on \\(\\beta_1\\)\n\n# run a regression of log(wage) on educ, exper\nreg_wage_on_educ_exp &lt;- lm(log(wage) ~ educ + exper, data = wage_data)\nsummary(reg_wage_on_educ_exp)\n\n\nCall:\nlm(formula = log(wage) ~ educ + exper, data = wage_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05800 -0.30136 -0.04539  0.30601  1.44425 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.216854   0.108595   1.997   0.0464 *  \neduc        0.097936   0.007622  12.848  &lt; 2e-16 ***\nexper       0.010347   0.001555   6.653 7.24e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4614 on 523 degrees of freedom\nMultiple R-squared:  0.2493,    Adjusted R-squared:  0.2465 \nF-statistic: 86.86 on 2 and 523 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-2",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-2",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "# step 1: run a regression of log(wage) on exper\nreg_logwage_on_exp &lt;- lm(log(wage) ~ exper, data = wage_data)\nresiduals_logwage_on_exp &lt;- reg_logwage_on_exp$residuals\n# step 2: run a regression of educ on exper\nreg_educ_on_exp &lt;- lm(educ ~ exper, data = wage_data)\nresiduals_educ_on_exp &lt;- reg_educ_on_exp$residuals\n# step 3: run a regression of residuals from step 1 on residuals from step 2\npartial_out_reg &lt;- lm(residuals_logwage_on_exp ~ residuals_educ_on_exp)\nsummary(partial_out_reg)\n\n\nCall:\nlm(formula = residuals_logwage_on_exp ~ residuals_educ_on_exp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05800 -0.30136 -0.04539  0.30601  1.44425 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -2.192e-18  2.010e-02    0.00        1    \nresiduals_educ_on_exp  9.794e-02  7.615e-03   12.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.461 on 524 degrees of freedom\nMultiple R-squared:  0.2399,    Adjusted R-squared:  0.2385 \nF-statistic: 165.4 on 1 and 524 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#whats-going-on",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#whats-going-on",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "What‚Äôs going on?",
    "text": "What‚Äôs going on?\n\n\nThe population model is given by: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + u_i\\]\nTo get the effect of \\(x_{1i}\\) on \\(y_i\\), the MLR is equivalent to the following two-step procedure:\n\nStep 1: Regress \\(y_i\\) on \\(x_{2i}\\) and obtain the residuals \\(\\hat{e}_i\\)\n\n\\(\\hat{e}_i\\) has the variation left in \\(y_i\\) after partialling out variation from \\(x_{2i}\\)\n\nStep 2: Regress \\(x_{1i}\\) on \\(x_{2i}\\) and obtain the residuals \\(\\hat{v}_i\\)\n\n\\(\\hat{v}_i\\) has the variation left in \\(x_{1i}\\) after partialling out variation from \\(x_{2i}\\)\n\nStep 3: Regress \\(\\hat{e}_i\\) on \\(\\hat{v}_i\\)\n\nThe idea is to partial out the effect of \\(x_{2i}\\) from \\(x_{1i}\\) and \\(y_i\\)\n\nThis is the same as regressing \\(y_i\\) on \\(x_{1i}\\) and \\(x_{2i}\\)\n\nHence comes the interpretation of \\(\\beta_1\\) as the effect of \\(x_{1i}\\) on \\(y_i\\) keeping \\(x_{2i}\\) fixed\nThere is another way to approach this. See textbook 3-2f and implement it in R"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#comparison-of-simple-and-multiple-regression-estimates",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#comparison-of-simple-and-multiple-regression-estimates",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Comparison of Simple and Multiple Regression Estimates",
    "text": "Comparison of Simple and Multiple Regression Estimates\n\n\nThe population model is given by: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + u_i\\]\nSuppose instead we only estimate the SLR of \\(y\\) on \\(x_{1i}\\): \\[\\tilde{y_i} = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 x_{1i}\\]\nSLR estimate \\(\\tilde{\\beta}_1\\) relates to the MLR estimate \\(\\hat{\\beta}_1\\) via: \\[\\tilde{\\beta}_1 = \\hat{\\beta}_1 + \\hat{\\beta}_2 \\delta_1\\] where \\(\\delta_1\\) is the slope from the regression of \\(x_{2i}\\) on \\(x_{1i}\\) from estimating: \\[x_{2i} = \\delta_0 + \\delta_1 x_{1i} + \\epsilon\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-3",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-3",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Confounding term:\n\n\\(\\hat{\\beta}_2 \\delta_1\\): The partial effect of \\(x_{2i}\\) on \\(\\hat{y}\\) scaled by the relationship between \\(x_{2i}\\) and \\(x_{1i}\\).\n\nTwo distinct cases where \\(\\tilde{\\beta}_1 = \\hat{\\beta}_1\\):\n\nThe partial effect of \\(x_{2i}\\) on \\(\\hat{y}\\) is zero: \\(\\hat{\\beta}_2 = 0\\).\n\\(x_{1i}\\) and \\(x_{2i}\\) are uncorrelated: \\(\\delta_1 = 0\\).\n\nThus generically in a MLR of \\(y_i\\) on \\(x_{1i}, \\cdots, x_{ki}\\), the OLS estimate on the coefficient on \\(x_{1i}\\)\n\nwill be identical to one obtained from a simple regression of \\(y_i\\) on \\(x_{1i}\\)\n\niff \\(x_{1i}\\) and \\(x_{2i}, \\cdots, x_{ki}\\) are uncorrelated.\n\n\nExample of ability bias in wage regressions"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#goodness-of-fit",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#goodness-of-fit",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Goodness of Fit",
    "text": "Goodness of Fit\n\nThe idea of the \\(R^2\\) statistic in MLR is the same as in SLR\n\nThe proportion of the total variation in \\(y_i\\) that is explained by the independent variables in the model \\[R^2 = \\frac{SSE}{SST} = 1 - \\frac{SSR}{SST}\\], where:\n\n\\(SSE = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2\\) is the explained sum of squares\n\\(SSR = \\sum_{i=1}^n \\hat{u}_i^2\\) is the sum of squared residuals\n\\(SST = \\sum_{i=1}^n (y_i - \\bar{y})^2\\) is the total sum of squares\n\n\nAlways between 0 and 1"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#assumptions-of-mlr",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#assumptions-of-mlr",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Assumptions of MLR",
    "text": "Assumptions of MLR\n\nMLR.1: Linearity: The population model \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_k x_{ki} + u_i\\) is linear in the parameters \\(\\beta_0, \\beta_1, \\ldots, \\beta_k\\)\nMLR.2: Random Sampling: The data \\((y_i, x_{1i}, x_{2i}, \\ldots, x_{ki})\\) for \\(i = 1, 2, \\ldots, n\\) are a random sample from the population\nMLR.3: No Perfect Collinearity: The X‚Äôs are not perfectly collinear\n\n\nThey are not a linear combination of one another\n\n\nMLR.4: Zero Conditional Mean: \\(E(u_i|x_{1i}, x_{2i}, \\ldots, x_{ki}) = 0\\) \n\nThis implies that \\(E(u_i) = 0\\) and \\(E(x_{ji}u_i) = 0\\) for all \\(j = 1, 2, \\ldots, k\\)\nIf this holds then the \\(x_{ji}\\) are called strictly exogeneous\n\n\n\n\n\nTheorem: Unbiasedness of the OLS estimator in MLR\n\n\nUnder Assumptions MLR.1-MLR.4, the OLS estimator is unbiased. That is, \\(E(\\hat{\\beta}_j) = \\beta_j\\) for \\(j = 0, 1, \\ldots, k\\)."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-4",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#section-4",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "We will start with the homoskedasticity assumption since it helps set some fundamental intuition.\nThis extends to heteroskedasticity as well.\nBut the math of homoskedasticity is much more straightforward and easier to follow.\nSo here we will focus on homoskedasticity.\nImplementation in practice should be heteroskedastic"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#homoskedasticity-assumption",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#homoskedasticity-assumption",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Homoskedasticity assumption",
    "text": "Homoskedasticity assumption\n\n\nHaving an estimate is of no use without a measureof its precision.\nSimilar to SLR, we will make an assumption on the Variance of the error term \\(u_i\\) conditional on the independent variables \\(x_{1i}, x_{2i}, \\ldots, x_{ki}\\):\nMLR.5: Homoskedasticity: \\(Var(u_i|x_{1i}, x_{2i}, \\ldots, x_{ki}) = \\sigma^2\\)\n\nThis implies that \\(Var(u_i) = \\sigma^2\\)\n\nUsing the popoulation model \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_k x_{ki} + u_i\\), we can take conditional variance of both sides to get: \\[Var(y_i|x_{1i}, x_{2i}, \\ldots, x_{ki}) = Var(u_i|x_{1i}, x_{2i}, \\ldots, x_{ki}) = \\sigma^2\\]\nWhy do we get this? Recall the formula of a variance of sums of objects.\nAgain as before we do not know \\(\\sigma^2\\) but we can estimate it using the residuals similar to SLR.\nBut first lets look at the sampling variance of the OLS estimates"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#sampling-variance-of-ols-estimator",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#sampling-variance-of-ols-estimator",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Sampling variance of OLS estimator",
    "text": "Sampling variance of OLS estimator\n\n\n\nTheorem: Sampling variance of OLS estimator in MLR\n\n\nUnder assumptions MLR.1-MLR.5, the sampling variance of the OLS estimate on the \\(j^{th}\\) coefficient \\(\\hat{\\beta}_j\\) is given by: \\[Var(\\hat{\\beta}_j) = \\frac{\\sigma^2}{(1 - R_j^2)\\sum_{i=1}^n (x_{ji} - \\bar{x}_j)^2}\\] for \\(j = 0, 1, \\ldots, k\\). where:\n\n\n\\(\\sigma^2\\) is the variance of the error term \\(u_i\\) conditional on the independent variables\n\\(\\bar{x}_j\\) is the sample mean of \\(x_{ji}\\)\n\\(\\sum_{i=1}^n (x_{ji} - \\bar{x}_j)^2\\) is the total sample variance of \\(x_{ji}\\)\n\\(R_j^2\\) is the \\(R^2\\) from regressing \\(x_{ji}\\) on all other independent variables and an intercept.\n\n\n\n\n\n\nObserve how each component matters in the formula and why each of them important.\nLook for connections with MLR.3"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#the-role-of-r_j2",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#the-role-of-r_j2",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "The role of \\(R_j^2\\)",
    "text": "The role of \\(R_j^2\\)\n\n\n\\(R_j^2\\) is the \\(R^2\\) from regressing \\(x_{ji}\\) on all other independent variables and an intercept.\nWhat happens to \\(Var(\\hat{\\beta}_j)\\) as \\(R_j^2\\) approaches 1?\nWhat does it mean when \\(R_j^2\\) is very close to 1 versus equal to 1?\n\nMulticollinearity VS Perfect Collinearity\n\nDefinition: Multicollinearity arises when independent variables in a regression model are highly correlated, making it difficult to estimate the effect of each variable accurately.\n\n\nExample: Estimating the effect of different school expenditure categories (e.g., teacher salaries, materials, athletics) on student performance.\nChallenge:\n\nWealthier schools spend more across all categories, leading to high correlations among variables.\nDifficult to estimate the partial effect of one category due to lack of variation.\n\nSolution: Consider combining correlated variables into a single index."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#more-on-multicollinearity",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#more-on-multicollinearity",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "More on multicollinearity",
    "text": "More on multicollinearity\n\nConsider a 3 variable population model: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + u_i\\]\n\n\\(x_{2i}\\) and \\(x_{3i}\\) are highly correlated\n\\(x_{1i}\\) is uncorrelated with \\(x_{2i}\\) and \\(x_{3i}\\)\n\n\n\n\nThe OLS estimator will still be unbiased because MLR1-MLR4 are satisfied\nHowever, the variance of the OLS estimates of \\(\\beta_2\\) and \\(\\beta_3\\) will be very high\nThis is because the \\(R^2\\) from\n\nregressing \\(x_{2i}\\) on \\(x_{3i}\\) and \\(x_{1i}\\) will be very high\nregressing \\(x_{3i}\\) on \\(x_{2i}\\) and \\(x_{1i}\\) will be very high\n\nBut the var of \\(\\hat{\\beta}_1\\) will be unaffected. Why?\nObserve that \\(Var(\\hat{\\beta}_1) = \\frac{\\sigma^2}{(1 - R_1^2)\\sum_{i=1}^n (x_{1i} - \\bar{x}_1)^2}\\)\n\nwhat is \\(R_1^2\\) based on the information you have?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#example-final-exam-scores",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#example-final-exam-scores",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Example: Final Exam Scores",
    "text": "Example: Final Exam Scores\n\nScenario: Predicting final exam scores using:\n\nKey Variable: Number of classes attended.\nOther control Variables: Cumulative GPA, SAT score, and high school performance.\n\nConcern: Other control variables are highly correlated (multicollinear).\nA useful exercise is to look at the standard errors of the OLS estimates."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#completing-the-model",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#completing-the-model",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Completing the model",
    "text": "Completing the model\n\nNow thatw e have laid out the assumptions for unbiasedness, and homoskedasticity for precision\n\nWe are left to estimate the variance of the error term \\(\\sigma^2\\) to complete the model\n\nSimialr to SLR, we can estimate \\(\\sigma^2\\) using the residuals: \\[\\hat{\\sigma}^2 = \\frac{1}{n - k - 1} \\sum_{i=1}^n \\hat{u}_i^2\\]\nThe degrees of freedom is \\(n - k - 1\\) because we have \\(n\\) observations and \\(k+1\\) parameters to estimate\n\n\n\n\nTheorem:\n\n\nUnder assumptions MLR.1-MLR.5, \\(E(\\hat{\\sigma}^2) = \\sigma^2\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#gauss-markov-theorem",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#gauss-markov-theorem",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Gauss-Markov Theorem",
    "text": "Gauss-Markov Theorem\n\n\nThe Gauss-Markov Theorem is a key result in econometrics that states that under the assumptions MLR.1-MLR.5, the OLS estimator is the best linear unbiased estimator (BLUE) of the population parameters.\nBest: The OLS estimator has the smallest variance among all linear unbiased estimators.\nLinear: The OLS estimator is a linear function of the dependent variable.\nUnbiased: The OLS estimator is unbiased.\nThe OLS estimator is the most efficient estimator among all unbiased estimators."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#standard-errors-of-hatbeta_j",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#standard-errors-of-hatbeta_j",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Standard errors of \\(\\hat{\\beta}_j\\)",
    "text": "Standard errors of \\(\\hat{\\beta}_j\\)\n\n\nUnder homoskedasticity, the standard error of the OLS estimate \\(\\hat{\\beta}_j\\) is given by: \\[SE(\\hat{\\beta}_j) = \\sqrt{Var(\\hat{\\beta}_j)}\\]\nan estimate of the standard deviation of the sampling distribution of \\(\\hat{\\beta}_j\\).\na measure of the precision of the OLS estimate \\(\\hat{\\beta}_j\\).\nused to construct confidence intervals and conduct hypothesis tests.\nestimated using the formula: \\[SE(\\hat{\\beta}_j) = \\sqrt{\\frac{\\hat{\\sigma}^2}{(1 - R_j^2)\\sum_{i=1}^n (x_{ji} - \\bar{x}_j)^2}} = \\sqrt{\\frac{\\hat{\\sigma}^2}{(1 - R_j^2)\\sqrt{n} \\quad sd(x_j)}}\\]\nNotice the role of \\(R_j^2\\) and \\(n\\) in the formula."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#recall",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#recall",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Recall",
    "text": "Recall\n\nRecall the example we did in class with the wage data on educ and exper\nFor the true population model satisfying MLR1-MLR4: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + u_i\\] \nSuppose we omitted \\(x_{2i}\\) and only ran the simple regression of \\(y_i\\) on \\(x_{1i}\\): \\[\\tilde{y_i} = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 x_{1i}\\]\n\\(\\tilde{\\beta}_1\\) relates to \\(\\hat{\\beta}_1\\) via: \\[\\tilde{\\beta}_1 = \\hat{\\beta}_1 + \\hat{\\beta}_2 \\delta_1\\] where \\(\\delta_1\\) is the slope from the regression of \\(x_{2i}\\) on \\(x_{1i}\\) from estimating: \\[x_{2i} = \\delta_0 + \\delta_1 x_{1i} + \\epsilon\\]\nSo \\(E(\\tilde{\\beta}_1) = \\beta_1 + \\beta_2 \\delta_1\\). Bias = \\(E(\\tilde{\\beta}_1) - \\beta_1 = \\beta_2 \\delta_1\\)\nLet us generalize this to a three variable case"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#omitted-variable-bias",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#omitted-variable-bias",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Omitted variable bias",
    "text": "Omitted variable bias\nFor the true population modelsatisfying MLR1-MLR4: \\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + u_i\\] - Suppose \\(x_{3i}\\) and \\(x_{2i}\\) are uncorrelated but \\(x_{3i}\\) and \\(x_{1i}\\) are correlated - Suppose we omitted \\(x_{3i}\\) and only ran the regression of \\(y_i\\) on \\(x_{1i}\\) and \\(x_{2i}\\): \\[\\tilde{y_i} = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 x_{1i} + \\tilde{\\beta}_2 x_{2i}\\]\n\n\nMight be tempting to think that \\(\\tilde{\\beta}_2\\) is unbiased and only \\(\\tilde{\\beta}_1\\) is biased\nBut both will be biased because of the induced correlation between \\(x_{1i}\\) and \\(x_{2i}\\) when \\(x_{3i}\\) is omitted\n\\(\\tilde{\\beta}_2\\) is unbiased only when\\(x_{1i}\\) and \\(x_{2i}\\) are uncorrelated. Then we can show that: \\[\\mathrm{E}\\left(\\widetilde{\\beta}_1\\right)=\\beta_1+\\beta_3 \\frac{\\sum_{i=1}^n\\left(x_{i 1}-\\bar{x}_1\\right) (x_{i 3} - \\bar{x_3})}{\\sum_{i=1}^n\\left(x_{i 1}-\\bar{x}_1\\right)^2}\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#ability-bias-example",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#ability-bias-example",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Ability bias example",
    "text": "Ability bias example\n\nThe true population model is given by: \\[log(wage_i) = \\beta_0 + \\beta_1 educ_i + \\beta_2 exper_i + \\beta_3 ability_i + u_i\\]\nSuppose \\(exper_i\\) and \\(ability_i\\) are uncorrelated (probably not true)\n\n\n\nSuppose we omitted the variable \\(ability_i\\) and only ran the regression of \\(log(wage_i)\\) on \\(educ_i\\) and \\(exper_i\\): \\[\\tilde{log(wage_i)} = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 educ_i + \\tilde{\\beta}_2 exper_i\\]\nBoth \\(\\tilde{\\beta}_1\\) and \\(\\tilde{\\beta}_2\\) will be biased\n\nEven if we assume suppose \\(exper_i\\) and \\(ability_i\\) are uncorrelated\n\nThe bias in \\(\\tilde{\\beta}_2\\) is due to the induced correlation between \\(educ_i\\) and \\(exper_i\\) when \\(ability_i\\) is omitted because \\(educ_i\\) and \\(ability_i\\) are correlated\nConfounding the effect of ability. Direction of the bias?\nSo imagine the further complexity if we assumed all variables were pairwise correlated."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/04_mlr.html#variances-in-misspecified-models",
    "href": "teachingmaterials/UG_intro_metrics/04_mlr.html#variances-in-misspecified-models",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Variances in misspecified models",
    "text": "Variances in misspecified models\n\nWe saw what happens to bias. What happens to precision?\nTrue model: \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + u_i\\) and \\(x_{1i}\\) and \\(x_{2i}\\) are correlated\nEstimate two models:\n\nModel 1: \\(\\hat{y_i} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1i} + \\hat{\\beta}_2 x_{2i}\\)\nModel 2: \\(\\tilde{y_i} = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 x_{1i}\\)\n\n\n\n\nWhen \\(\\beta_2 \\neq 0, \\widetilde{\\beta}_1\\) is biased, \\(\\hat{\\beta}_1\\) is unbiased, and \\(\\operatorname{Var}\\left(\\widetilde{\\beta}_1\\right)&lt;\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)\\)\nWhen \\(\\beta_2=0, \\widetilde{\\beta}_1\\) and \\(\\hat{\\beta}_1\\) are both unbiased, and \\(\\operatorname{Var}\\left(\\widetilde{\\beta}_1\\right)&lt;\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)\\)\n\n\nThis is because (recall the formula for the variance of the OLS estimator):\n\n\\(\\operatorname{Var}\\left(\\hat{\\beta}_1\\right)=\\sigma^2 /\\left[\\operatorname{SST}_1\\left(1-R_1^2\\right)\\right]\\)\n\\(\\operatorname{Var}\\left(\\widetilde{\\beta}_1\\right)=\\sigma^2 /\\left[\\operatorname{SST}_1\\right]\\)\n\nTake away: Including irrelevant variables in the model ‚Äúmay‚Äù not affect the unbiasedness of the OLS estimator, but it will affect the precision of the estimates."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#prerequisites",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#prerequisites",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nR and RStudio is installed\nUpdate R packages regularly\nRequired packages for today:\n\nBase R (primary focus)\n\n\nToday‚Äôs Agenda\n\nLive coding\nFocus on typing commands yourself\nAvoid copy-paste to build muscle memory\n\n\n\n\n\n\n\nNote\n\n\nThis is not a course in R!"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#rstudio-interface",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#rstudio-interface",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "RStudio Interface",
    "text": "RStudio Interface\n\nRStudio Interface\nExplain each pane‚Äôs function: - Source editor (top left) - Console (bottom left) - Environment (top right) - Files/Plots/Help (bottom right)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#basic-arithmetic",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#basic-arithmetic",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Basic Arithmetic",
    "text": "Basic Arithmetic\n\n# Addition\n1 + 2\n\n# Subtraction\n6 - 7\n\n# Division\n5 / 2\n\n# Exponentiation\n2^3\n\n# Integer division\n100 %/% 60  # How many whole hours in 100 minutes?\n\n# Modulo (remainder)\n100 %% 60   # How many minutes are left over?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#logic-operations",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#logic-operations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Logic Operations",
    "text": "Logic Operations\n\n\n\n# Basic comparisons\n1 &gt; 2\n1 &gt; 2 & 1 &gt; 0.5  # AND\n1 &gt; 2 | 1 &gt; 0.5  # OR\n\n# Truth testing\nisTRUE(1 &lt; 2)\n\n\nImportant Operators:\n\n&gt;, &lt;: Greater/less than\n&gt;=, &lt;=: Greater/less equal\n==: Equality test\n!=: Not equal\n&: AND\n|: OR"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#logic-important-details",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#logic-important-details",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Logic: Important Details",
    "text": "Logic: Important Details\n\n\nOrder of Precedence:\n\nLogical operators (&gt;, &lt;, etc.)\nBoolean operators (&, |)\n\n\n# Be explicit!\n1 &gt; 0.5 & 1 &gt; 2\n\n# Not\n1 &gt; 0.5 & 2  # Can be confusing\n\n\nFloating Point Numbers:\n\n# This returns FALSE!\n0.1 + 0.2 == 0.3\n\n# Use instead:\nall.equal(0.1 + 0.2, 0.3)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#value-matching",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#value-matching",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Value Matching",
    "text": "Value Matching\n\n# Check if value is in a vector\n4 %in% 1:10\n\n# Create a \"not in\" operator\n`%ni%` = Negate(`%in%`)\n4 %ni% 5:10\n\n\nThe backticks (`) help specify functions"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#everything-is-an-object",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#everything-is-an-object",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Everything is an Object",
    "text": "Everything is an Object\nCommon object types in R:\n\nVectors\nMatrices\nData frames\nLists\nFunctions\n\n\n# Create different objects\nvec &lt;- 1:5\nmat &lt;- matrix(1:9, nrow=3)\ndf &lt;- data.frame(x=1:3, y=4:6)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#objects-have-classes",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#objects-have-classes",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Objects Have Classes",
    "text": "Objects Have Classes\n\n\n\n# Create data frame\nd &lt;- data.frame(\n  x = 1:2,\n  y = 3:4\n)\n\n# Check properties\nclass(d)\ntypeof(d)\nstr(d)\n\n\nUnderstanding Objects:\n\nclass(): Object‚Äôs class\ntypeof(): Object‚Äôs type\nstr(): Object‚Äôs structure\nView(): Interactive viewing"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#global-environment",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#global-environment",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Global Environment",
    "text": "Global Environment\n\n\n\n# Create data frame\nd &lt;- data.frame(\n  x = 1:2,\n  y = 3:4\n)\n\n# This fails:\nlm(y ~ x)\n\n# This works:\nlm(y ~ x, data = d)\n\n\nKey Points:\n\nObjects live in the global environment\nMust specify data source\nDifferent from Stata‚Äôs single-dataset approach\nMultiple objects can exist simultaneously"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#assignment-operators",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#assignment-operators",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Assignment Operators",
    "text": "Assignment Operators\n\n\nUsing Arrow (&lt;-):\n\n# Standard assignment\na &lt;- 10 + 5\n\n# Right assignment\n10 + 5 -&gt; a\n\nEmbodies the idea of assigned to\n\nUsing Equals (=):\n\n# Alternative assignment\nb = 10 + 10\n\n# Must be on left with =\n# This won't work:\n# 10 + 10 = b\n\n\nAssignment Choice\n\nMost R users prefer &lt;- for assignment\n= has specific role in function evaluation\nPersonal choice, but be consistent\n= is quicker to type and familiar from other languages"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#variables-and-assignment",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#variables-and-assignment",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Variables and Assignment",
    "text": "Variables and Assignment\n\n# Variable assignment\nx &lt;- 1\ny &lt;- \"roses\"\nz &lt;- function(x) { sqrt(x) }\n\n# Using variables\nz(9)\n\n[1] 3"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#control-flow-ifelse",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#control-flow-ifelse",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Control Flow: if/else",
    "text": "Control Flow: if/else\n\nx &lt;- 5\ny &lt;- 3\n\nif (x &gt; y) {\n  print(\"x is larger than y\")\n} else {\n  print(\"x is less than or equal to y\")\n}\n\n[1] \"x is larger than y\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#loops",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#loops",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Loops",
    "text": "Loops\n\n# For loop\nfor(i in 1:5) {\n  print(paste(\"Iteration\", i))\n}\n\n[1] \"Iteration 1\"\n[1] \"Iteration 2\"\n[1] \"Iteration 3\"\n[1] \"Iteration 4\"\n[1] \"Iteration 5\"\n\n# Loop with conditions\nfor(fruit in c(\"mangos\",\"bananas\",\"apples\")) {\n  print(paste(\"I love\", fruit))\n}\n\n[1] \"I love mangos\"\n[1] \"I love bananas\"\n[1] \"I love apples\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#functions",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#functions",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Functions",
    "text": "Functions\n\n# Define function\ngreet &lt;- function(name = \"Lord Vader\") {\n  paste(\"Hello,\", name)\n}\n\n# Use function\ngreet()\n\n[1] \"Hello, Lord Vader\"\n\ngreet(\"Luke\")\n\n[1] \"Hello, Luke\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#creating-variables",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#creating-variables",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Creating Variables",
    "text": "Creating Variables\n\n# Price of a good\nprice &lt;- 50\n\n# Quantity sold\nquantity &lt;- 10\n\n# Calculate revenue\nrevenue &lt;- price * quantity\nrevenue\n\n[1] 500"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#multiple-assignments",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#multiple-assignments",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Multiple Assignments",
    "text": "Multiple Assignments\n\n# Assign same value to multiple variables\nx &lt;- y &lt;- 5\n\n# Check values\nx\n\n[1] 5\n\ny\n\n[1] 5"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#numeric-data",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#numeric-data",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Numeric Data",
    "text": "Numeric Data\n\n# GDP growth rate\ngdp_growth &lt;- 2.5\nclass(gdp_growth)\n\n[1] \"numeric\"\n\n# Population (whole number)\npopulation &lt;- 1000L  # L makes it integer\nclass(population)\n\n[1] \"integer\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#text-and-logical-data",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#text-and-logical-data",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Text and Logical Data",
    "text": "Text and Logical Data\n\n# Country name (character/string)\ncountry &lt;- \"United States\"\nclass(country)\n\n[1] \"character\"\n\n# Logical (TRUE/FALSE)\nis_developed &lt;- TRUE\nclass(is_developed)\n\n[1] \"logical\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#reserved-words",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#reserved-words",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Reserved Words",
    "text": "Reserved Words\n\n\nStrictly Reserved:\n\nif\nelse\nwhile\nfunction\nfor\nTRUE/FALSE\nNULL\nInf\nNA\n\n\nSemi-Reserved:\n\nc() (concatenate)\npi\nMany function names\n\n\n# Don't do this!\npi &lt;- 2\nc &lt;- 4"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#namespace-conflicts",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#namespace-conflicts",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Namespace Conflicts",
    "text": "Namespace Conflicts\n\nlibrary(dplyr)\n\n# Shows conflicts:\n# filter masked from 'package:stats'\n# lag masked from 'package:stats'\n\nTwo solutions:\n\nUse package::function()\n\n\nstats::filter(1:10, rep(1, 2))\n\n\nAssign permanently\n\n\nfilter &lt;- stats::filter"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#using-square-brackets",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#using-square-brackets",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Using Square Brackets",
    "text": "Using Square Brackets\n\n\nBasic Indexing:\n\n# Vector indexing\na &lt;- 1:10\na[4]        # 4th element\na[c(4, 6)]  # 4th and 6th\n\n# Matrix/dataframe\nd[1, 1]     # First row & column\n\n\nList Indexing:\n\nmy_list &lt;- list(\n  a = \"hello\",\n  b = 1:3\n)\n\nmy_list[[1]]     # First element\nmy_list[[2]][3]  # Third item of second element"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#using-dollar-sign",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#using-dollar-sign",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Using Dollar Sign",
    "text": "Using Dollar Sign\n\n# List example\nmy_list$a           # Access 'a' element\nmy_list$b[3]        # Third item of 'b'\n\n# Data frame\nstarwars$name[1]    # First name\n\n\n$ provides direct access to named elements"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#removing-objects",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#removing-objects",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Removing Objects",
    "text": "Removing Objects\n\n# Remove specific objects\nrm(a, b)\n\n# Remove all objects (not recommended)\nrm(list = ls())\n\n# Detach package\ndetach(package:dplyr)\n\n# Clear plots\ndev.off()\n\n\n\n\n\n\n\nTip\n\n\nBetter to restart R session than use rm(list = ls())"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#overview-of-data-structures",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#overview-of-data-structures",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Overview of Data Structures",
    "text": "Overview of Data Structures\nR has several basic data structures:\n\n\n\nDimension\nHomogeneous\nHeterogeneous\n\n\n\n\n1\nVector\nList\n\n\n2\nMatrix\nData Frame\n\n\n3+\nArray\nnested Lists"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vectors",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vectors",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Vectors",
    "text": "Vectors\nVectors are containers for objects of identical type:\n\n# Create vectors with c()\nx &lt;- c(1, 3, 5, 7, 8, 9)\nprint(x)\n\n[1] 1 3 5 7 8 9\n\n# Create sequence\ny &lt;- 1:10\nprint(y)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# Repeat values\nrep(\"A\", times = 5)\n\n[1] \"A\" \"A\" \"A\" \"A\" \"A\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vector-operations",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vector-operations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Vector Operations",
    "text": "Vector Operations\n\n# Subsetting vectors\nx &lt;- c(1, 3, 5, 7, 8, 9)\nx[1]      # First element\n\n[1] 1\n\nx[1:3]    # First three elements\n\n[1] 1 3 5\n\nx[c(1,3,4)] # Selected elements\n\n[1] 1 5 7"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vector-logic",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#vector-logic",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Vector Logic",
    "text": "Vector Logic\n\nx &lt;- c(1, 3, 5, 7, 8, 9)\n# Logical operations\nx &gt; 3\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\nx[x &gt; 3]  # Subsetting with logic\n\n[1] 5 7 8 9\n\nsum(x &gt; 3) # Count values &gt; 3\n\n[1] 4"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#matrices",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#matrices",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Matrices",
    "text": "Matrices\nTwo-dimensional arrays with same data type:\n\n# Create matrix\nX &lt;- matrix(1:9, nrow = 3, ncol = 3)\nprint(X)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n# Matrix by rows\nY &lt;- matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE)\nprint(Y)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#matrix-operations",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#matrix-operations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Matrix Operations",
    "text": "Matrix Operations\n\n# Matrix arithmetic\nX + Y  # Element-wise addition\n\n     [,1] [,2] [,3]\n[1,]    2    6   10\n[2,]    6   10   14\n[3,]   10   14   18\n\nX * Y  # Element-wise multiplication\n\n     [,1] [,2] [,3]\n[1,]    1    8   21\n[2,]    8   25   48\n[3,]   21   48   81\n\nX %*% Y  # Matrix multiplication\n\n     [,1] [,2] [,3]\n[1,]   66   78   90\n[2,]   78   93  108\n[3,]   90  108  126\n\n# Subsetting\nX[1, 2]  # Element at row 1, column 2\n\n[1] 4\n\nX[1, ]   # First row\n\n[1] 1 4 7\n\nX[, 1]   # First column\n\n[1] 1 2 3"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#creating-lists",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#creating-lists",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Creating Lists",
    "text": "Creating Lists\nLists can contain elements of different types:\n\n# Create a list\nex_list &lt;- list(\n  a = c(1, 2, 3, 4),\n  b = TRUE,\n  c = \"Hello!\",\n  d = matrix(1:4, 2, 2)\n)\nprint(ex_list)\n\n$a\n[1] 1 2 3 4\n\n$b\n[1] TRUE\n\n$c\n[1] \"Hello!\"\n\n$d\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#list-operations",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#list-operations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "List Operations",
    "text": "List Operations\n\n# Access list elements\nex_list$a  # Using $\n\n[1] 1 2 3 4\n\nex_list[[1]]  # Using [[]]\n\n[1] 1 2 3 4\n\nex_list[\"a\"]  # Using []\n\n$a\n[1] 1 2 3 4\n\n# Add new elements\nex_list$e &lt;- \"New element\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#installing-packages",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#installing-packages",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Installing Packages",
    "text": "Installing Packages\n\n# Install a package\ninstall.packages(\"tidyverse\")\n\n# Load the package\nlibrary(tidyverse)\n\n\n\n\n\n\n\nNote\n\n\nYou only need to install a package once, but you need to load it each session"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#getting-help",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#getting-help",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Getting Help",
    "text": "Getting Help\n\n\nBasic Help:\n\n# Full help\nhelp(plot)\n\n# Shorthand\n?plot\n\n# Examples\nexample(plot)\n\n\nPackage Help:\n\n# Package vignettes\nvignette(\"dplyr\")\n\n# List all vignettes\nvignette(all = FALSE)\n\n# Package demos\ndemo(package = \"graphics\")"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#introduction-to-data-frames",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#introduction-to-data-frames",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Introduction to Data Frames",
    "text": "Introduction to Data Frames\nData frames are table-like structures:\n\n# Create a data frame\ndf &lt;- data.frame(\n  id = 1:3,\n  name = c(\"John\", \"Jane\", \"Bob\"),\n  score = c(85, 92, 78)\n)\nprint(df)\n\n  id name score\n1  1 John    85\n2  2 Jane    92\n3  3  Bob    78"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#data-frame-operations",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#data-frame-operations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Data Frame Operations",
    "text": "Data Frame Operations\n\n# Basic operations\nnames(df)  # Column names\n\n[1] \"id\"    \"name\"  \"score\"\n\nnrow(df)   # Number of rows\n\n[1] 3\n\nncol(df)   # Number of columns\n\n[1] 3\n\n# Access columns\ndf$name\n\n[1] \"John\" \"Jane\" \"Bob\" \n\ndf[[\"score\"]]\n\n[1] 85 92 78"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#subsetting-data-frames",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#subsetting-data-frames",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Subsetting Data Frames",
    "text": "Subsetting Data Frames\n\n# Subset rows\ndf[df$score &gt; 80, ]\n\n  id name score\n1  1 John    85\n2  2 Jane    92\n\n# Subset columns\ndf[, c(\"name\", \"score\")]\n\n  name score\n1 John    85\n2 Jane    92\n3  Bob    78\n\n# Using subset()\nsubset(df, score &gt; 80, select = c(\"name\", \"score\"))\n\n  name score\n1 John    85\n2 Jane    92"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#additional-resources",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#additional-resources",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nR Documentation: r-project.org\nRStudio Cheatsheets: rstudio.com/resources/cheatsheets\nAdvanced R by Hadley Wickham: adv-r.hadley.nz\nStack Overflow R Tag: stackoverflow.com/questions/tagged/r"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/01_introRv2.html#practice-on-your-own",
    "href": "teachingmaterials/UG_intro_metrics/01_introRv2.html#practice-on-your-own",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Practice on your own",
    "text": "Practice on your own\n\nCreate vectors using different methods (c(), :, seq(), rep())\nPractice logical operations and understand operator precedence\nCreate a list with different types of elements and practice indexing\nLoad a package and resolve a namespace conflict\nCreate and remove objects from your environment"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Moshi Alam",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "links.html#software-engineering-for-economists",
    "href": "links.html#software-engineering-for-economists",
    "title": "Moshi Alam",
    "section": "Software engineering for economists",
    "text": "Software engineering for economists\n\nVersion control: GitHub and Git\n\nfrom quantecon\nfrom Tilburg Science\n\n\n\nUnit testing\n\nfrom quantecon\n\n\n\nContinuous integration"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Moshi Alam",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\nHi!üòä I am a labor economist. My research fields are Labor Economics, Public Economics and Applied Econometrics. In my work, I use both design-based (reduced form) and model-based (structural) methods, and at times I design surveys to collect data with identifying variation. I received my PhD in Economics, from the University of Wisconsin-Madison.\n\n\n\n\n\n\n\n\n\n Working Papers\n\n\n\n1. Employee-Side Discrimination: Beliefs and Preferences\n\n\nwith Mehreen Mookerjee and Sanket Roy\n\n\nR&R at Quantitative Economics PhD JMP \n\n\nAbstract Online Appendix A-C   BibTeX \n\n\n\n\n2. The Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation\n\n\nwith Monica Agarwal\n\n\nR&R at Journal of Human Resources \n\n\nAbstract SSRN   BibTeX \n\n\n\n\n3. Labor Market Consequences of Pay-Equity Laws\n\n\nwith Steven Lehrer and Nuno Souso Pereira\n\n\nUnder Review  Post-doc JMP\n\n\nAbstract   BibTeX \n\n\n\n\n4. Optimal Place‚ÄëBased Transfers using Measured Geographic Variation in the Marginal Utility of Income\n\n\nwith Morris Davis and Jesse Gregory\n\n\nDraft Coming Soon\n\n\n\n\n\n Publications\n\n\n\nIncreases in shared custody after divorce in the United States\n\n\nwith Daniel Meyer and Marcia Carlson\n\n\n Demographic Research 46(38) 2022: 1137-1162 ‚≠ê Editor‚Äôs Choice Article\n\n\nAbstract Replication   BibTeX \n\n\n\n\n\n Research in Progress\n\n\n\nSpatial Inequality and School Choice Mechanisms\n\n\nwith Monica Agarwal, Chao Fu, and YingHua He\n\n\n\n\nLabor Market Inequality and Collective Bargaining\n\n\nwith Steven Lehrer and Nuno Souso Pereira\n\n\n\n\n\n\nDormant Papers\n\n\n Click to view dormant papers\n\n\n\n\nIdentification in Models of Discrimination\n\n\n[Subsumed in PhD job market paper ‚ÄúEmployee Side Discrimination: Beliefs and Preferences‚Äù]\n\n\n\n\n\n\n\n\n\nCode\nmicro = require(\"micromodal@0.4.10\");\n\nmicro.init({\n  awaitOpenAnimation: true,\n  awaitCloseAnimation: true\n});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncreases in shared custody after divorce in the United States\nwith Daniel Meyer and Marcia Carlson\n\n\nThis paper provides new evidence on the time trend in shared physical custody after divorce in the U.S., using eight waves of data from the Current Population Survey - Child Support Supplement. We find that the likelihood of shared custody more than doubled between divorces that occurred before 1985 and those in 2010-2014, from 12% to 28%. We show that non-Hispanic Whites and those who are more socioeconomically advantaged are more likely to have shared custody. Using more formal methods we show that the increase cannot be explained by changes in the characteristics of those divorcing; instead, we infer that this is the result of changing norms and policies that favor shared custody. Finally, this paper complements previous analyses using court record data from Wisconsin and shows that while the rate of shared custody in Wisconsin is higher than the national rate, a large increase over time has occurred in the nation as well as in Wisconsin. These changing patterns have important implications for children‚Äôs living arrangements and for the parental investments that children receive after their parents‚Äô divorce.\n\n\n\n\n\n\n\n\n\n\n\nLabor Market Consequences of Pay-Equity Laws\nwith Steven Lehrer and Nuno Souso Pereira\n\n\nLimited policy variation, data constraints in defining ‚Äòequal work‚Äô, and compliance issues have prevented rigorous causal analysis of pay equity laws. We address these challenges using Portugal‚Äôs 2018 legislation, which penalized firms with over 250 employees for gender wage gaps exceeding 5%. Using administrative data that links employees to industry-defined job titles within firms, we analyze its impact both within and between genders using an event study design. We find the law achieved its intended effects in some areas while generating unintended consequences in others. Jobs with initial gaps exceeding 5% saw a 9% reduction, mainly through slower male wage growth. A small fraction of jobs with negative gaps saw reduced female wage growth, closing the gap by half. However, gaps in jobs initially between 0-5% unexpectedly widened by 21% due to slower female wage growth. These unintended consequences are more pronounced in male-dominated industries and cannot be explained by productivity differences. Further, we find that firms did not change their size to evade the law, nor did it impact job gender composition, or hours worked. Our findings reveal both intended and unintended consequences of pay equity laws implemented with uniform regulatory targets: while the 5% target effectively reduced large disparities, it inadvertently widened gaps below the threshold as firms, with enforcement rules now clarified, strategically adjusted wages but not employment, offering crucial insights for policy design in achieving ‚Äúequal pay for equal work‚Äù.\n\n\n\n\n\n\n\n\n\n\n\nEmployee-Side Discrimination: Beliefs and Preferences\nwith Mehreen Mookerjee and Sanket Roy\n\n\nWorkers‚Äô preferences and beliefs shape labor market outcomes, yet remain understudied. We develop a theory-driven novel identification strategy for information experiments that separates preferences from beliefs. We apply this to provide the first evidence on the distribution of workers‚Äô preferences on manager gender and their beliefs on managers‚Äô mentoring ability. In the absence of information on manager mentoring ability, workers are indifferent to manager gender. However, upon receiving information on manager mentorship ability, workers prefer to work for female managers‚Äîwilling to forgo 1.3‚Äì2.2% of average annual wages. Hence, absent additional information, workers believe female managers are worse mentors (1.6% wage equivalent). Non-parametric estimates of the distributions reveal that 75% prefer female managers with mentoring information, and 67% believe male managers are better mentors absent information. Machine learning algorithms show that individuals with higher education are less likely to hold such beliefs. These beliefs are primarily driven by perceptions that women are less competent. Evidence suggests these beliefs are likely biased, highlighting scope for information-based policy interventions that could reduce suboptimal matching and gender gaps in management levels. Our identification-driven design provides a general framework for information experiments to study beliefs.\n\n\n\n\n\n\n\n\n\n\n\nThe Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation\nwith Monica Agarwal\n\n\nExisting research shows that women benefit more from private toilets, but misperceptions about the net benefits from toilets and lack of women‚Äôs decision-making power can hinder toilet adoption by households. In this paper, we explore a novel link between household sanitation and policies that empower women. We show that a policy aimed at improving women‚Äôs property inheritance rights in India led to an increase in toilet adoption in the households of treated cohorts by at least 10%. Prior literature shows mixed evidence on whether the policy increased women‚Äôs inheritance, but shows that the policy had significant indirect effects, such as improving women‚Äôs education. To generate empirical tests for the mechanisms driving our main results, we build a discrete choice model with idiosyncratic household preference shocks that produces policy-relevant complementarity between women‚Äôs education and decision-making power in adoption of a household public good valued more by women. Using a heterogeneity-robust event-study design, we find that, consistent with our model, the increase in toilet adoption is concentrated in states where the policy boosted women‚Äôs education‚Äîplausibly reducing misperceptions about the benefits of toilets‚Äîand increased women‚Äôs decision-making power. Our findings highlight that policies empowering women can yield unintended benefits beyond their original scope‚Äîwhile we document improvements in toilet coverage, the implications extend to other household investments where women‚Äôs preferences are stronger, but various frictions limit adoption."
  },
  {
    "objectID": "blogs/versioncontrol.html",
    "href": "blogs/versioncontrol.html",
    "title": "Version control",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\nDisclaimer: There are many amazing resources all over the internet on how to version control. This by no means is exhaustive, in fact what I have shared below is the minimal setup that works for me."
  },
  {
    "objectID": "blogs/versioncontrol.html#step-1-initialize-git-in-your-project",
    "href": "blogs/versioncontrol.html#step-1-initialize-git-in-your-project",
    "title": "Version control",
    "section": "Step 1: Initialize Git in Your Project",
    "text": "Step 1: Initialize Git in Your Project\nNavigate to your project directory and initialize a Git repository:\ncd path/to/MyCoolProject/code\ngit init\nThis creates a new Git repository in the MyCoolProject/code directory."
  },
  {
    "objectID": "blogs/versioncontrol.html#step-2-create-a-.gitignore-file-in-code",
    "href": "blogs/versioncontrol.html#step-2-create-a-.gitignore-file-in-code",
    "title": "Version control",
    "section": "Step 2: Create a .gitignore File in /code",
    "text": "Step 2: Create a .gitignore File in /code\nTo exclude certain files from being tracked by Git, create a .gitignore file in the /code directory. Suppose you want to ignore all files with extension .bak and the folder called temp.\n# Ignore temporary files\n*.bak\n/temp/\nAlthough you can create multiple .gitignore within subfolders. I typically prefer having a single gitignore in the main directory and then use relative paths to ensure which files and folders I want git to ignore."
  },
  {
    "objectID": "blogs/versioncontrol.html#step-3-connect-to-a-remote-repository-github",
    "href": "blogs/versioncontrol.html#step-3-connect-to-a-remote-repository-github",
    "title": "Version control",
    "section": "Step 3: Connect to a Remote Repository (GitHub)",
    "text": "Step 3: Connect to a Remote Repository (GitHub)\nI host my version controlled files on GitHub.\n\nCreate a new repository on GitHub\nAdd the remote URL to your local Git repository:\n\ngit remote add origin https://github.com/YourUsername/MyCoolProject-code.git"
  },
  {
    "objectID": "blogs/versioncontrol.html#step-4-stage-and-commit-your-files",
    "href": "blogs/versioncontrol.html#step-4-stage-and-commit-your-files",
    "title": "Version control",
    "section": "Step 4: Stage and Commit Your Files",
    "text": "Step 4: Stage and Commit Your Files\n\n\n\n\n\n\nConfirm working branch\n\n\n\n\n\nEnsure you are on the same branch as your primary branch in your repo. In my first attempt my primary branch in the repo was main while that on VSCode was master. The solution to this is a careful force merge of the two branches:\ngit checkout main\ngit merge master --allow-unrelated-histories\n\n\n\nAfter setting up the remote repository, you can stage and commit your files. Itypically do this on the fly using VSCode default GUI.\n\nClick on the Source Control icon in the left sidebar in VSCode.\nYou should see all your files listed as untracked. Click on the + icon next to each file to stage them, or click + next to Changes to stage all files.\nEnter a commit message in the text box at the top.\nClick on the checkmark icon to commit your staged changes.\nPush your changes to the remote repository."
  },
  {
    "objectID": "blogs/versioncontrol.html#step-5-track-changes-and-collaborate",
    "href": "blogs/versioncontrol.html#step-5-track-changes-and-collaborate",
    "title": "Version control",
    "section": "Step 5: Track Changes and Collaborate",
    "text": "Step 5: Track Changes and Collaborate\nNow that your /code folder is under version control and hosted on GitHub, you can track changes, create branches, merge changes, and collaborate with others. VSCode provides a powerful interface for managing Git repositories, making it easier to review changes and resolve conflicts."
  },
  {
    "objectID": "blogs/namingconventions.html",
    "href": "blogs/namingconventions.html",
    "title": "Naming conventions",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\nChoosing clear, concise, and meaningful names for variables, functions, files, etc., is challenging. Good names improve code readability and maintainability, but finding the right name can be surprisingly difficult, especially when your project folder is overflowing with files and subfolders. Good names can help users of your package or code replication kit.\nI will describe here a file naming convention that works for me. Sometimes this might go against styling guides of the language used although I try as much as possible to avoid this. This may not necessarily fit everyone‚Äôs requirement as coding and project management styles vary widely. I will not cover how I name folders as that is more about project management."
  },
  {
    "objectID": "blogs/namingconventions.html#footnotes",
    "href": "blogs/namingconventions.html#footnotes",
    "title": "Naming conventions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis quote is widely attributed to Phil Karlton, a software engineer known for his work at Netscape.‚Ü©Ô∏é"
  },
  {
    "objectID": "morepages/phdstructural.html",
    "href": "morepages/phdstructural.html",
    "title": "PhD: Structural + Computation",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "morepages/phdstructural.html#course-description",
    "href": "morepages/phdstructural.html#course-description",
    "title": "PhD: Structural + Computation",
    "section": "Course Description",
    "text": "Course Description\nTHis si the second part of a two-part sequence of Applied ecopnometrics at the PhD level. Here I cover structural models and econometric methods with a focus on some types of labor and public economics problems. Having a comprehensive course on structural models is nearly impossible since structural work fine tune the model to the specific theory and context. The key lies in identification, which can ultimatley help us in doing counterfactuals. Hence, my emphasis will be mostly on identification, and primarily with discrete choice models (both static and dynamic) using estimation methods like MLE, GMM, SMM, and primarily indirect inference. I will cover some numerical optimization methods like gradient-based, derivative-free methods but mostly Nelder-Mead simplex algorithm.\nI do not find the discussions of whether structural models are better than design-based (reduced form) methods very constructive and hence will not engage in them. However, I will list some papers that discuss these. I like both, and have found both helpful in my work. In my view, both approaches have their own strengths, and it is cool to leverage best of both worlds.\nNo textbook as such‚Äîits mostly papers, but I found Kenneth Train‚Äôs Discrete Choice Methods with Simulation very helpful when I was learning discrete choice models for the first time. Depending on time I will also talk about some of my experience in improving computational efficiency in julia, and discuss some of the workflows that have worked for me."
  },
  {
    "objectID": "morepages/phdstructural.html#assessment",
    "href": "morepages/phdstructural.html#assessment",
    "title": "PhD: Structural + Computation",
    "section": "Assessment",
    "text": "Assessment\n\nProblem Sets ‚Äî 80%: Four problem sets + presentations. These are to be completed in groups of two.\n\nStudents can use their programming language of choice. I recommend julia, because of its computational advantages. However, R or Python are also fine.\nStudents are expected to compile their assignments using LaTeX. The final submission will involve both code and results in a single PDF with all tables properly formatted, variables properly labeled, and figures and tables with complete footnotes as if they are submitting the work to a journal.\nI will also assign students topics for presentations/referee reports.\n\nClass attendance and participation ‚Äî 20%"
  },
  {
    "objectID": "morepages/phdstructural.html#readings",
    "href": "morepages/phdstructural.html#readings",
    "title": "PhD: Structural + Computation",
    "section": "Readings",
    "text": "Readings\nThe readings are in not a particular order, although I will talk about identification in general first and then how is strucutral (model-based) approach different from reduced form (design-based) approach. Things that are not in particular order maybe specific topics & estimation routines and papers applying them.\n\nIdentification\n\nHeckman, J.J. and Vytlacil, E.J. (2007a). ‚ÄúEconometric Evaluation of Social Programs, Part I: Causal Models, Structural Models and Econometric Policy Evaluation.‚Äù Handbook of Econometrics, Vol. 6B, Ch. 70.\nHeckman, J.J. and Vytlacil, E.J. (2007b). ‚ÄúEconometric Evaluation of Social Programs, Part II: Using the Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments.‚Äù Handbook of Econometrics, Vol. 6B, Ch. 71.\nFrench, E. and Taber, C. (2011). ‚ÄúIdentification of Models of the Labor Market.‚Äù Handbook of Labor Economics, Vol. 4A, Ch. 6: 537-617.\nMatzkin, R.L. (2007). ‚ÄúNonparametric Identification.‚Äù Handbook of Econometrics, Vol. 6B, Ch. 73.\n\n\n\nStructural vs.¬†Reduced Form Methods\n\nLow, H. and Meghir, C. (2017). ‚ÄúThe Use of Structural Models in Econometrics.‚Äù Journal of Economic Perspectives, 31(2): 33-58.\nAngrist, J.D. and Pischke, J.S. (2010). ‚ÄúThe Credibility Revolution in Empirical Economics: How Better Research Design is Taking the Con out of Econometrics.‚Äù Journal of Economic Perspectives, 23(1): 69-90.\nKeane, M.P. (2010). ‚ÄúA Structural Perspective on the Experimentalist School of Econometrics.‚Äù Journal of Economic Perspectives\nGaliani, S. and Pantano, J. (2021). ‚ÄúStructural Models: Inception and Frontier.‚Äù NBER Working Paper 28698.\n\n\n\n\n\nStatic Discrete Choice Models\n\nMcFadden, D. (1973). ‚ÄúConditional Logit Analysis of Qualitative Choice Behavior.‚Äù In P. Zarembka (ed.), Frontiers in Econometrics. Academic Press.\nMcFadden, D. (1981). ‚ÄúEconometric Models of Probabilistic Choice.‚Äù In C. Manski & D. McFadden (eds.), Structural Analysis of Discrete Data.\n\n\n\n\n\nDynamic Discrete Choice Models\n\nRust, J. (1987). ‚ÄúOptimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher.‚Äù Econometrica, 55(5): 999-1033.\nHotz, V.J. and Miller, R.A. (1993). ‚ÄúConditional Choice Probabilities and the Estimation of Dynamic Models.‚Äù Review of Economic Studies, 60(3): 497-529.\n\n\n\n\nArcidiacono, P. and Miller, R.A. (2011). ‚ÄúConditional Choice Probabilities and the Estimation of Dynamic Models with Unobserved Heterogeneity.‚Äù Econometrica, 79(6): 1823-1867.\n\n\n\nEstimation Methods\n\nMLE, GMM, SMM, II\n\nRuud, P.A. (1991). ‚ÄúExtensions of Estimation Methods Using the EM Algorithm.‚Äù Journal of Econometrics, 49(3): 305-341.\n\n\n\nHansen, L.P. (1982). ‚ÄúLarge Sample Properties of Generalized Method of Moments Estimators.‚Äù Econometrica, 50(4): 1029-1054.\n\n\n\n\nMcFadden, D. (1989). ‚ÄúA Method of Simulated Moments for Estimation of Discrete Response Models without Numerical Integration.‚Äù Econometrica, 57(5): 995-1026.\n\n\n\n\nGourieroux, C., Monfort, A., and Renault, E. (1993). ‚ÄúIndirect Inference.‚Äù Journal of Applied Econometrics, 8(S1): S85-S118.\n\n\n\n\nApplications in Labor Economics\n\n\nStated Preferences\n\nWiswall, M. and Zafar, B. (2018). ‚ÄúPreference for the Workplace, Investment in Human Capital, and Gender.‚Äù Quarterly Journal of Economics, 133(1): 457-507.\nAlam, M.M.U., Mookerjee, M., and Roy, S. (2021) ‚ÄúEmployee-Side Discrimination: Beliefs and Preferences.‚Äù\nAdams, A., and Andrew, A. (2025) ‚ÄúRevealed Beliefs and the Marriage Market Return to Education‚Äú Quarterly Journal of Economics.\nDelavande, A. and Zafar, B. (2019). ‚ÄúUniversity Choice: The Role of Expected Earnings, Nonpecuniary Outcomes, and Financial Constraints.‚Äù Journal of Political Economy, 127(5): 2343-2393.\n\n\n\nMonopsony and Firm Effects\n\nCard, D., Cardoso, A.R., Heining, J., and Kline, P. (2018). ‚ÄúFirms and Labor Market Inequality: Evidence and Some Theory.‚Äù Journal of Labor Economics, 36(S1): S13-S70.\n\n\n\nLamadon, T., Mogstad, M., and Setzler, B. (2022). ‚ÄúImperfect Competition, Compensating Differentials, and Rent Sharing in the US Labor Market.‚Äù American Economic Review, 112(1): 169-212.\nKroft, K., Luo, Y., Mogstad, M., and Setzler, B. (2025). ‚ÄúImperfect Competition and Rents in Labor and Product Markets: The Case of the Construction Industry.‚Äù American Economic Review, 115(9): 2926-2969.\nKline, P. and Petkova, K. (2025). ‚ÄúLabor Market Monopsony: Fundamentals and Frontiers.‚Äù Handbook of Labor Economics, Vol. 6: 655-728.\n\n\n\nEmpirical school choice\n\nAgarwal, N., & Somaini, P. (2018). ‚ÄúDemand Analysis Using Strategic Reports: An Application to a School Choice Mechanism.‚Äù Econometrica\nKapor, A., Neilson, C., & Zimmerman, S. (2020). ‚ÄúHeterogeneous Beliefs and School Choice Mechanisms.‚Äù American Economic Review\n\n\n\nOptimal Policies, Career Decisions, Human Capital, Household consumption, Migration, Search\n\nAlam, Davis & Gregory (2025) ‚ÄúOptimal Place-Based Redistribution using Geographic Variation in the Marginal Utility of Income‚Äù\nFu & Gregory (2019) ‚ÄúEstimation of an Equilibrium Model with Externalities: Post-Disaster Neighborhood Rebuilding‚Äù Econometrica\nPostel-Vinay, F. and Robin, J.M. (2002). ‚ÄúEquilibrium Wage Dispersion with Worker and Employer Heterogeneity.‚Äù Econometrica, 70(6): 2295-2350.\nKeane, M.P. and Wolpin, K.I. (1997). ‚ÄúThe Career Decisions of Young Men.‚Äù Journal of Political Economy, 105(3): 473-522.\nEckstein, Z. and Wolpin, K.I. (1989). ‚ÄúDynamic Labour Force Participation of Married Women and Endogenous Work Experience.‚Äù Review of Economic Studies, 56(3): 375-390.\nTodd, P.E. and Wolpin, K.I. (2006). ‚ÄúAssessing the Impact of a School Subsidy Program in Mexico: Using a Social Experiment to Validate a Dynamic Behavioral Model of Child Schooling and Fertility.‚Äù American Economic Review, 96(5): 1384-1417.\nVoena, A. (2015). ‚ÄúYours, Mine, and Ours: Do Divorce Laws Affect the Intertemporal Behavior of Married Couples?‚Äù American Economic Review, 105(8): 2295-2332.\nKennan, J. and Walker, J.R. (2011). ‚ÄúThe Effect of Expected Income on Individual Migration Decisions.‚Äù Econometrica, 79(1): 211-251.\n\n\n\n\nApplications in Public Economics\n\nAlam, M.M.U., Davis, M, and Gregory, J. (2025). ‚ÄúOptimal Place-Based Redistribtuion using Geographic Variation in Marginal Utility of Income‚Äù\nChetty, R. (2009). ‚ÄúSufficient Statistics for Welfare Analysis: A Bridge Between Structural and Reduced-Form Methods.‚Äù Annual Review of Economics, 1: 451-488.\n\n\n\nApplications in Development Economics\n\nAttanasio, O., Meghir, C., and Santiago, A. (2012). ‚ÄúEducation Choices in Mexico: Using a Structural Model and a Randomized Experiment to Evaluate PROGRESA.‚Äù Review of Economic Studies, 79(1): 37-66.\nDuflo, E., Hanna, R., and Ryan, S.P. (2012). ‚ÄúIncentives Work: Getting Teachers to Come to School.‚Äù American Economic Review, 102(4): 1241-1278.\n\n\n\nSurvey Articles\n\nTodd, P.E. and Wolpin, K.I. (2010). ‚ÄúStructural Estimation and Policy Evaluation in Developing Countries.‚Äù Annual Review of Economics, 2: 21-50.\nKeane, M.P., Todd, P.E., and Wolpin, K.I. (2011). ‚ÄúThe Structural Estimation of Behavioral Models: Discrete Choice Dynamic Programming Methods and Applications.‚Äù Handbook of Labor Economics, Vol. 4, Ch. 4: 331-461.\nAguirregabiria, V. and Mira, P. (2010). ‚ÄúDynamic Discrete Choice Structural Models: A Survey.‚Äù Journal of Econometrics, 156(1): 38-67.\nKeane, M.P. and Wolpin, K.I. (2009). ‚ÄúEmpirical Applications of Discrete Choice Dynamic Programming Models.‚Äù Review of Economic Dynamics, 12(1): 1-22.\nBlundell, R. and MaCurdy, T. (1999). ‚ÄúLabor Supply: A Review of Alternative Approaches.‚Äù Handbook of Labor Economics, Vol. 3A, Ch. 27."
  },
  {
    "objectID": "morepages/phddesignbased.html",
    "href": "morepages/phddesignbased.html",
    "title": "PhD: Causality & Design-Based Methods",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "morepages/phddesignbased.html#course-description",
    "href": "morepages/phddesignbased.html#course-description",
    "title": "PhD: Causality & Design-Based Methods",
    "section": "Course Description",
    "text": "Course Description\nThis is the first course in a two-course sequence on applied econometrics at the PhD level, where we will cover design based methods for causal inference. The next course will cover model-based structural methods.\nThere is no particular textbook for this course. We will mostly talk about the econometrics of methods and applications through papers. I will upload slides on canvas. Some additional useful references are:\n\nAngrist and Pischke (2009), Mostly Harmless Econometrics: An Empiricist‚Äôs Companion. Princeton University Press.\nCunningham, S (2012), Causal Inference: The Mixtape. Yale University Press. [Open-source Link]"
  },
  {
    "objectID": "morepages/phddesignbased.html#course-outline",
    "href": "morepages/phddesignbased.html#course-outline",
    "title": "PhD: Causality & Design-Based Methods",
    "section": "Course outline",
    "text": "Course outline\n\nPotential outcomes framework\nRandomized controlled trials\nIV and Heterogeneous treatment effects\nRegression discontinuity designs\nFE, TWFE and Negative weights\nHeterogeneity robust D-i-D and extensions\nShrinkage Estimators\nJudge IV Designs\nShift share IV\nMarginal Treatment Effects"
  },
  {
    "objectID": "morepages/phddesignbased.html#readings",
    "href": "morepages/phddesignbased.html#readings",
    "title": "PhD: Causality & Design-Based Methods",
    "section": "Readings",
    "text": "Readings\nThis reading list by no means is exhaustive. I have tried to add handbook chapters and survey papers since they are pretty well explanatory. Your objective in reading these papers is not only to understand the empirical application but also to understand how good authors write and structure their papers.\n\nRandomized Controlled Trials\n\nMiguel & Kremer (2004), ‚ÄúWorms: Identifying Impacts on Education and Health in the Presence of Treatment Externalities‚Äù. Econometrica\nBertrand & Mullainathan (2004). ‚ÄúAre Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination.‚Äù American Economic Review\nDuflo, Glennerster, & Kremer, M. (2007), ‚ÄúUsing Randomization in Development Economics Research: A Toolkit,‚Äù Handbook of Development Economics.\n\nInstrumental Variables and heterogeneous treatment effects\n\nAngrist & Krueger (1991), ‚ÄúDoes Compulsory School Attendance Affect Schooling and Earnings?‚Äù QJE.\nBound, Jaeger & Baker (1995), ‚ÄúProblems with Instrumental Variables Estimation when the Correlation between the Instruments and the Endogenous Explanatory Variable is Weak,‚Äù Journal of the American Statistical Association.\nCard (1999), ‚ÄúThe Causal Effect of Education on Earnings,‚Äù in Handbook of Labor Economics.\nImbens & Angrist, J. D. (1994), ‚ÄúIdentification and Estimation of Local Average Treatment Effects,‚Äù Econometrica.\n\nRegression Discontinuity\n\nLee & Lemieux (2010), ‚ÄúRegression Discontinuity Designs in Economics,‚Äù JEL\nBlack (1999). ‚ÄúDo Better Schools Matter? Parental Valuation of Elementary Education.‚Äù Quarterly Journal of Economics\nZimmerman (2014). ‚ÄúThe returns to college admission for academically marginal students.‚Äù Journal of Labor Economics\nClark & Martorell (2014). ‚ÄúThe signaling value of a high school diploma.‚Äù Journal of Political Economy\nKolesar & Rothe (2018). ‚ÄúInference in Regression Discontinuity Designs with a Discrete Running Variable.‚Äù American Economic Review.\n\nTWFE and Negative weights\n\nGoodman-Bacon (2021). ‚ÄúDifference-in-differences with variation in treatment timing.‚Äù Journal of Econometrics.\nde Chaisemartin & D‚ÄôHaultfoeuille (2020). ‚ÄúTwo-way fixed effects estimators with heterogeneous treatment effects.‚Äù American Economic Review.\n\nHeterogeneity robust D-i-D and extensions\n\nCallaway & Sant‚ÄôAnna (2021). ‚ÄúDifference-in-differences with multiple time periods.‚Äù Journal of Econometrics.\nSun & Abraham (2021). ‚ÄúEstimating dynamic treatment effects in event studies with heterogeneous treatment effects.‚Äù Journal of Econometrics.\nRambachan & Roth (2023) ‚ÄúA More Credible Approach to Parallel Trends‚Äù Review of Economic Studies.\nRoth, Sant‚ÄôAnna, Bilinksky, & Poe (2023). ‚Äú‚ÄúWhat‚Äôs trending in difference-in-differences? A synthesis of the recent econometrics literature‚Äù. Journal of Econometrics‚Äù\nAgarwal & Alam (2025), ‚ÄúThe Unintended Benefits of Women Empowerment on Household Sanitation‚Äù \n\nShrinkage Estimators\n\nWalters (2024), ‚ÄúEmpirical Bayes methods in labor economics,‚Äù Handbook of Econometrics, Volume 5.\nKline & Walters (2021), ‚ÄúReasonable Doubt: Experimental Detection of Job-Level Employment Discrimination,‚Äù Econometrica\nAlam, Mookerjee & Roy (2021) ‚ÄúEmployee-Side DIscrimination‚ÄìBeliefs and Preferences‚Äù\nAlam, Davis & Gregory (2025) ‚ÄúOptimal Place Based Redistribution using Geographic Variation in the Marginal Utility of Income‚Äù\n\nJudge IV Designs\n\nDobbie, Goldin, & Yang (2018). ‚ÄúThe Effects of Pretrial Detention on Conviction, Future Crime, and Employment: Evidence from Randomly Assigned Judges‚Äù American Economic Review.\nDobbie, Goldsmith-Pinkham, & Yang (2017). ‚ÄúConsumer Bankruptcy and Financial Health‚Äù Review of Economics and Statistics.\nFrandsen, Lefgren, & Leslie (2023). ‚ÄúJudging Judge Fixed Effects.‚Äù American Economic Review.\n\nShift share IV\n\nBorusyak, Hull, & Jaravel (2022). ‚ÄúQuasi-experimental shift-share research designs.‚Äù Review of Economic Studies.\nGoldsmith-Pinkham, Sorkin, & Swift (2020). ‚ÄúBartik instruments: What, when, why, and how.‚Äù American Economic Review.\n\nMarginal Treatment Effects\n\nHeckman, & Vytlacil (2007). ‚ÄúEconometric evaluation of social programs, part I: Causal models, structural models and econometric policy evaluation.‚Äù Handbook of Econometrics.\nHeckman, & Vytlacil (2007). ‚ÄúEconometric evaluation of social programs, part II: Using the marginal treatment effect to organize alternative econometric estimators to evaluate social programs.‚Äù Handbook of Econometrics."
  },
  {
    "objectID": "morepages/phddesignbased.html#assessment",
    "href": "morepages/phddesignbased.html#assessment",
    "title": "PhD: Causality & Design-Based Methods",
    "section": "Assessment",
    "text": "Assessment\n\nProblem Sets ‚Äî 80%: Four problem sets involving both theoretical derivations and empirical exercises + presentations. These are to be completed in groups of two.\n\nStudents can use their programming language of choice. I recommend R.\nStudents are expected to compile their assignments using LaTeX or equivalently in R Markdown. The final submission will involve both code and results in a single PDF with all tables properly formatted, variables properly labeled, and figures and tables with complete footnotes as if they are submitting the work to a journal.\nI will also assign students topics for presentations/referee reports.\n\nClass participation ‚Äî 20%"
  },
  {
    "objectID": "morepages/podcasts.html",
    "href": "morepages/podcasts.html",
    "title": "Podcasts",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\nPodcasts can at times offer an engaging and accessible way to grasp the underlying intuition of various econometric methods. They aid in building a deeper understanding of these methods and in exploring a wide range of problems through the lens of economics.\nI found the following episodes to be particularly interesting. This is a continously evolving list. Suggestions are welcome!\n\nRCT:\n\nAmy Finkelstein on the impact of health insurance (Oregon Medicaid expansion) experiment. ‚ÄúHow do we know what really works in healthcare?‚Äù ‚Äì Freakonomics (April 2, 2015)\nNicholas Bloom on the impact of working from home on productivity. ‚ÄúWhen you start to miss Tony from Accounting‚Äù ‚Äì Hidden Brain (Nov 2020)\nJim Heckman on the impact of early childhood investments on long run outcomes. ‚ÄúWhats not on the test‚Äù ‚Äì Hidden Brain\nJohn List (U-Chicago) on the rise of RCT and worries of scaling up experiments (SUTVA violations). ‚ÄúThe Price of Doing Business with John List‚Äù ‚Äì People I (Mostly) Admire\n‚ÄúA Nobel-Prize for Development RCTs!‚Äù by David McKenzie World Bank Blog\n\n\n\nIV (Continuous and discrete treatments):\n\nSairt Weisburd on Police presence and Crime ‚Äì Probable Causation July 21, 2020\nCarolina Artega on Parental Incarceration and Educational outcomes ‚Äì Probable Causation July 20, 2021\n\n\n\nD-i-D:\n\nMolly Schnell on how exposure to school shootings affects students‚Äô outcomes Probable Causation March 15, 2022\n(advanced) Adrew Goodman-Bacon on recent advances on D-i-D with staggered timing APPAM - Methodological Advances for Difference-in-Differences with Staggered Timing\n\n\n\nRD:\n\n‚ÄúIf Mayors ruled the worlds‚Äù Freakonomics April 10, 2014\n‚ÄúWhy is Uber an Economist‚Äôs Dream?‚Äù Freakonomics September 7, 2016\nMichael Lovenheim on grade retention and crime. Probable Causation September 17, 2019\nGaurav Khanna on Employment and Crime in Colombia. Probable Causation Aug 17, 2021\n\n\n\nDiff-in-RD (advanced)\n\nKirabo Jackson on single-sex education and academic and criminal outcomes. Probable Causation March 31, 2020"
  },
  {
    "objectID": "morepages/econ852.html",
    "href": "morepages/econ852.html",
    "title": "Structural and reduced form methods in labor economics: Course Outline",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\nOutline\n\nPrinciples of empirical research\n\nIdentification\n\n‚ÄúNon-parametric identification‚Äù, Matzkin (2007)\n‚ÄúIdentification of models of the labor market‚Äù Taber and French (2010)\n‚ÄúPartial Identification in Econometrics‚Äù Tamer (2010)\n\nAdvantages of reduced form methods and advantages of structural models\nFeasibility of each approach individually and jointly\n‚ÄúStructural Equations, Treatment Effects and Econometric Policy Evaluation‚Äù Heckman and Vytlacil (2003)\n\nReduced form methods\n\nShift-share exclusion restrictions\n\n‚ÄúBartik Instruments: What, When, Why and How‚Äù Goldsmith-Pinkham, Sorkin and Swift (2020)\n‚ÄúQuasi-experimental shift-share research designs‚Äù Borusyak, Hull and Jaravel (2020)\n\nVariation in treatment timings and heterogenous effects\n\n‚ÄúWhat‚Äôs trending in difference-in-differences?‚Äù Roth and Santa‚ÄôAnna (2022)\n‚ÄúTwo-way fixed effects estimators with heterogeneous treatment effects‚Äù de Chaisemartin and d`Haultfoeuille (2020)\n‚ÄúThe Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation‚Äù Alam and Agarwal (2023)\n\nEmpirical Bayes\n\n‚ÄúEmpirical Bayes deconvolution estimates.‚Äù Efron (2016)\n‚ÄúSystemic discrimination among large US employers‚Äù, Kline, Rose and Walters (2022)\n‚ÄúRobust empirical bayes confidence intervals‚Äù Armstrong, Koles√°r and Plagborg-M√∏ller (2022)\n\nDiscontinuity based designs\n\n‚ÄúInference on causal effects in a generalized regression kink design‚Äù Card et al.¬†(2015)\n‚ÄúInference in Regression Discontinuity Designs with a Discrete Running Variable‚Äù, Kolesar and Rothe (2018)\n\n\nStructural models\n\nConditional choice probabilities, discrete choice and dynamic models\n\n‚ÄúDiscrete Choice Methods with Simulation‚Äù Train (2009)\n‚ÄúConditional Choice Probabilities and the Estimation of Dynamic Models‚Äù, Hotz and Miller (1993)\n‚ÄúCollege Attrition and the Dynamics of Information Revelation‚Äù, Arcidiacono, Aucejo, Maurel, et al.¬†(2018)\n‚ÄúThe Structural Estimation of Behavioral Models: Discrete Choice Dynamic Programming Methods and Applications,‚Äù Keane and Wolpin (2011)\n\nStated preference\n\n‚ÄúPreference for the workplace, investment in human capital and gender‚Äù, Wiswall Zafar (2018)\n‚ÄúUnderstanding Migration Aversion Using Elicited Choice Probabilities‚Äù, Kosar, Ransom, van der Klaauw (2022)\n‚ÄúOptimal Place-based redistribution‚Äù Alam, Davis and Gregory (2023)\n\n\nModels on wage inequality\n\n‚ÄúHigh wage workers and high wage firms‚Äù Abowd, Kramarz and Margolis (1999)\n‚ÄúA Distributional Framework for Matched Employer-employee data‚Äù, Bonhomme, Lamadon, Manresa (2019)\n‚ÄúRacial Gaps in Wage Growth: Discrimination and Search Frictions‚Äù Alam (2020)\n‚ÄúDiscretizing Unobserved heterogeneity‚Äù Bonhomme, Lamadon, Manresa (2019)\n‚ÄúMonopsony in Movers: The Elasticity of Labor Supply to Firm Wage Policies‚Äù, Bassier, Dube, Naidu (2021)\n\n\nUsing both reduced form and structural models\n\n‚ÄúWorker-side discrimination‚ÄìBeliefs and Preferences - Evidence from an Information Experiment on Jobseekers‚Äù, Alam, Mookerjee, Roy (2022)\n‚ÄúEstimating Equilibrium Effects of Job Search Assistance,‚Äù Gautier, Muller, van der Klaauw, Rosholm and Svarer (2018)\n‚ÄúThe Demand for Food of Poor Urban Mexican Households: Understanding Policy Impacts Using Structural Models‚Äù Angelucci and Attanasio (2013)\n‚ÄúEvaluating Search and Matching Models Using Experimental Data‚Äù Lise, Seitz and Smith (2015)\n‚ÄúEvaluating a Structural Model of Labor Supply and Welfare Participation: Evidence from State Welfare Reform Experiments,‚Äù Choi (2018)\n‚ÄúEstimating labour supply responses and welfare participation: Using a natural experiment to validate a structural labour supply model‚Äù Hansen and Liu (2015)\n‚ÄúThe Role of Labor and Marriage Markets, Preference Heterogeneity and the Welfare System on the Life Cycle Decisions of Black, Hispanic and White Women,‚Äù Keane and Wolpin (2010)\n‚ÄúApproximating the Equilibrium Effects of Informed School Choice,‚Äù Allende, Gallego and Nielson (2019)\n\nCoding in Julia (if time permits)\n\nWhy Julia?\nEfficient code, version control and large project workflow\nAutomatic testing and reproducibility\nIntroduction to numerical optimization #### Other readings\n\nControl function approach\n\nControl Function Methods in Applied Econometrics, Wooldridge (2015)\n‚ÄúIdentification of Treatment Effects Using Control Functions in Models with Continuous, Endogenous Treatment and Heterogeneous Effects‚Äù, Heckman et. al (2008)\n‚ÄúUsing Matching, Instrumental Variables, and Control Functions to Estimate Economic Choice Models‚Äù Heckman and Navarro (2004)\n‚ÄúControl functions‚Äù Navarro (2010)"
  },
  {
    "objectID": "morepages/UG_intro_metrics.html",
    "href": "morepages/UG_intro_metrics.html",
    "title": "Introduction to Econometrics",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "morepages/UG_intro_metrics.html#course-information",
    "href": "morepages/UG_intro_metrics.html#course-information",
    "title": "Introduction to Econometrics",
    "section": " Course Information",
    "text": "Course Information\n\n  Download Syllabus \nAlso see  Resources for Students"
  },
  {
    "objectID": "morepages/UG_intro_metrics.html#lecture-slides",
    "href": "morepages/UG_intro_metrics.html#lecture-slides",
    "title": "Introduction to Econometrics",
    "section": " Lecture Slides",
    "text": "Lecture Slides\n\n\nIntroduction to R\nStatistical Review & Population Concepts\nSimple Linear Regressions\nMultiple Linear Regressions\nMore on MLR\nInference in Regression Models\nHeteroskedasticity & Serial Correlation [Discussion section]\nPotential Outcomes\nRandomized Controlled Trials\nInstrumental Variables, 2SLS & HTE\nPanel Data and FE, TWFE\nDifference-in-Differences\nRegression Discontinuity Designs\nCourse Summary"
  },
  {
    "objectID": "morepages/UG_intro_metrics.html#problem-sets",
    "href": "morepages/UG_intro_metrics.html#problem-sets",
    "title": "Introduction to Econometrics",
    "section": " Problem Sets",
    "text": "Problem Sets\n\nProblem Set 1 (Due Sep 18)\n Assignment |  Solutions\nProblem Set 2 (Due Oct 5)\n Assignment |  Solutions\nProblem Set 3 (Due Oct 31)\n Assignment\nProblem Set 4 (Due Nov 16)\n Assignment |"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\nClark University\n\nUndergraduate: Econometrics\nPhD: Applied Econometrics-I: Causality & Design-Based Methods\nPhD: Applied Econometrics-II: Structural + Computation\nPhD: Econometric Theory\nUndergraduate: Statistics [Canvas Course Website]\n\n\n\n\nQueen‚Äôs University\n\nPhD: Structural and reduced form methods in labor economics\n\n[Course Outline]\n\nUndergraduate: Applied Econometrics: Causal Inference.\n\n[Course Outline] [Course Website]\n\n\n\n\n\nUniversity of Wisconsin-Madison\n\nDepartment of Economics Nominee for UW-Madison Letters & Sciences Teaching Fellows Award 2019\n\n\nEcon 705 ‚Äì Econometric Theory (Graduate). Instructors: Jack Porter & Jeffrey Smith\n\nJuli Plant Grainger Teaching Excellence Award\nDistinguished Teaching Assistant\n\nEcon 706 ‚Äì Applied Econometrics (Graduate). Instructors: Christopher Taber & Kenneth West\n\nDistinguished Teaching Assistant\n\nEcon 101 [Head TA]. Instructor: Korinna Hansen; Elizabeth Kelly; Gwen Eudey \n\nDistinguished Teaching Assistant (x 2)\n\n\n\n\n\n\n\nResources for students\nCoding for undergrads\nPodcasts discussing empircal research in economics"
  },
  {
    "objectID": "morepages/code.html",
    "href": "morepages/code.html",
    "title": "Code",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\nCode for research\nHere are the codes of some julia/R functions that I have implemented in my research. There may be more efficient routines. I have often found julia to be quite fast if the data or the parameter space is large. And I like coding in it.\nI have tried to make them context agnostic. However, they may not be fully general, some almost by construction. Hence these are not packages. Please feel free to use them, or report a bug if you find one!\n\nQuantile regressions with FE (Canay 2011) (julia)\nNelder-Mead simplex algorithm (julia)\nParametric shrinkage with heteroskedastic errors (julia)\nNon-parametric shrinkage with heteroskedastic errors and shape restrictions (R)\nEvent studies with interacted FE (julia)\n\n\n\nCode for teaching\nMost of these are in R. Their objective is to simulate data with failures in assumptions required for identification, or for inference and show what happens. Some of them are simply hard-coding the estimator instead of using a package which I have found to be helpful being able to compare various estimators.\n\nSimple linear regression\nCentral Limit Theorem\nFrisch-Waugh-Lovell theorem\nIV and 2SLS\nWeak IV vs Strong IV"
  },
  {
    "objectID": "morepages/resourcesforugstudents.html",
    "href": "morepages/resourcesforugstudents.html",
    "title": "Resources for undergrad students",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "morepages/resourcesforugstudents.html#coding-resources",
    "href": "morepages/resourcesforugstudents.html#coding-resources",
    "title": "Resources for undergrad students",
    "section": "Coding resources",
    "text": "Coding resources\nStudents are free to use any language of their preference‚ÄìStata, R, julia, python, Matlab etc. Historically, most students have used Stata for the analysis they conduct in their term paper. However, starting 2025, I have shifted my teaching of Econometrics, specifically implementation of methods‚Äîboth simulation and estimation‚Äîto R. Below you will find old open-source resources as well as new resources that I recommend to students.\nI strongly encourage students to use open-source languages like R, julia and python."
  },
  {
    "objectID": "morepages/resourcesforugstudents.html#r-resources",
    "href": "morepages/resourcesforugstudents.html#r-resources",
    "title": "Resources for undergrad students",
    "section": "R resources",
    "text": "R resources\n\nStata2R: Students used to working in Stata will find this website incredibly useful if they want to transition to R.\nR manuals from CRAN and the CRAN homepage for R\nMaster repo with various cheatsheets\nRMarkdown: I ask students to complete their problem sets in RMarkdown to have both code compilation as well as theoretical proofs written and executed in the same file.\n\nR Markdown: The Definitive Guide: far more extensive, covers interactivity and additional features.\nQuarto markdown is another alternative that I really like for its versatility in languages. RMarkdown can also handle multiple languages (see here) but I prefer the ease of customization of Quarto when it comes to multiple languages.\n\nPackage specific:\n\ndata.table\ndplyr\nggplot2\nfixest\nAER (Applied Econometrics with R)\nbinsreg\nvtable\nstargazer\nmore on stargazer\nmodelsummary"
  },
  {
    "objectID": "morepages/resourcesforugstudents.html#stata-resources",
    "href": "morepages/resourcesforugstudents.html#stata-resources",
    "title": "Resources for undergrad students",
    "section": "Stata Resources",
    "text": "Stata Resources\nBesides google search being a very good friend while picking up any language, here are some resources on Stata from the internet that may be useful for students.\n\nSocial Science Computing Center at UW-Madison\nData and Statistical services at Princeton\nAdvanced Research computing at UCLA\nProject management in Stata\nTransitioning between Stata and R\n\nMost of them, have corresponding pages for R as well."
  },
  {
    "objectID": "morepages/resourcesforugstudents.html#best-practices",
    "href": "morepages/resourcesforugstudents.html#best-practices",
    "title": "Resources for undergrad students",
    "section": "Best practices",
    "text": "Best practices\n\nUseful checklist while working with regression outputs\nCode and Data for the Social Sciences: A Practitioner‚Äôs Guide, by Gentzkow and Shapiro"
  },
  {
    "objectID": "morepages/econ452.html",
    "href": "morepages/econ452.html",
    "title": "Econ 452: Course Outline",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\nOutline\n\nPotential Outcomes Framework (1 lecture)\nRandomized Control Trials (1.5 lectures)\nRegressions (1.5 lectures)\nNon-linear regressions (2 lectures)\nInstrumental Variables (5 lectures)\nHeterogeneous Treatment Effects (1 lecture)\nPanel data and Fixed Effects (3 lectures)\nDifference-in-Differences (5 lectures)\nRegression Discontinuity (2 lectures)\nInference (1 lecture)\nTake away from the course (1 lecture)\n\n\n\nAssessment\n\n10% Discussion and class participation\n30% 5 Problem sets\n60% Group project"
  },
  {
    "objectID": "morepages/phdmetrics.html",
    "href": "morepages/phdmetrics.html",
    "title": "PhD: Econometric Theory",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "morepages/phdmetrics.html#course-description",
    "href": "morepages/phdmetrics.html#course-description",
    "title": "PhD: Econometric Theory",
    "section": "Course Description",
    "text": "Course Description\nThis is a core PhD level econometrics course. I am not an Econometric theorist, but I think a lot about Econometrics and pay attention to it in my work. Hence, my teaching of this course may differ from a traditional econometric theorist.\nMy goal here is to get you ready for second year applied econometrics course sequence of design-based and structural methods. Hence I want to ensure certain results, and style of approaching econometric proofs are at your fingertips as you embark on research. An additional theme, besides all the math, will be simulation to better understand estimators and sensitivity of assumptions. I have found this very useful in my own learning to line up intuition with the theory. I will be mostly doing this in R or julia.\nI will mostly follow Bruce Hansen‚Äôs Econometrics (2022) textbook from which I have learnt a lot and found very useful. You would also find the first part of this book Probability and Statistics for Economists (2022) very useful too."
  },
  {
    "objectID": "morepages/phdmetrics.html#broad-outline",
    "href": "morepages/phdmetrics.html#broad-outline",
    "title": "PhD: Econometric Theory",
    "section": "Broad outline",
    "text": "Broad outline\nI plan to cover this course in mostly the following big sub-parts:\n\nIdentification and Estimation\nParametric estimation of linear models\nLarge sample asymptotics and inference, and resampling based inference\nNon-parametrics\nNon-linear models"
  },
  {
    "objectID": "morepages/phdmetrics.html#assessment",
    "href": "morepages/phdmetrics.html#assessment",
    "title": "PhD: Econometric Theory",
    "section": "Assessment",
    "text": "Assessment\n\nProblem Sets ‚Äî 80%: Four problem sets involving both theoretical derivations and empirical exercises + presentations. These are to be completed in groups of two.\n\nStudents can use their programming language of choice. I recommend R.\nStudents are expected to compile their assignments using LaTeX or equivalently in R Markdown. The final submission will involve both code and results in a single PDF with all tables properly formatted, variables properly labeled, and figures and tables with complete footnotes as if they are submitting the work to a journal.\n\nClass participation ‚Äî 20%"
  },
  {
    "objectID": "blogs/julia_environments.html",
    "href": "blogs/julia_environments.html",
    "title": "Reproducible julia projects",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\nA workflow that starts your project to be reproducible from day one, will reduce your work going forward. Since I have started using this workflow, I have realized that by construction it forces certain good habits. In this post, I will share a simple example of creating a reproducible project in julia, by using julia environments.1 The setup below works for me to ensure that the correct versions of my dependencies are used automatically on any machine."
  },
  {
    "objectID": "blogs/julia_environments.html#setting-up-a-julia-project-environment",
    "href": "blogs/julia_environments.html#setting-up-a-julia-project-environment",
    "title": "Reproducible julia projects",
    "section": "Setting up a julia project environment",
    "text": "Setting up a julia project environment\nFirst, setting up a new julia project typically involves creating the working directory, initializing the environment within that directory, and then modifying the environment, e.g.¬†adding any necessary packages.\nmkdir -p path/to/MyCoolProject\ncd path/to/MyCoolProject\nThen I typically create a setup.jl file in the path/to/MyCoolProject/code folder to activate the environment and adding necessary packages.\nusing Pkg\ncd(@__DIR__)\nPkg.activate(@__DIR__)\nThese commands will create a Project.toml and Manifest.toml file in your project directory. These files will track your project dependencies and their exact versions, ensuring reproducibility.\n\nOnce you‚Äôve initialized your project, you can add packages to it, as you normally would.\n# Add packages to your project\n(MyCoolProject) pkg&gt; add DataFramesMeta\nAdding the very first package does two things:\n\nUpdates Project.toml: It adds DataFrames to the list of dependencies.\nUpdates Manifest.toml: It records the exact version of DataFrames and its dependencies to ensure reproducibility."
  },
  {
    "objectID": "blogs/julia_environments.html#reusing-and-modifying-your-environment",
    "href": "blogs/julia_environments.html#reusing-and-modifying-your-environment",
    "title": "Reproducible julia projects",
    "section": "Reusing and modifying your environment",
    "text": "Reusing and modifying your environment\nIf you‚Äôve closed your julia session and want to continue working on your project later, navigate back to your project directory and reactivate the environment:\ncd(\"path/to/MyCoolProject\")\njulia&gt; ]\n(v1.9) pkg&gt; activate .\nThis reactivates the environment associated with the Project.toml and Manifest.toml files in the same directory.\nTo add more packages to your project at any time:\n(MyCoolProject) pkg&gt; add Plots\nThis command updates your environment to include the Plots package. The Project.toml and Manifest.toml files will be updated accordingly.\nTo see the current status of your environment run Pkg.status() and to update run Pkg.update()"
  },
  {
    "objectID": "blogs/julia_environments.html#sharing-your-environment",
    "href": "blogs/julia_environments.html#sharing-your-environment",
    "title": "Reproducible julia projects",
    "section": "Sharing your environment",
    "text": "Sharing your environment\nTo share your project with others, provide the directory containing Project.toml and Manifest.toml. Others can recreate your environment by running:\njulia&gt; ]\n(v1.9) pkg&gt; activate .\n(MyCoolProject) pkg&gt; instantiate\nThis installs all the dependencies listed in Manifest.toml, recreating your exact environment."
  },
  {
    "objectID": "blogs/julia_environments.html#setting-up-the-project-on-a-different-machine",
    "href": "blogs/julia_environments.html#setting-up-the-project-on-a-different-machine",
    "title": "Reproducible julia projects",
    "section": "Setting up the project on a different machine",
    "text": "Setting up the project on a different machine\n\nWhen you clone a project repository or copy a project folder to a different machine, the Manifest.toml file contains the exact versions of all dependencies needed.\nRunning Pkg.instantiate() in this context installs these exact versions, recreating the original environment.\n\njulia&gt; ]\n(v1.9) pkg&gt; instantiate\nThe instantiate command has two more useful features:\n\nRestoring an Environment:\n\nIf you‚Äôve made changes to your environment or accidentally removed packages and want to restore the environment to the exact state described in the Manifest.toml, you can use Pkg.instantiate() to reinstall all necessary dependencies.\nThis is also useful if you‚Äôve deleted the ~/.julia/environments directory or are switching between environments and want to ensure the current project has all the required packages.\n\nEnsuring consistency across users: If you‚Äôre working in a shared project and the Manifest.toml has been updated by someone else (e.g., new packages have been added or versions changed), running Pkg.instantiate will synchronize your local environment with the latest dependencies as defined in the Manifest.toml.\n\nHappy researching!"
  },
  {
    "objectID": "blogs/julia_environments.html#footnotes",
    "href": "blogs/julia_environments.html#footnotes",
    "title": "Reproducible julia projects",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is different from creating a julia package. Excellent resources on creating julia packages can be found here, here and using the PkgTemplates.jl package to create a new package can be found here‚Ü©Ô∏é"
  },
  {
    "objectID": "blogs/dropbox_git_issues.html",
    "href": "blogs/dropbox_git_issues.html",
    "title": "Issues with cloud sync and version control",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\nMany of us use cloud based services to sync important files. These services are not version controlling systems. If you have been use cloud based services to sync your files like Dropbox, it is recommended not to have a git repo inside a Dropbox folder for reasons described here, [here] and here or ensure Dropbox ignores the files that could cause conflicts with git. In short, this is how I do this:\n\nI only use git to version control my code. All other documentation that do not need version control for example, related papers, data etc. live in a project folder inside Dropbox.\nIf I am the only person writing the code, I either tell Dropbox to ignore the code directory if it is living in Dropbox, or I keep it outside of Dropbox. The latter works best if you are the sole person working on the code. The former is useful only for project organization‚Äîgiven that data and other documentation is living in the Dropbox folder, it is only convenient to also have the code directory inside the same project folder.\nIf I am collaborating with someone on code and they do not want to use git then I do not version control our code in the Dropbox folder. Rather, I keep a separate folder with all my codes in a non-Dropbox folder and version control that. At the end of each day, I then sync them with the Dropbox folder. This is only possible because my scripts are typically different from my collaborators script."
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Research",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\n\n Working papers\n\nEmployee-Side Discrimination: Beliefs and Preferences (PhD JMP)\nwith Mehreen Mookerjee and Sanket Roy\n[+Abstract] Online Appendix A-C\n\n\nR&R at Quantitative Economics Updated July ‚Äô25\n\nThe Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation\nwith Monica Agarwal [+Abstract] [ SSRN]\n\n\nR&R at Journal of Human Resources Updated April ‚Äô25\n\nLabor Market Consequences of Pay-Equity Laws (Post-doc JMP)\nwith Steven Lehrer and Nuno Souso Pereira\n[+Abstract]\n\n\nUpdated Aug ‚Äô25 [Under review]\n\nComputing Optimal Place‚ÄëBased Transfers with Direct Measurement of Geographic Variation in Marginal Utility of Income\nwith Morris Davis and Jesse Gregory\n\n\nDraft coming soon!\n\n\n\n\n\n\n Publications/Accepted\n\n‚ÄúIncreases in shared custody after divorce in the United States.‚Äù\nwith Daniel Meyer and Marcia Carlson.\n[+Abstract] [ Replication]\n\n\nDemographic Research 46 (2022): 1137-1162. ‚ÄúEditor‚Äôs Choice‚Äù article\n\n\n\n\n\n\n Research in progress\n\nSpatial Inequality and School Choice Mechanisms\nwith Monica Agarwal, Chao Fu, YingHua He\nLabor Market Inequality and Collective Bargaining\nwith Steven Lehrer and Nuno Souso Pereira\nRacial Gaps in Wage Growth: Discrimination, Selection and Search Frictions\n\n\n\n\n\nDormant papers\n\nIdentification in Models of Discrimination\n[subsumed in my PhD job market paper ‚ÄúEmployee Side Discrimination: Beliefs and Preferences‚Äù]\n\n\n\n\n\n\nCode\nmicro = require(\"micromodal@0.4.10\");\n\nmicro.init({\n  awaitOpenAnimation: true,\n  awaitCloseAnimation: true\n});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncreases in shared custody after divorce in the United States\n\n\nThis paper provides new evidence on the time trend in shared physical custody after divorce in the U.S., using eight waves of data from the Current Population Survey - Child Support Supplement. We find that the likelihood of shared custody more than doubled between divorces that occurred before 1985 and those in 2010-2014, from 12% to 28%. We show that non-Hispanic Whites and those who are more socioeconomically advantaged are more likely to have shared custody. Using more formal methods we show that the increase cannot be explained by changes in the characteristics of those divorcing; instead, we infer that this is the result of changing norms and policies that favor shared custody. Finally, this paper complements previous analyses using court record data from Wisconsin and shows that while the rate of shared custody in Wisconsin is higher than the national rate, a large increase over time has occurred in the nation as well as in Wisconsin. These changing patterns have important implications for children‚Äôs living arrangements and for the parental investments that children receive after their parents‚Äô divorce."
  },
  {
    "objectID": "papers_complete.html",
    "href": "papers_complete.html",
    "title": "Moshi Alam",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Working Papers\n\n\n\n1. Employee-Side Discrimination: Beliefs and Preferences\n\n\nwith Mehreen Mookerjee and Sanket Roy\n\n\nR&R at Quantitative Economics PhD JMP \n\n\nAbstract Online Appendix A-C   BibTeX \n\n\n\n\n2. The Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation\n\n\nwith Monica Agarwal\n\n\nR&R at Journal of Human Resources \n\n\nAbstract SSRN   BibTeX \n\n\n\n\n3. Labor Market Consequences of Pay-Equity Laws\n\n\nwith Steven Lehrer and Nuno Souso Pereira\n\n\nUnder Review  Post-doc JMP\n\n\nAbstract   BibTeX \n\n\n\n\n4. Optimal Place‚ÄëBased Transfers using Measured Geographic Variation in the Marginal Utility of Income\n\n\nwith Morris Davis and Jesse Gregory\n\n\nDraft Coming Soon\n\n\n\n\n\n Publications\n\n\n\nIncreases in shared custody after divorce in the United States\n\n\nwith Daniel Meyer and Marcia Carlson\n\n\n Demographic Research 46(38) 2022: 1137-1162 ‚≠ê Editor‚Äôs Choice Article\n\n\nAbstract Replication   BibTeX \n\n\n\n\n\n Research in Progress\n\n\n\nSpatial Inequality and School Choice Mechanisms\n\n\nwith Monica Agarwal, Chao Fu, and YingHua He\n\n\n\n\nLabor Market Inequality and Collective Bargaining\n\n\nwith Steven Lehrer and Nuno Souso Pereira\n\n\n\n\n\n\nDormant Papers\n\n\n Click to view dormant papers\n\n\n\n\nIdentification in Models of Discrimination\n\n\n[Subsumed in PhD job market paper ‚ÄúEmployee Side Discrimination: Beliefs and Preferences‚Äù]\n\n\n\n\n\n\n\n\n\nCode\nmicro = require(\"micromodal@0.4.10\");\n\nmicro.init({\n  awaitOpenAnimation: true,\n  awaitCloseAnimation: true\n});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncreases in shared custody after divorce in the United States\nwith Daniel Meyer and Marcia Carlson\n\n\nThis paper provides new evidence on the time trend in shared physical custody after divorce in the U.S., using eight waves of data from the Current Population Survey - Child Support Supplement. We find that the likelihood of shared custody more than doubled between divorces that occurred before 1985 and those in 2010-2014, from 12% to 28%. We show that non-Hispanic Whites and those who are more socioeconomically advantaged are more likely to have shared custody. Using more formal methods we show that the increase cannot be explained by changes in the characteristics of those divorcing; instead, we infer that this is the result of changing norms and policies that favor shared custody. Finally, this paper complements previous analyses using court record data from Wisconsin and shows that while the rate of shared custody in Wisconsin is higher than the national rate, a large increase over time has occurred in the nation as well as in Wisconsin. These changing patterns have important implications for children‚Äôs living arrangements and for the parental investments that children receive after their parents‚Äô divorce.\n\n\n\n\n\n\n\n\n\n\n\nLabor Market Consequences of Pay-Equity Laws\nwith Steven Lehrer and Nuno Souso Pereira\n\n\nLimited policy variation, data constraints in defining ‚Äòequal work‚Äô, and compliance issues have prevented rigorous causal analysis of pay equity laws. We address these challenges using Portugal‚Äôs 2018 legislation, which penalized firms with over 250 employees for gender wage gaps exceeding 5%. Using administrative data that links employees to industry-defined job titles within firms, we analyze its impact both within and between genders using an event study design. We find the law achieved its intended effects in some areas while generating unintended consequences in others. Jobs with initial gaps exceeding 5% saw a 9% reduction, mainly through slower male wage growth. A small fraction of jobs with negative gaps saw reduced female wage growth, closing the gap by half. However, gaps in jobs initially between 0-5% unexpectedly widened by 21% due to slower female wage growth. These unintended consequences are more pronounced in male-dominated industries and cannot be explained by productivity differences. Further, we find that firms did not change their size to evade the law, nor did it impact job gender composition, or hours worked. Our findings reveal both intended and unintended consequences of pay equity laws implemented with uniform regulatory targets: while the 5% target effectively reduced large disparities, it inadvertently widened gaps below the threshold as firms, with enforcement rules now clarified, strategically adjusted wages but not employment, offering crucial insights for policy design in achieving ‚Äúequal pay for equal work‚Äù.\n\n\n\n\n\n\n\n\n\n\n\nEmployee-Side Discrimination: Beliefs and Preferences\nwith Mehreen Mookerjee and Sanket Roy\n\n\nWorkers‚Äô preferences and beliefs shape labor market outcomes, yet remain understudied. We develop a theory-driven novel identification strategy for information experiments that separates preferences from beliefs. We apply this to provide the first evidence on the distribution of workers‚Äô preferences on manager gender and their beliefs on managers‚Äô mentoring ability. In the absence of information on manager mentoring ability, workers are indifferent to manager gender. However, upon receiving information on manager mentorship ability, workers prefer to work for female managers‚Äîwilling to forgo 1.3‚Äì2.2% of average annual wages. Hence, absent additional information, workers believe female managers are worse mentors (1.6% wage equivalent). Non-parametric estimates of the distributions reveal that 75% prefer female managers with mentoring information, and 67% believe male managers are better mentors absent information. Machine learning algorithms show that individuals with higher education are less likely to hold such beliefs. These beliefs are primarily driven by perceptions that women are less competent. Evidence suggests these beliefs are likely biased, highlighting scope for information-based policy interventions that could reduce suboptimal matching and gender gaps in management levels. Our identification-driven design provides a general framework for information experiments to study beliefs.\n\n\n\n\n\n\n\n\n\n\n\nThe Unintended Benefits of Women‚Äôs Empowerment on Household Sanitation\nwith Monica Agarwal\n\n\nExisting research shows that women benefit more from private toilets, but misperceptions about the net benefits from toilets and lack of women‚Äôs decision-making power can hinder toilet adoption by households. In this paper, we explore a novel link between household sanitation and policies that empower women. We show that a policy aimed at improving women‚Äôs property inheritance rights in India led to an increase in toilet adoption in the households of treated cohorts by at least 10%. Prior literature shows mixed evidence on whether the policy increased women‚Äôs inheritance, but shows that the policy had significant indirect effects, such as improving women‚Äôs education. To generate empirical tests for the mechanisms driving our main results, we build a discrete choice model with idiosyncratic household preference shocks that produces policy-relevant complementarity between women‚Äôs education and decision-making power in adoption of a household public good valued more by women. Using a heterogeneity-robust event-study design, we find that, consistent with our model, the increase in toilet adoption is concentrated in states where the policy boosted women‚Äôs education‚Äîplausibly reducing misperceptions about the benefits of toilets‚Äîand increased women‚Äôs decision-making power. Our findings highlight that policies empowering women can yield unintended benefits beyond their original scope‚Äîwhile we document improvements in toilet coverage, the implications extend to other household investments where women‚Äôs preferences are stronger, but various frictions limit adoption."
  },
  {
    "objectID": "teach.html",
    "href": "teach.html",
    "title": "Teaching",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n\nClark University\n\n\nUndergraduate: Statistics [Course website]\nUndergraduate: Econometrics\nPhD: Applied Econometrics-I [Course website]\n\nStarting Spring 2025:\n\nPhD: Applied Econometrics-II\nPhD: Econometric Theory\n\n\n\n\n\nQueen‚Äôs University\n\n\nPhD: Structural and reduced form methods in labor economics\n[Course Outline]\nUndergraduate: Applied Econometrics: Causal Inference\n[Course Outline] [Course Website]\n\n\n\n\n\nUniversity of Wisconsin-Madison\n\nüèÜ Department of Economics Nominee for UW-Madison Letters & Sciences Teaching Fellows Award 2019\n\n\n\nEcon 705 ‚Äì Econometric Theory (Graduate) Instructors: Jack Porter & Jeffrey Smith\n\nüèÜ Juli Plant Grainger Teaching Excellence Award\nüèÜ Distinguished Teaching Assistant\n\nEcon 706 ‚Äì Applied Econometrics (Graduate) Instructors: Christopher Taber & Kenneth West\n\nüèÜ Distinguished Teaching Assistant\n\nEcon 101 [Head TA] Instructors: Korinna Hansen, Elizabeth Kelly, Gwen Eudey\n\nüèÜ Distinguished Teaching Assistant (√ó2)\n\n\n\n\n\n\nResources for Students\n\nCoding for Undergrads\nPodcasts Discussing Empirical Research in Economics"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV\n        \n        \n          \n        \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n\n\n  Download my CV \nLast updated: September 2025"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#introduction",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#introduction",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Introduction",
    "text": "Introduction\nPopulation model: \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_k x_{ki} + u_i\\).\n\n\n\nestimate the parameters & SE using OLS\n\n\nNow, based on sample estimates and standard errors. we will answer questions like:\n\nWhether the estimated coefficient is statistically significant at any confidence level?\n\nWhether the true population parameter estimate is statistically different from zero at any confidence level?\nChoice of models\n\n\n\n\nlibrary(wooldridge)\nwage_data &lt;- wage1\nreg1 &lt;- lm(log(wage) ~ educ + exper + tenure, data = wage_data)\nsummary(reg1)\n\n\nCall:\nlm(formula = log(wage) ~ educ + exper + tenure, data = wage_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05802 -0.29645 -0.03265  0.28788  1.42809 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.284360   0.104190   2.729  0.00656 ** \neduc        0.092029   0.007330  12.555  &lt; 2e-16 ***\nexper       0.004121   0.001723   2.391  0.01714 *  \ntenure      0.022067   0.003094   7.133 3.29e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4409 on 522 degrees of freedom\nMultiple R-squared:  0.316, Adjusted R-squared:  0.3121 \nF-statistic: 80.39 on 3 and 522 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#recall-from-econ160",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#recall-from-econ160",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Recall from Econ160",
    "text": "Recall from Econ160\n\n\nTo test equality of proportions between two groups, we used the \\(z\\)-test\n\n\\(H_0: p_1 - p_2 = 0\\) vs \\(H_1: p_1 - p_2 \\neq 0\\)\nTest statistic: \\(z = \\frac{(\\hat{p}_1 - \\hat{p}_2) - 0}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}}\\) Follows a standard normal distribution\nCI: \\((\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2}^* \\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}\\)\n\nTo test equality of means between two groups, we used the \\(t\\)-test\n\n\\(H_0: \\mu_1 - \\mu_2 = 0\\) vs \\(H_1: \\mu_1 - \\mu_2 \\neq 0\\)\nTest statistic: \\(t = \\frac{(\\bar{y}_1 - \\bar{y}_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\) Follows a \\(t\\) distribution with \\(n_1 + n_2 - 2\\) (d.o.f.)\nCI: \\((\\bar{y}_1 - \\bar{y}_2) \\pm t_{\\alpha/2, n_1 + n_2 - 2}^* \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\)\n\n\n\n\n\nAssumptions\n\n\nrandom sampling, independence, and large sample size"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#big-picture",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#big-picture",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Big picture",
    "text": "Big picture\n\nTo test hypotheses about regression coeffcients \\(\\hat{\\beta}_j\\), we need to know:\n\nthe sampling distribution of the \\(\\hat{\\beta}_j\\)‚Äôs  \n\nOnce we have the sampling distribution of the \\(\\hat{\\beta}_j\\)\n\nWe can get the standard errors of the \\(\\hat{\\beta}_j\\)‚Äôs\n\nEstimates of the standard deviation of the sampling distribution of the \\(\\hat{\\beta}_j\\)‚Äôs\n\n\nWe can make inferences about the population parameters \\(\\beta_j\\)‚Äôs‚Äô based on\n\nthe estimates, standard errors and the sampling distribution of the \\(\\hat{\\beta}_j\\)‚Äôs\n\nTurns out that under some assumptions, the \\(\\hat{\\beta}_j\\)‚Äôs follow a \\(t\\) distribution (in practice) \n\nIt requires an assumption on the distribution of the errors \\(u_i\\)‚Äôs MLR.6"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#assumption-mlr.6",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#assumption-mlr.6",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Assumption MLR.6:",
    "text": "Assumption MLR.6:\n\n\n\nAssumption MLR.6: Normality of Errors\n\n\nThe population error \\(u_i\\) is normally distributed with mean 0 and constant variance \\(\\sigma^2\\) and independent of the regressors for all \\(i = 1, 2, \\ldots, n\\) \\[u_i \\sim N(0, \\sigma^2)\\]\n\n\n\n\nThis directly implies MLR.4 and MLR.5\nThe full set of assumptions MLR.1-MLR.6 are called the classical linear model (CLM) assumptions. Together they imply: \\[y \\mid x_1, \\ldots x_k \\sim N(\\beta_0 + \\beta_1 x_{1i} + \\ldots + \\beta_k x_{ki}, \\sigma^2)\\]\nHard to defend this very strong assumption\n\nThankfully not required for large samples (beyond the scope of this course)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#section",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#section",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "Theorem 4.1: Normality of OLS Estimators\n\n\nUnder the CLM assumptions MLR. 1 through MLR.6, conditional on the sample values of the independent variables,\n\\[\n\\hat{\\beta}_j \\sim \\operatorname{Normal}\\left(\\beta_j , \\operatorname{Var}\\left(\\hat{\\beta}_j\\right)\\right),\n\\]\nwhere \\(\\operatorname{Var}\\left(\\hat{\\beta}_{j}\\right)\\)was given in Chapter 3 [equation (3.51)]. Therefore,\n\\[\n\\frac{\\hat{\\beta}_j-\\beta_j}{\\operatorname{sd}\\left(\\hat{\\beta}_j\\right)} \\sim \\operatorname{Normal}(0,1) \\quad \\text { for } j=0,1, \\ldots, k\n\\]\n\n\n\n\n\n\nTheorem 4.2: t-distribution of OLS Estimates\n\n\nUnder the CLM assumptions MLR. 1 through MLR.6, conditional on the sample values of the independent variables,\n\\[\n\\frac{\\hat{\\beta}_j-\\beta_j}{\\operatorname{se}\\left(\\hat{\\beta}_j\\right)} \\sim t_{n-k-1} \\quad \\text { for } j=0,1, \\ldots, k\n\\]\nwhere \\(k+1\\) is the number of unknown parameters in the population model and \\(n-k-1\\) is the d.o.f.\n\n\n\nObserve the differences!"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#single-hypothesis-testing-1",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#single-hypothesis-testing-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Single hypothesis testing",
    "text": "Single hypothesis testing\nInference on the \\(j\\)th population parameter \\(\\beta_j\\):\n\nNull hypothesis: \\(H_0: \\beta_j = b\\), where \\(b\\) is a hypothesized value typically 0\nNote that this is a test on the \\(j\\)th population parameter while holding all other parameters constant\nOne-sided alternative: \\(H_1: \\beta_j &gt; b\\) or \\(H_1: \\beta_j &lt; b\\)\nTwo-sided alternative: \\(H_1: \\beta_j \\neq b\\)\nset b= 0. Test statistic: \\(t_{\\hat{\\beta}_j} = \\frac{\\hat{\\beta}_j - b}{\\operatorname{se}(\\hat{\\beta}_j)} = \\frac{\\hat{\\beta}_j}{\\operatorname{se}(\\hat{\\beta}_j)}\\)\nWe know that the sampling distribution of \\(t_{\\hat{\\beta}_j}\\) follows‚Ä¶"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#one-sided-test",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#one-sided-test",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "One-sided test",
    "text": "One-sided test\nFix a level of significance \\(\\alpha\\) (e.g., 0.05)\n\n\n\nalternative: \\(H_1: \\beta_j &gt; 0\\) (or \\(H_1: \\beta_j &lt; 0)\\)\n\nReject \\(H_0\\) if \\(t_{\\hat{\\beta}_j} &gt; t_{\\alpha, n-k-1}^*\\)\np-value = \\(P(T &gt; t_{\\hat{\\beta}_j})\\) where \\(T \\sim t_{n-k-1}\\)\nConfidence interval: \\(\\hat{\\beta}_j \\pm t_{\\alpha, n-k-1}^* \\times \\operatorname{se}(\\hat{\\beta}_j)\\)\n\nFor large samples, t-distribution \\(\\rightarrow\\) standard normal\n\nthe critical value \\(\\approx  \\pm 1.65\\) for \\(\\alpha = 0.05\\)\n\n\n\n\n\n\nOne-sided test (right)\n\n\n\n\n\nOne-sided test (left)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#examples",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#examples",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Examples",
    "text": "Examples\n\n\n\nlibrary(wooldridge)\nnrow(meap93) - 4 - 1 # DOF\n\n[1] 403\n\nsummary(lm(math10 ~ totcomp + staff + enroll, data=meap93))\n\n\nCall:\nlm(formula = math10 ~ totcomp + staff + enroll, data = meap93)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.235  -7.008  -0.807   6.097  40.689 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.2740209  6.1137938   0.372    0.710    \ntotcomp      0.0004586  0.0001004   4.570 6.49e-06 ***\nstaff        0.0479199  0.0398140   1.204    0.229    \nenroll      -0.0001976  0.0002152  -0.918    0.359    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.24 on 404 degrees of freedom\nMultiple R-squared:  0.05406,   Adjusted R-squared:  0.04704 \nF-statistic: 7.697 on 3 and 404 DF,  p-value: 5.179e-05\n\n\n\n\nlibrary(wooldridge)\nnrow(meap93) - 4 - 1 # DOF\n\n[1] 403\n\nsummary(lm(math10 ~ log(totcomp) + log(staff) + log(enroll), data=meap93))\n\n\nCall:\nlm(formula = math10 ~ log(totcomp) + log(staff) + log(enroll), \n    data = meap93)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.735  -6.838  -0.835   6.139  39.718 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -207.6649    48.7031  -4.264 2.50e-05 ***\nlog(totcomp)   21.1550     4.0555   5.216 2.92e-07 ***\nlog(staff)      3.9800     4.1897   0.950   0.3427    \nlog(enroll)    -1.2680     0.6932  -1.829   0.0681 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.18 on 404 degrees of freedom\nMultiple R-squared:  0.06538,   Adjusted R-squared:  0.05844 \nF-statistic:  9.42 on 3 and 404 DF,  p-value: 4.974e-06"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#two-sided-test",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#two-sided-test",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Two-sided test",
    "text": "Two-sided test\nFix a level of significance \\(\\alpha\\) (e.g., 0.05)\n\n\n\nalternative: \\(H_1: \\beta_j \\neq 0\\)\n\nReject \\(H_0\\) if \\(|t_{\\hat{\\beta}_j}| &gt; t_{\\alpha/2, n-k-1}^*\\)\np-value = \\(P(|T| &gt; |t_{\\hat{\\beta}_j}|)\\)\nConfidence interval: \\(\\hat{\\beta}_j \\pm t_{\\alpha/2, n-k-1}^* \\times \\operatorname{se}(\\hat{\\beta}_j)\\)\n\nFor large samples, t-distribution \\(\\rightarrow\\) standard normal\n\nthe critical value \\(\\approx \\pm 1.96\\) for \\(\\alpha = 0.05\\)\n\n\n\n\n\n\nTwo-sided test"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#examples-1",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#examples-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Examples",
    "text": "Examples\n\nlibrary(wooldridge)\nnrow(meap93) - 4 - 1 # DOF\n\n[1] 403\n\nsummary(lm(math10 ~ log(totcomp) + log(staff) + log(enroll), data=meap93))\n\n\nCall:\nlm(formula = math10 ~ log(totcomp) + log(staff) + log(enroll), \n    data = meap93)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.735  -6.838  -0.835   6.139  39.718 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -207.6649    48.7031  -4.264 2.50e-05 ***\nlog(totcomp)   21.1550     4.0555   5.216 2.92e-07 ***\nlog(staff)      3.9800     4.1897   0.950   0.3427    \nlog(enroll)    -1.2680     0.6932  -1.829   0.0681 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.18 on 404 degrees of freedom\nMultiple R-squared:  0.06538,   Adjusted R-squared:  0.05844 \nF-statistic:  9.42 on 3 and 404 DF,  p-value: 4.974e-06"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#computing-p-values-directly-in-r",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#computing-p-values-directly-in-r",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Computing p-values directly in R",
    "text": "Computing p-values directly in R\n\np-value is the probability of observing the sample (statistic) if \\(H_0\\) is true\nIndeed you can do this using a table.\nBut R can do this for you\n\n\nt_value &lt;- 2.5    #  t-value\ndf &lt;- 100         #  degrees of freedom\n\n# Two-tailed p-value\np_value &lt;- 2 * (1 - pt(abs(t_value), df))\nprint(p_value)\n\n[1] 0.01404579\n\n# One-tailed p-value (right tail)\np_right &lt;- 1 - pt(t_value, df)\nprint(p_right)\n\n[1] 0.007022895\n\n# One-tailed p-value (left tail)\np_left &lt;- pt(t_value, df)\nprint(p_left)\n\n[1] 0.9929771"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#testing-linear-combinations",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#testing-linear-combinations",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Testing Linear combinations",
    "text": "Testing Linear combinations\n\nDoes attending \\(jc_i\\) has lower effect on wages as going to university \\(univ_i\\)? \\[log(wage_i) = \\beta_0 + \\beta_1 jc_i + \\beta_2 univ_i + \\beta_3 exper_i + u_i\\]\nWhat are we testing?\n\n\nlibrary(wooldridge)\nsummary(lm(lwage ~ jc + univ + exper, data = twoyear))\n\n\nCall:\nlm(formula = lwage ~ jc + univ + exper, data = twoyear)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.10362 -0.28132  0.00551  0.28518  1.78167 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.4723256  0.0210602  69.910   &lt;2e-16 ***\njc          0.0666967  0.0068288   9.767   &lt;2e-16 ***\nuniv        0.0768762  0.0023087  33.298   &lt;2e-16 ***\nexper       0.0049442  0.0001575  31.397   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4301 on 6759 degrees of freedom\nMultiple R-squared:  0.2224,    Adjusted R-squared:  0.2221 \nF-statistic: 644.5 on 3 and 6759 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#section-1",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#section-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "\\[log(wage_i) = \\beta_0 + \\beta_1 jc_i + \\beta_2 univ_i + \\beta_3 exper_i + u_i\\] \\(H_0: \\beta_1 = \\beta_2\\) and \\(H_1: \\beta_1 &lt; \\beta_2\\)\n\n\n\nCall \\(\\beta_1 - \\beta_2 = \\theta\\) and so \\(H_0: \\theta = 0\\) and \\(H_1: \\theta &lt; 0\\)\nTest statistic: \\(t_{\\hat{\\theta}} = \\frac{\\hat{\\theta}}{\\operatorname{se}(\\hat{\\theta})} = \\frac{\\hat{\\beta}_1 - \\hat{\\beta}_2}{\\operatorname{se}(\\hat{\\beta}_1-\\hat{\\beta}_2)} = \\frac{\\hat{\\beta}_1 - \\hat{\\beta}_2}{\\sqrt{\\operatorname{se}(\\hat{\\beta}_1)^2 + \\operatorname{se}(\\hat{\\beta}_2)^2 + 2\\widehat{\\operatorname{cov}(\\hat{\\beta}_1, \\hat{\\beta}_2)}}}\\) \nEasy to calculate \\(t_{\\hat{\\theta}}\\) if \\(\\widehat{\\operatorname{cov}(\\hat{\\beta}_1, \\hat{\\beta}_2)}\\) is known"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#implementation",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#implementation",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Implementation",
    "text": "Implementation\n\n\n\\[log(wage_i) = \\beta_0 + \\beta_1 jc_i + \\beta_2 univ_i + \\beta_3 exper_i + u_i\\] \n\\[log(wage_i) = \\beta_0 + (\\theta + \\beta_2) jc_i + \\beta_2 univ_i + \\beta_3 exper_i + u_i\\]\n\\[log(wage_i) = \\beta_0 + \\theta jc_i + \\beta_2 (jc_i + univ_i) + \\beta_3 exper_i + u_i\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#r-code",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#r-code",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "R code",
    "text": "R code\n\\[log(wage_i) = \\beta_0 + \\theta jc_i + \\beta_2 (jc_i + univ_i) + \\beta_3 exper_i + u_i\\]\n\nlibrary(wooldridge)\nsummary(lm(lwage ~ jc + I(jc + univ) + exper, data = twoyear))\n\n\nCall:\nlm(formula = lwage ~ jc + I(jc + univ) + exper, data = twoyear)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.10362 -0.28132  0.00551  0.28518  1.78167 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.4723256  0.0210602  69.910   &lt;2e-16 ***\njc           -0.0101795  0.0069359  -1.468    0.142    \nI(jc + univ)  0.0768762  0.0023087  33.298   &lt;2e-16 ***\nexper         0.0049442  0.0001575  31.397   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4301 on 6759 degrees of freedom\nMultiple R-squared:  0.2224,    Adjusted R-squared:  0.2221 \nF-statistic: 644.5 on 3 and 6759 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#testing-multiple-restrictions",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#testing-multiple-restrictions",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Testing multiple restrictions",
    "text": "Testing multiple restrictions\n\nThe \\(t\\)-test is used to test a hypothesis about a single population parameter \\(\\beta_j\\)\nThe \\(F\\)-test is used to test multiple hypotheses about multiple population parameters jointly\nExample: \\(\\log (\\text { salary }_i )=  \\beta_0+\\beta_1 \\text { years }_i +\\beta_2 \\text { gamesyr }_i +\\beta_3 \\text { bavg }_i  +\\beta_4 \\text { hrunsyr }_i +\\beta_5 \\text { rbisyr }_i +u_i\\)\n\n\\(\\mathrm{H}_0: \\beta_3=0, \\beta_4=0, \\beta_5=0\\)\n\\(\\mathrm{H}_1:\\) \\(H_0\\) is not true: At least one of \\(\\beta_3, \\beta_4, \\beta_5\\) is not zero"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#section-2",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#section-2",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "library(wooldridge)\nsummary(lm(log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr, data = mlb1))\n\n\nCall:\nlm(formula = log(salary) ~ years + gamesyr + bavg + hrunsyr + \n    rbisyr, data = mlb1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.02508 -0.45034 -0.04013  0.47014  2.68924 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.119e+01  2.888e-01  38.752  &lt; 2e-16 ***\nyears       6.886e-02  1.211e-02   5.684 2.79e-08 ***\ngamesyr     1.255e-02  2.647e-03   4.742 3.09e-06 ***\nbavg        9.786e-04  1.104e-03   0.887    0.376    \nhrunsyr     1.443e-02  1.606e-02   0.899    0.369    \nrbisyr      1.077e-02  7.175e-03   1.500    0.134    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7266 on 347 degrees of freedom\nMultiple R-squared:  0.6278,    Adjusted R-squared:  0.6224 \nF-statistic: 117.1 on 5 and 347 DF,  p-value: &lt; 2.2e-16\n\n\n\nBased on what we have learned so far, what do we think about \\(\\mathrm{H}_0: \\beta_3=0, \\beta_4=0, \\beta_5=0\\)?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#let-us-run-both-models",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#let-us-run-both-models",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Let us run both models",
    "text": "Let us run both models\n\n\nUnrestricted model\n\nlibrary(wooldridge)\nunrestricted &lt;-  lm(log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr, data = mlb1)\nsummary(unrestricted)\n\n\nCall:\nlm(formula = log(salary) ~ years + gamesyr + bavg + hrunsyr + \n    rbisyr, data = mlb1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.02508 -0.45034 -0.04013  0.47014  2.68924 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.119e+01  2.888e-01  38.752  &lt; 2e-16 ***\nyears       6.886e-02  1.211e-02   5.684 2.79e-08 ***\ngamesyr     1.255e-02  2.647e-03   4.742 3.09e-06 ***\nbavg        9.786e-04  1.104e-03   0.887    0.376    \nhrunsyr     1.443e-02  1.606e-02   0.899    0.369    \nrbisyr      1.077e-02  7.175e-03   1.500    0.134    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7266 on 347 degrees of freedom\nMultiple R-squared:  0.6278,    Adjusted R-squared:  0.6224 \nF-statistic: 117.1 on 5 and 347 DF,  p-value: &lt; 2.2e-16\n\nsum(unrestricted$residuals^2)\n\n[1] 183.1863\n\n\n\nRestricted model\n\nlibrary(wooldridge)\nrestricted &lt;-  lm(log(salary) ~ years + gamesyr, data = mlb1)\nsummary(restricted)\n\n\nCall:\nlm(formula = log(salary) ~ years + gamesyr, data = mlb1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.66858 -0.46412 -0.01177  0.49219  2.68829 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 11.223804   0.108312 103.625  &lt; 2e-16 ***\nyears        0.071318   0.012505   5.703  2.5e-08 ***\ngamesyr      0.020174   0.001343  15.023  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7527 on 350 degrees of freedom\nMultiple R-squared:  0.5971,    Adjusted R-squared:  0.5948 \nF-statistic: 259.3 on 2 and 350 DF,  p-value: &lt; 2.2e-16\n\nsum(restricted$residuals^2)\n\n[1] 198.3115\n\n\n\n\nIs the increase in SSR large enough to reject the null hypothesis?\nBut what is the test statistic that we can use?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#the-f-test",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#the-f-test",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "The F-test",
    "text": "The F-test\n\n\n\n\n\\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots + \\beta_k x_{ki} + u_i\\) \nHypotheses Test of \\(q\\) exclusion restrictions\n\n\\(H_0: \\beta_{k-q} = \\beta_{k-q+1} = \\ldots = \\beta_k = 0\\)\n\\(H_1:\\) At least one of \\(\\beta_{k-q}, \\beta_{k-q+1}, \\ldots, \\beta_k\\) is not zero\n\nTest statistic: \\(F = \\frac{(SSR_r - SSR_{ur})/q}{SSR_{ur}/(n-k-1)}\\)\n\nCan bee re-written as \\(\\frac{(R^2_{UR} - R^2_R)/q}{(1 - R^2_{UR})/(n-k-1)}\\) \nFollows an \\(F\\)-distribution with \\(q\\) and \\(n-k-1\\) d.o.f.\nNote:\n\n\\(q = dof_r - dof_{ur}\\)\nF &gt; 0\n\n\n\n\n\n\n\n\nExample F sampling distribution"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#going-back-to-the-example",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#going-back-to-the-example",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Going back to the example",
    "text": "Going back to the example\n\\(\\log(salary_i)=  \\beta_0+\\beta_1 years_i +\\beta_2 gamesyr_i +\\beta_3 bavg_i  +\\beta_4 hrunsyr_i +\\beta_5 rbisyr_i +u_i\\)\n\n\\(\\mathrm{H}_0: \\beta_3=0, \\beta_4=0, \\beta_5=0\\)\n\\(\\mathrm{H}_1:\\) \\(H_0\\) is not true.\n\n\nlibrary(wooldridge)\nunrestricted &lt;-  lm(log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr, data = mlb1)\nrestricted &lt;-  lm(log(salary) ~ years + gamesyr, data = mlb1)\nF_stat &lt;- ((sum(restricted$residuals^2) - sum(unrestricted$residuals^2))/3)/(sum(unrestricted$residuals^2)/(nrow(mlb1) - 5-1))\nprint(F_stat)\n\n[1] 9.550254\n\ncritical_F &lt;- qf(0.05, df1 = 3, df2 = nrow(mlb1) - 5-1, lower.tail = F)\nprint(critical_F)\n\n[1] 2.630641\n\nif (F_stat &gt; critical_F) {\n  print(\"Reject H0\")\n} else {\n  print(\"Fail to reject H0\")\n}\n\n[1] \"Reject H0\""
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#section-3",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#section-3",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "\\(\\log(salary_i)=  \\beta_0+\\beta_1 years_i +\\beta_2 gamesyr_i +\\beta_3 bavg_i  +\\beta_4 hrunsyr_i +\\beta_5 rbisyr_i +u_i\\)\n\n\nBut recall when we ran the unrestricted model, we found that \\(\\beta_3, \\beta_4, \\beta_5\\) were not statistically significant.\nSo, whats going on here with the joint F-test?\n\\(hrunsyr\\) and \\(rbisyr\\) are highly correlated.\n\nmulticollinearity \\(\\rightarrow\\) large standard errors \\(\\rightarrow\\) low t-stats \\(\\rightarrow\\) individual statistical insignificance\n\nThe F-test is a joint test (including bavg) and is not affected by multicollinearity\nHence F-tests of joint hypotheses can be useful in the presence of multicollinearity"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#relationship-between-t-and-f-tests",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#relationship-between-t-and-f-tests",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Relationship between t and F tests",
    "text": "Relationship between t and F tests\n\nFor a single restriction \\(q=1\\), the F-test is equivalent to the t-test\n\n\\(F_{1,n-k-1} = t^2_{n-k-1}\\)\n\nFor single hypothesis testing, the t-test is more powerful\n\nF-tests remain under-powered than t-tests (See Math refresher C)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#reporting-regression-results",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#reporting-regression-results",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Reporting Regression Results",
    "text": "Reporting Regression Results\n\nReport Estimated Coefficients\n\nInterpret key variables‚Äô estimates in economic or practical terms.\n\nInclude Standard Errors\n\nPreferred over just \\(t\\)-statistics as they help interpret hypothesis tests and confidence intervals.\n\nReport \\(R^2\\) and Other Fit Statistics\n\n\\(R^2\\) is essential for goodness-of-fit.\n\nReporting F-statistics helps test exclusion restrictions.\n\nSummarize in Tables for Multiple Models\n\nIf multiple equations are estimated, use tables instead of inline equations.\n\nDependent variable should be clearly indicated.\n\nIndependent variables should be listed in the first column.\n\nStandard errors in parentheses below estimates."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#salary-and-benefits-tradeoff-example",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#salary-and-benefits-tradeoff-example",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Salary and Benefits Tradeoff example",
    "text": "Salary and Benefits Tradeoff example\n\n\nTotal compensation (\\(totcomp\\)) consists of salary and benefits:\\[totcomp = salary + benefits = salary \\left( 1 + \\frac{benefits}{salary} \\right)\\]\nTaking the log transformation: \\(\\log(totcomp) = \\log(salary) + \\log(1 + b/s).\\)\nFor small \\(b/s\\), can approximate \\(\\log(1 + b/s) \\approx b/s.\\)\nThis leads to the econometric model:\\[\\log(salary) = \\beta_0 + \\beta_1 (b/s) + \\text{other *controls*}. \\]\nHypothesis Test: Testing the salary-benefits tradeoff:\n\n\\(H_0: \\beta_1 = -1\\) (full tradeoff)\n\\(H_1: \\beta_1 \\neq -1\\) (partial or no tradeoff)\n\nData from MEAP93 controls for enrollment, staff size, dropout, and graduation rates."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#section-4",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#section-4",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "library(stargazer, wooldridge)\nmodel1 &lt;- lm(log(salary) ~ I(benefits/salary), data = meap93)\nmodel2 &lt;- lm(log(salary) ~ I(benefits/salary) + I(log(enroll)) + I(log(staff)), data = meap93)\nmodel3 &lt;- lm(log(salary) ~ I(benefits/salary) + I(log(enroll)) + I(log(staff)) + droprate + gradrate, data = meap93)\n\nstargazer(model1, model2, model3, \n          type = \"text\", \n          title = \"Regression Results\",\n          omit.stat = c(\"ser\"), # Omit some stats if needed\n          dep.var.labels = \"Log(salary)\",\n          column.labels = c(\"Model 1\", \"Model 2\", \"Model 3\"),\n          covariate.labels = c(\"benefits to salary ratio\", \"log of enrollment\", \"log of staff\", \"Drop out rate\", \"Graduation rate\", \"Intercept\"))\n\n\nRegression Results\n================================================================================================\n                                                   Dependent variable:                          \n                         -----------------------------------------------------------------------\n                                                       Log(salary)                              \n                                 Model 1                 Model 2                 Model 3        \n                                   (1)                     (2)                     (3)          \n------------------------------------------------------------------------------------------------\nbenefits to salary ratio        -0.825***               -0.605***               -0.589***       \n                                 (0.200)                 (0.165)                 (0.165)        \n                                                                                                \nlog of enrollment                                       0.087***                0.088***        \n                                                         (0.007)                 (0.007)        \n                                                                                                \nlog of staff                                            -0.222***               -0.218***       \n                                                         (0.050)                 (0.050)        \n                                                                                                \nDrop out rate                                                                    -0.0003        \n                                                                                 (0.002)        \n                                                                                                \nGraduation rate                                                                   0.001         \n                                                                                 (0.001)        \n                                                                                                \nIntercept                       10.523***               10.844***               10.738***       \n                                 (0.042)                 (0.252)                 (0.258)        \n                                                                                                \n------------------------------------------------------------------------------------------------\nObservations                       408                     408                     408          \nR2                                0.040                   0.353                   0.361         \nAdjusted R2                       0.038                   0.348                   0.353         \nF Statistic              17.050*** (df = 1; 406) 73.386*** (df = 3; 404) 45.428*** (df = 5; 402)\n================================================================================================\nNote:                                                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/05_inference.html#modelsummary-package",
    "href": "teachingmaterials/UG_intro_metrics/05_inference.html#modelsummary-package",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "modelsummary package",
    "text": "modelsummary package\n\nlibrary(modelsummary)\nmodels &lt;- list(\n  \"Model 1\" = model1,\n  \"Model 2\" = model2,\n  \"Model 3\" = model3\n)\nmodelsummary(models, stars = TRUE, output = \"markdown\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model 1\n                Model 2\n                Model 3\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  10.523***\n                  10.844***\n                  10.738***\n                \n                \n                  \n                  (0.042)\n                  (0.252)\n                  (0.258)\n                \n                \n                  I(benefits/salary)\n                  -0.825***\n                  -0.605***\n                  -0.589***\n                \n                \n                  \n                  (0.200)\n                  (0.165)\n                  (0.165)\n                \n                \n                  I(log(enroll))\n                  \n                  0.087***\n                  0.088***\n                \n                \n                  \n                  \n                  (0.007)\n                  (0.007)\n                \n                \n                  I(log(staff))\n                  \n                  -0.222***\n                  -0.218***\n                \n                \n                  \n                  \n                  (0.050)\n                  (0.050)\n                \n                \n                  droprate\n                  \n                  \n                  -0.000\n                \n                \n                  \n                  \n                  \n                  (0.002)\n                \n                \n                  gradrate\n                  \n                  \n                  0.001\n                \n                \n                  \n                  \n                  \n                  (0.001)\n                \n                \n                  Num.Obs.\n                  408\n                  408\n                  408\n                \n                \n                  R2\n                  0.040\n                  0.353\n                  0.361\n                \n                \n                  R2 Adj.\n                  0.038\n                  0.348\n                  0.353\n                \n                \n                  AIC\n                  8070.3\n                  7913.7\n                  7912.4\n                \n                \n                  BIC\n                  8082.4\n                  7933.7\n                  7940.5\n                \n                \n                  Log.Lik.\n                  192.417\n                  272.763\n                  275.397\n                \n                \n                  F\n                  17.050\n                  73.386\n                  45.428\n                \n                \n                  RMSE\n                  0.15\n                  0.12\n                  0.12"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html",
    "title": "Econometrics PS 2",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-2",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-2",
    "title": "Econometrics PS 2",
    "section": "Question 2",
    "text": "Question 2\nDifferent states have different minimum wages. For example:\n\nAlabama, Georgia, Mississippi: $7.25/hour (federal minimum)\nFlorida: $12.00/hour\n\nNew York: $15.00/hour\nCalifornia: $15.50/hour\n\nYou want to estimate the effect of minimum wage on employment rates using data from different counties in the US indexed by c. You consider two regression specifications:\n\\text{employment rate}_c = \\beta_0 + \\beta_1 \\text{min\\_wage}_c + u_c \\quad (1)\n\\text{employment rate}_c = \\beta_0 + \\beta_1 \\text{min\\_wage}_c + \\beta_2 \\text{avg\\_wage}_c + u_c \\quad (2)\nwhere avg_wage is the average wage in the county and min_wage is the minimum wage in the county (which is the same as the state minimum wage for all counties in that state).\nWhich model correctly estimates the effect of minimum wage on employment and why?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-3",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-3",
    "title": "Econometrics PS 2",
    "section": "Question 3",
    "text": "Question 3\nLoad the wooldridge library and using the wage1 dataset, youa re interested in documenting the gender wage gap.\n\nStart with running the following regression: log(wage_i) = \\beta_0 + \\beta_1 \\, female_i + u_i where female is a binary variable that takes the value 1 if the worker is female and 0 otherwise. Interpret the coefficient on female.\nIn estimating the average gender wage gap, why did we not include a dummy variable for male in the regression above?\nNow include educ (years of education), exper (years of experience), and tenure (years with current employer) in your analysis. How and why does the inclusion of these variables affect the coefficient on female? (Report the estimates side by side using the stargazer or modelsummary package).\nNow suppose someone asks you does an additional year of education effects wages differently for male and female workers. How would you modify your regression to answer this question? Run the regression and interpret the relevant coefficients.\nDo you think adding any other variables non-linearly will be helpful? If so, which ones and do your best to show data patterns to support your argument? (You do not need to run any regressions for this part)."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-4",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-4",
    "title": "Econometrics PS 2",
    "section": "Question 4",
    "text": "Question 4\n\nProblem C6 Wooldridge Chapter 3.\nHow is this different from the partialling out analysis we did in class? Explain briefly."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-5",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps2.html#question-5",
    "title": "Econometrics PS 2",
    "section": "Question 5",
    "text": "Question 5\n\nProblem C13 Wooldridge Chapter 3."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps4.html",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps4.html",
    "title": "Econometrics PS 4",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps4.html#simplified-angrist-and-krueger-1991-replication",
    "href": "teachingmaterials/UG_intro_metrics/ps/ugmetricsps4.html#simplified-angrist-and-krueger-1991-replication",
    "title": "Econometrics PS 4",
    "section": "Simplified Angrist and Krueger (1991) Replication",
    "text": "Simplified Angrist and Krueger (1991) Replication\nYou will need libraries AER, ggplot2, and lmtest for this problem set.\nRecall the context of our quiz on Instrumental Variables based on Angrist and Krueger (1991). Load iv_csl_dataset.csv in R using read.csv function. It contains a simplified simulated dataset based on Angrist and Krueger (1991). The variable qob indicates the quarter of birth of individual i (Q1, Q2, Q3, Q4). The rest should be self-explanatory.\nWe study the causal effect of education on earnings, controlling for a bunch of other included exogenous variables.  \\ln(Wage_i) = \\beta_0 + \\beta_1 Educ_i + \\beta_3 Age_i + \\beta_4 Region_i + u_i  where Wage is the annual wage of individual i, Educ is years of education, Age is age in years, and Region is a categorical variable indicating the region of residence (representing region fixed effects) which includes the , and clearly E(u_i|Educ_i) \\neq 0 so E(u_i | Educ_i, Age_i, Region_i) \\neq 0 as well.\n\nQuestion 1\nExplore the dataset and report summary statistics of the variables\n\n\nQuestion 2\nMake two plots and describe what you see in each plot:\n\nmean years of education by quarter of birth\nmean log wage by quarter of birth\n\n\n\nQuestion 3\nGenerate a dummy variable Z equal to 1 if an individual was born in Quarter 1, and 0 otherwise. Explain why Z is a valid instrument for Educ in the above regression.\n\n\nQuestion 4\nEstimate the 1st stage regression. Be careful to include the other exogenous variables in the regression. Report and interpret the results. See slide 39.\n\n\nQuestion 5\nPredict the values of Educ using the 1st stage regression and save them in a new variable called Educ_hat. Estimate the 2nd stage regression of ln(Wage) on Educ_hat and the other exogenous variables. Report and interpret the results. See slide 39 & 40.\n\n\nQuestion 6\nNow instead of manually doing the 2SLS procedure, use the ivreg function from the AER package to estimate the IV regression of ln(Wage) on Educ, using Z as an instrument for Educ, and including the other exogenous variables. Compare the results. What differs and why?\nUse summary(yourivmodel, diagnostics = TRUE) to see the diagnostic tests and interpret whether the instrument is weak or not.\n\n\nQuestion 7\nExplain why your estimate is a Local Average Treatment Effect and for whom it is identified."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html",
    "title": "Econometrics PS 2 - Solution key",
    "section": "",
    "text": "Md Moshi Ul Alam\n      Assistant Professor of Economics\n      \n        Clark University\n      \n      \n        \n          \n          Email\n        \n        \n          \n          CV"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-a",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-a",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (a)",
    "text": "Part (a)\n\ndata(lawsch85)\n\nmodel1 &lt;- lm(lsalary ~ GPA + rank , data = lawsch85)\nmodel2 &lt;- lm(lsalary ~ GPA + rank  + age, data = lawsch85)\nmodel3 &lt;- lm(lsalary ~ GPA + rank  + clsize, data = lawsch85)\n\nstargazer(model1, model2, model3, type = \"text\",\n          title = \"Law School Salary Regressions\",\n          dep.var.labels = \"Log(Salary)\",\n          covariate.labels = c(\"GPA\", \"Rank\", \"Age\", \"Class Size\"),\n          keep.stat = c(\"n\", \"rsq\", \"adj.rsq\"))\n\n\nLaw School Salary Regressions\n==========================================\n                  Dependent variable:     \n             -----------------------------\n                      Log(Salary)         \n                (1)       (2)       (3)   \n------------------------------------------\nGPA          0.294***  0.295***  0.337*** \n              (0.069)   (0.083)   (0.070) \n                                          \nRank         -0.004*** -0.004*** -0.004***\n             (0.0003)  (0.0004)  (0.0003) \n                                          \nAge                     0.0002            \n                       (0.0004)           \n                                          \nClass Size                       0.0003***\n                                 (0.0001) \n                                          \nConstant     9.899***  9.860***  9.675*** \n              (0.245)   (0.293)   (0.255) \n                                          \n------------------------------------------\nObservations    142       99        139   \nR2             0.824     0.804     0.838  \nAdjusted R2    0.821     0.797     0.834  \n==========================================\nNote:          *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nInterpretations are straightforward. I expect students to specify that these are average effects, all else equal, and being careful on not making causal statements instead specify them as associations.\nInclusion of class size seemingly increases the effect of GPA, while inclusion of age has no discernible effect on the GPA coefficient.\nThe reason why I say ‚Äúseemingly‚Äù is because the change when eye-balled with the standard errors gives confidence intervals that gives the upper end of model 2‚Äôs coefficient‚Äôs 95% CI at 0.458 and the lower end of model 3‚Äôs coefficient‚Äôs 95% CI at 0.2, which overlap. Before making statistical claims, we need to formally test equality of coefficients across models."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-b",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-b",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (b)",
    "text": "Part (b)\nModel 2‚Äôs R-squared is lower than Model 1‚Äôs, despite adding a variable. This happens because there are missing values leading to lower number of observations. You can check this by looking at the number of observations in each model when estimation results are produced, and further clarify by running:\n\nsummary(lawsch85$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   3.00   63.50   85.00   85.82  112.50  206.00      45 \n\n\nwhich shows 45 missing values of age."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-a-1",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-a-1",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (a)",
    "text": "Part (a)\n\nlibrary(wooldridge)\nmodel_gender1 &lt;- lm(lwage ~ female, data = wage1)\nsummary(model_gender1)\n\n\nCall:\nlm(formula = lwage ~ female, data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05123 -0.31774 -0.04889  0.35548  1.65773 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.81357    0.02981  60.830   &lt;2e-16 ***\nfemale      -0.39722    0.04307  -9.222   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4935 on 524 degrees of freedom\nMultiple R-squared:  0.1396,    Adjusted R-squared:  0.138 \nF-statistic: 85.04 on 1 and 524 DF,  p-value: &lt; 2.2e-16\n\n\nOn average, female workers earn approximately 39.73% less than male workers. The exact percentage difference is (e^{-0.3972} - 1) \\times 100 = -32.8\\% accounting for the log transformation."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-b-1",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-b-1",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (b)",
    "text": "Part (b)\nWe don‚Äôt include both female and male dummies because of Perfect multicollinearity: female + male = 1 for every observation. So we need to omit one category to avoid this issue. ## Part (c)\n\nmodel_gender2 &lt;- lm(lwage ~ female + educ + exper + tenure, data = wage1)\n\nstargazer(model_gender1, model_gender2, type = \"text\",\n          title = \"Gender Wage Gap Analysis\",\n          dep.var.labels = \"Log(Wage)\",\n          covariate.labels = c(\"Female\", \"Education\", \"Experience\", \"Tenure\"),\n          keep.stat = c(\"n\", \"rsq\", \"adj.rsq\"))\n\n\nGender Wage Gap Analysis\n=========================================\n                 Dependent variable:     \n             ----------------------------\n                      Log(Wage)          \n                  (1)            (2)     \n-----------------------------------------\nFemale         -0.397***      -0.301***  \n                (0.043)        (0.037)   \n                                         \nEducation                     0.087***   \n                               (0.007)   \n                                         \nExperience                    0.005***   \n                               (0.002)   \n                                         \nTenure                        0.017***   \n                               (0.003)   \n                                         \nConstant        1.814***      0.501***   \n                (0.030)        (0.102)   \n                                         \n-----------------------------------------\nObservations      526            526     \nR2               0.140          0.392    \nAdjusted R2      0.138          0.388    \n=========================================\nNote:         *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nThe coefficient on female decreases from -0.397 to -0.301 (becomes less negative). But be careful of claiming this statistically. Recall the CI based explanation above.\nHowever, typically in gender gap empirical problems after controlling a bunch of different variables which are expected to differ between gender and also matter for the labor outcomes, one typically observes statistically lower estimates of gender wage gap than raw gender wage gap. This is even more typical of estimate in larger samples which also will give tighter confidence intervals. Part of the raw gender gap are due to differences in: Education levels between genders, Work experience between genders and Job tenure between genders, among other differences. You can read more on this by yourself, but occupational differences account for a majority of the raw gender wage gap, and depending on the country, hours worked and which hours are worked also matter."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-d",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-d",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (d)",
    "text": "Part (d)\n\nmodel_gender3 &lt;- lm(lwage ~ female + educ + female:educ + exper + tenure, data = wage1)\nsummary(model_gender3)\n\n\nCall:\nlm(formula = lwage ~ female + educ + female:educ + exper + tenure, \n    data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.91695 -0.26530 -0.02059  0.25715  1.27586 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.464712   0.122892   3.781 0.000174 ***\nfemale      -0.210376   0.173969  -1.209 0.227107    \neduc         0.090276   0.008715  10.359  &lt; 2e-16 ***\nexper        0.004642   0.001628   2.850 0.004541 ** \ntenure       0.017436   0.002981   5.849 8.76e-09 ***\nfemale:educ -0.007245   0.013562  -0.534 0.593456    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4162 on 520 degrees of freedom\nMultiple R-squared:  0.3926,    Adjusted R-squared:  0.3868 \nF-statistic: 67.22 on 5 and 520 DF,  p-value: &lt; 2.2e-16\n\n\nWe add an interaction term female √ó educ to allow education returns to vary by gender.\n\nBase education effect (for males): 9.02% return per year\nAdditional returns for females: -0.7% per year (interaction term) but it is statistically insginifcant (t-stat = - 0.534).\nThus education returns for females cannot be claimed to be statistically different from males"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-e",
    "href": "teachingmaterials/UG_intro_metrics/pssol/ps2sol.html#part-e",
    "title": "Econometrics PS 2 - Solution key",
    "section": "Part (e)",
    "text": "Part (e)\nLets residualize lwage from educ exper female and tenure to see how the data pattern looks with exper^2 and tenure^2 after expunging variation in lwage from educ exper female and tenure.\n\nmodel_resid &lt;- lm(lwage ~ educ + female + exper + tenure, data = wage1)\nwage1$residuals &lt;- resid(model_resid)\n\npar(mfrow = c(1, 2))\nplot((wage1$exper)^2, wage1$residuals, main = \"Residualized Log Wage \\n vs Experience squared\", \n     xlab = \"Experience\", ylab = \"Residualized Log Wage\", col = rgb(0,0,1,0.3), pch = 19)\nlines(lowess((wage1$exper)^2, wage1$residuals), col = \"red\", lwd = 2)\nplot((wage1$tenure)^2, wage1$residuals, main = \"Residualized Log Wage\\n  vs Tenure squared\",\n     xlab = \"Tenure\", ylab = \"Residualized Log Wage\", col = rgb(0,0,1,0.3), pch = 19)\nlines(lowess((wage1$tenure)^2, wage1$residuals), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nThese patterns suggest adding exper¬≤ and tenure¬≤ diminishing marginal returns to experience and tenure commonly observed in labor economics.. Adding these non-linearities could improve model fit."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#introduction",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#introduction",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nData scaling\nStandardized coefficients\nNonlinearities in X\nInteraction terms\nAverage partial effects\nAdjusted R-squared\nOver fitting"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#data-scaling",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#data-scaling",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Data Scaling",
    "text": "Data Scaling\n\nlibrary(wooldridge); library(stargazer);\nmodel1 &lt;- lm(bwght ~ cigs + faminc, bwght) # bwght in grams\nmodel2 &lt;- lm(I(bwght/16) ~ cigs + faminc, bwght) # bwght in pounds\nbwght$packs &lt;- bwght$cigs/20 # 1 pack =  20 cigs\nmodel3 &lt;- lm(bwght ~ packs + faminc, bwght) # use packs instead of cigs\nstargazer(model1, model2, model3, type = \"text\")\n\n\n=================================================================\n                                       Dependent variable:       \n                                ---------------------------------\n                                  bwght    I(bwght/16)   bwght   \n                                   (1)         (2)        (3)    \n-----------------------------------------------------------------\ncigs                            -0.463***   -0.029***            \n                                 (0.092)     (0.006)             \n                                                                 \npacks                                                  -9.268*** \n                                                        (1.832)  \n                                                                 \nfaminc                           0.093***   0.006***    0.093*** \n                                 (0.029)     (0.002)    (0.029)  \n                                                                 \nConstant                        116.974***  7.311***   116.974***\n                                 (1.049)     (0.066)    (1.049)  \n                                                                 \n-----------------------------------------------------------------\nObservations                      1,388       1,388      1,388   \nR2                                0.030       0.030      0.030   \nAdjusted R2                       0.028       0.028      0.028   \nResidual Std. Error (df = 1385)   20.063      1.254      20.063  \nF Statistic (df = 2; 1385)      21.274***   21.274***  21.274*** \n=================================================================\nNote:                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#data-scaling-1",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#data-scaling-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Data Scaling",
    "text": "Data Scaling\n\nCoefficients in a regression model are sensitive to the units of measurement\n\n\n\nThe population model: \\(bwght_i = \\beta_0 + \\beta_1 cigs_i + \\beta_2 faminc + u_i\\) follows MLR 1-5\n\\(bwght_i/16 = \\beta_0/16 + \\beta_1/16 cigs_i + \\beta_2/16 faminc + u_i\\)\n\nCoefficients scaled down by factor with which dependent variable is scaled\n\n\\(bwhgt_i = \\beta_0 + 20\\beta_1 cigs_i/20 + \\beta_2 faminc + u_i\\)\n\nwhich simplifies to \\(bwhgt_i = \\beta_0 + 20\\beta_1 packs_i + \\beta_2 faminc + u_i\\)\nCoefficients scaled up by factor with which independent variable is scaled\n\nWhat about SE? R^2?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#standardized-coefficients",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#standardized-coefficients",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Standardized Coefficients",
    "text": "Standardized Coefficients\nInstead of asking what happens to \\(y\\) when \\(x\\) changes by 1 unit, we ask what happens to \\(y\\) when \\(x\\) changes by 1 standard deviation\n\nThis is useful because:\n\n\\(x\\) may be measured in different units in different datasets\n\\(x\\) may be a composite index of several variables\n\\(x\\) could be scaled up or down differently in different datasets. E.g. GPA\n\nBut s.d. effects are only useful when interpreted relative to the mean of \\(x\\)\n\nSo the standardized \\(x_i\\) is \\(x^* = (x_i - \\bar{x})/s_x\\)\n\nThus from the population model: \\(y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k + u\\)\n\nThe standardized model is: \\(y = \\beta_0^* + \\beta_1^* x_1^* + \\ldots + \\beta_k^* x_k^* + u^*\\)\n\nwhere \\(\\beta_j^* =  \\frac{s_{x_j}}{s_y}\\beta_j\\) for \\(j = 1, \\ldots, k\\)\n\n\nHow would you derive this?\nThis is easy to implement in R using scale() function"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#standardized-coefficients-1",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#standardized-coefficients-1",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Standardized Coefficients",
    "text": "Standardized Coefficients\n\n\nScaled estimation:\n\nmodel4 &lt;- lm(scale(bwght) ~ scale(cigs) + scale(faminc), bwght)\nstargazer(model1, model4, type = \"text\", omit.stat = c(\"f\", \"ser\"))\n\n\n==========================================\n                  Dependent variable:     \n              ----------------------------\n                  bwght      scale(bwght) \n                   (1)            (2)     \n------------------------------------------\ncigs            -0.463***                 \n                 (0.092)                  \n                                          \nfaminc           0.093***                 \n                 (0.029)                  \n                                          \nscale(cigs)                    -0.136***  \n                                (0.027)   \n                                          \nscale(faminc)                  0.085***   \n                                (0.027)   \n                                          \nConstant        116.974***      -0.000    \n                 (1.049)        (0.026)   \n                                          \n------------------------------------------\nObservations      1,388          1,388    \nR2                0.030          0.030    \nAdjusted R2       0.028          0.028    \n==========================================\nNote:          *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\nCompute manually:\n\nmodel1$coef[\"cigs\"]* sd(bwght$cigs)/sd(bwght$bwght)\n\n      cigs \n-0.1359828 \n\nmodel1$coef[\"faminc\"]* sd(bwght$faminc)/sd(bwght$bwght)\n\n    faminc \n0.08540571"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#more-examples",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#more-examples",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "More examples",
    "text": "More examples\nprice \\(=\\beta_0+\\beta_1\\) nox \\(+\\beta_2\\) crime \\(+\\beta_3\\) rooms \\(+\\beta_4\\) dist \\(+\\beta_5\\) stratio \\(+u\\)\n\n\n\nlibrary(wooldridge)\nsummary(lm(price ~ nox + crime + rooms + dist + stratio, hprice2))\n\n\nCall:\nlm(formula = price ~ nox + crime + rooms + dist + stratio, data = hprice2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13914  -3201   -662   2110  38064 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 20871.13    5054.60   4.129 4.27e-05 ***\nnox         -2706.43     354.09  -7.643 1.09e-13 ***\ncrime        -153.60      32.93  -4.665 3.97e-06 ***\nrooms        6735.50     393.60  17.112  &lt; 2e-16 ***\ndist        -1026.81     188.11  -5.459 7.57e-08 ***\nstratio     -1149.20     127.43  -9.018  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5586 on 500 degrees of freedom\nMultiple R-squared:  0.6357,    Adjusted R-squared:  0.632 \nF-statistic: 174.5 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nsummary(lm(scale(price) ~ scale(nox) + scale(crime) + scale(rooms) + scale(dist) + scale(stratio), hprice2))\n\n\nCall:\nlm(formula = scale(price) ~ scale(nox) + scale(crime) + scale(rooms) + \n    scale(dist) + scale(stratio), data = hprice2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5110 -0.3476 -0.0719  0.2291  4.1334 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     2.327e-16  2.697e-02   0.000        1    \nscale(nox)     -3.404e-01  4.454e-02  -7.643 1.09e-13 ***\nscale(crime)   -1.433e-01  3.072e-02  -4.665 3.97e-06 ***\nscale(rooms)    5.139e-01  3.003e-02  17.112  &lt; 2e-16 ***\nscale(dist)    -2.348e-01  4.302e-02  -5.459 7.57e-08 ***\nscale(stratio) -2.703e-01  2.997e-02  -9.018  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6066 on 500 degrees of freedom\nMultiple R-squared:  0.6357,    Adjusted R-squared:  0.632 \nF-statistic: 174.5 on 5 and 500 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#functional-forms",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#functional-forms",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Functional forms",
    "text": "Functional forms\nRecall from lecture 1\n\n\n\nSpecification\nChange in x\nEffect on y\n\n\n\n\nLevel-level\n+1 unit\n+\\(b_1\\) units\n\n\nLevel-log\n+1%\n+\\(\\frac{b_1}{100}\\) units\n\n\nLog-level\n+1 unit\n+\\((100 \\times b_1)\\%\\)\n\n\nLog-log\n+1%\n+\\(b_1\\%\\)"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#nonlinearities-in-x",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#nonlinearities-in-x",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Nonlinearities in X",
    "text": "Nonlinearities in X\n\\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{1i}^2 + \\beta_3 x_{2i} + u_i\\]\n\\[\\frac{\\partial y}{\\partial x_{1i}} = \\beta_1 + 2\\beta_2 x_{1i}\\]\nDiscuss the nature of price change of houses with respect to number of rooms:\n\nlm(log(price) ~ log(nox) + log(dist) + rooms + I(rooms^2), hprice2)\n\n\nCall:\nlm(formula = log(price) ~ log(nox) + log(dist) + rooms + I(rooms^2), \n    data = hprice2)\n\nCoefficients:\n(Intercept)     log(nox)    log(dist)        rooms   I(rooms^2)  \n   12.87147     -0.88558     -0.04421     -0.72860      0.08004  \n\n\n\n\nBased on estimates how does price change as # of rooms go up?\nIncreasing or decreasing rates?\nAre there tipping points?\n\n\\(|\\beta_1/2\\beta_2|\\) is the tipping point for \\(y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{1i}^2 + \\beta_3 x_{3i} + u_i\\) when \\(x_{1i}\\) changes"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#interaction-terms",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#interaction-terms",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Interaction terms",
    "text": "Interaction terms\n\n\n\\(p =  \\beta_0 + \\beta_1 sqrft + \\beta_2 bdrms + \\beta_3 sqrft \\times bdrms + \\beta_4 bthrms +u\\)\nWe can formalize it with conditional expecations:\n\\(E(p|sqrft, bdrms, bthrms) = \\beta_0 + \\beta_1 sqrft + \\beta_2 bdrms + \\beta_3 sqrft \\times bdrms + \\beta_4 bthrms\\)\n\\[\\frac{\\partial E(p|sqrft, bdrms, bthrms)}{\\partial bdrms} = \\beta_2 + \\beta_3 sqrft\\]\nSo at sqrft = \\(\\bar{sqrft}\\), the effect of bdrms on price is \\(\\beta_2 + \\beta_3 \\bar{sqrft}\\)\nEasy to obtain given \\(\\hat{\\beta}_2\\) and \\(\\hat{\\beta}_3\\) and \\(\\bar{sqrft}\\)\nSimilarly in the previous slide \\(\\frac{\\partial E(y | x_1 = \\bar{x_1}, x_2)}{\\partial x_1} = \\beta_1 + 2\\beta_2 \\bar{x_1}\\)\n\n\n\nmodel &lt;-  lm(price ~ sqrft + bdrms + I(sqrft * bdrms), data = hprice1)\n model$coefficients[\"bdrms\"] + model$coefficients[\"I(sqrft * bdrms)\"] * mean(hprice1$sqrft)\n\n   bdrms \n11.26181"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#adjusted-r-squared",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#adjusted-r-squared",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\n\nRecall Econ 160\nAdjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in the model.\nCompare goodness of fit of models with different numbers of X‚Äôs. \\[\\text{Adjusted-}R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right)\\] \\(R^2\\) is the R-squared value, \\(n\\) is the # observations and \\(k\\) is the number of X‚Äôs\n\nPenalizes the addition of unnecessary predictors\n\nThe F-test could be related to the adjusted R-squared. (next topic)\n\nCan be written into \\(UR\\) and \\(R\\) models for the F-test\nF-test is useful when models are nested"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#overfittingovercontrolling",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#overfittingovercontrolling",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Overfitting/overcontrolling",
    "text": "Overfitting/overcontrolling\n\nIncluding too many controls can distort causal interpretation.\n\nExample: Estimating the effect of beer tax on traffic fatalities ins tates:\n\n\\[\n\\text{fatalities}_s = \\beta_0 + \\beta_1 \\text{tax}_s + \\beta_2 \\text{miles}_s + \\beta_3 \\text{percmale}_s + \\beta_4 \\text{perc16_21}_s + \\dots\n\\]\n\nShould we control for beer consumption (beercons)?\n\nNo, it mediates the effect of tax on fatalities.\n\nControlling for it absorbs the policy impact."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#the-problem-of-overcontrolling",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#the-problem-of-overcontrolling",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "The Problem of Overcontrolling",
    "text": "The Problem of Overcontrolling\n\nOvercontrolling can remove meaningful variation in key variables.\n\nExample: Estimating the effect of pesticides on health costs:\n\nControlling for doctor visits blocks part of the effect.\n\nAnother case: School quality ‚Üí earnings:\n\nIf quality raises education, controlling for education understates its impact.\n\nTakeaway: Control variables should reflect causal logic, not just maximize \\(R^2\\)."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#binary-variables",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#binary-variables",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Binary variables",
    "text": "Binary variables\n\n\nBinary variables are {0,1} variables. E.g. female, married, smoker\nExample: Estimating the effect of gender on wages:\n\\(wage_i = \\beta_0 + \\delta_0 female_i + \\beta_1 educ_i + u_i\\)\n\\(\\delta_0=\\mathrm{E}( wage_i \\mid female_i =1, educ_i )-\\mathrm{E}( wage_i \\mid female_i =0, educ_i )\\)\nDifference in wages between females and males, holding education constant.\nIf \\(\\delta_0 &lt; 0\\), women earn less than men on average, given education.\n\nMales are the base group (\\(\\beta_0\\) is their intercept)[draw]\n\nIncluding both male and female leads to perfect collinearity.\nAlternatively: \\(wage_i = \\alpha_0 + \\gamma_0 male_i + \\beta_1 educ_i + u_i\\)\n\nHere, females are the base group."
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#tests-for-wage-discrimination",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#tests-for-wage-discrimination",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "tests for wage discrimination",
    "text": "tests for wage discrimination\nwage \\(=\\beta_0+\\delta_0\\) female \\(+\\beta_1\\) educ \\(+\\beta_2\\) exper \\(+\\beta_3\\) tenure \\(+u\\)\n\nlibrary(wooldridge)\nsummary( lm(wage ~ female + educ + exper + tenure, data = wage1))\n\n\nCall:\nlm(formula = wage ~ female + educ + exper + tenure, data = wage1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.7675 -1.8080 -0.4229  1.0467 14.0075 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.56794    0.72455  -2.164   0.0309 *  \nfemale      -1.81085    0.26483  -6.838 2.26e-11 ***\neduc         0.57150    0.04934  11.584  &lt; 2e-16 ***\nexper        0.02540    0.01157   2.195   0.0286 *  \ntenure       0.14101    0.02116   6.663 6.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.958 on 521 degrees of freedom\nMultiple R-squared:  0.3635,    Adjusted R-squared:  0.3587 \nF-statistic:  74.4 on 4 and 521 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#multiple-categories",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#multiple-categories",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Multiple categories",
    "text": "Multiple categories\nMarital status and gender: \\[\nlog(wage_i) = \\beta_0 + \\beta_1 marriedmale_i + \\beta_2 marriedfemale_i + \\beta_3 unmarriedfemale_i \\\\\n+ \\beta_4 educ_i + \\beta_5 exper_i + \\beta_6 tenure_i + \\beta_7 exper^2_i + \\beta_8 tenure^2_i + u_i\\] What is the base group?\n\nsummary(lm(log(wage) ~ I(married*(1-female)) + I(married*female) + I((1-married)*female) + educ + exper + tenure + I(exper^2) + I(tenure^2), data = wage1) )\n\n\nCall:\nlm(formula = log(wage) ~ I(married * (1 - female)) + I(married * \n    female) + I((1 - married) * female) + educ + exper + tenure + \n    I(exper^2) + I(tenure^2), data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89697 -0.24060 -0.02689  0.23144  1.09197 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                0.3213781  0.1000090   3.213 0.001393 ** \nI(married * (1 - female))  0.2126757  0.0553572   3.842 0.000137 ***\nI(married * female)       -0.1982676  0.0578355  -3.428 0.000656 ***\nI((1 - married) * female) -0.1103502  0.0557421  -1.980 0.048272 *  \neduc                       0.0789103  0.0066945  11.787  &lt; 2e-16 ***\nexper                      0.0268006  0.0052428   5.112 4.50e-07 ***\ntenure                     0.0290875  0.0067620   4.302 2.03e-05 ***\nI(exper^2)                -0.0005352  0.0001104  -4.847 1.66e-06 ***\nI(tenure^2)               -0.0005331  0.0002312  -2.306 0.021531 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3933 on 517 degrees of freedom\nMultiple R-squared:  0.4609,    Adjusted R-squared:  0.4525 \nF-statistic: 55.25 on 8 and 517 DF,  p-value: &lt; 2.2e-16\n\n\n\nWhat is the wage gap between married females and unmarried females?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#interactions-with-dummy-variables",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#interactions-with-dummy-variables",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Interactions with dummy variables",
    "text": "Interactions with dummy variables\nWhat is the point of interacting: Marital status X gender?\n\\[\nlog(wage_i) = \\beta_0 + \\beta_1  female_i + \\beta_2 married_i + \\beta_3 married_i * female_i \\\\\n+ \\beta_4 educ_i + \\beta_5 exper_i + \\beta_6 tenure_i + \\beta_7 exper^2_i + \\beta_8 tenure^2_i + u_i\\]\n\nsummary(lm(log(wage) ~ female + married + I((married)*female) + educ + exper + tenure + I(exper^2) + I(tenure^2), data = wage1))\n\n\nCall:\nlm(formula = log(wage) ~ female + married + I((married) * female) + \n    educ + exper + tenure + I(exper^2) + I(tenure^2), data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89697 -0.24060 -0.02689  0.23144  1.09197 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            0.3213781  0.1000090   3.213 0.001393 ** \nfemale                -0.1103502  0.0557421  -1.980 0.048272 *  \nmarried                0.2126757  0.0553572   3.842 0.000137 ***\nI((married) * female) -0.3005931  0.0717669  -4.188 3.30e-05 ***\neduc                   0.0789103  0.0066945  11.787  &lt; 2e-16 ***\nexper                  0.0268006  0.0052428   5.112 4.50e-07 ***\ntenure                 0.0290875  0.0067620   4.302 2.03e-05 ***\nI(exper^2)            -0.0005352  0.0001104  -4.847 1.66e-06 ***\nI(tenure^2)           -0.0005331  0.0002312  -2.306 0.021531 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3933 on 517 degrees of freedom\nMultiple R-squared:  0.4609,    Adjusted R-squared:  0.4525 \nF-statistic: 55.25 on 8 and 517 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#different-slopes",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#different-slopes",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Different slopes",
    "text": "Different slopes\n\nDo men and women have different returns to education?\n\\(wage_i = \\beta_0 + \\beta_1 educ_i + \\beta_2 female_i + \\beta_3 educ_i * female_i + u_i\\)\n\\(E(wage_i | educ_i, female_i = 1) - E(wage_i | educ_i, female_i = 0) = \\beta_3 educ_i\\)\n\\(\\uparrow\\) educ by 1 unit \\(\\uparrow\\) wage by \\(\\beta_1 + \\beta_3\\) for females and \\(\\beta_1\\) for males. \n\n\nsummary(lm(log(wage) ~ educ + female + I(educ*female) + exper + expersq + tenure + tenursq, data = wage1))\n\n\nCall:\nlm(formula = log(wage) ~ educ + female + I(educ * female) + exper + \n    expersq + tenure + tenursq, data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.83265 -0.25261 -0.02374  0.25396  1.13584 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       0.3888060  0.1186871   3.276  0.00112 ** \neduc              0.0823692  0.0084699   9.725  &lt; 2e-16 ***\nfemale           -0.2267886  0.1675394  -1.354  0.17644    \nI(educ * female) -0.0055645  0.0130618  -0.426  0.67028    \nexper             0.0293366  0.0049842   5.886 7.11e-09 ***\nexpersq          -0.0005804  0.0001075  -5.398 1.03e-07 ***\ntenure            0.0318967  0.0068640   4.647 4.28e-06 ***\ntenursq          -0.0005900  0.0002352  -2.509  0.01242 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4001 on 518 degrees of freedom\nMultiple R-squared:  0.441, Adjusted R-squared:  0.4334 \nF-statistic: 58.37 on 7 and 518 DF,  p-value: &lt; 2.2e-16\n\n\n\nWhat is the gender gap at the average education level?"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#different-models-for-diff-groups",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#different-models-for-diff-groups",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Different models for diff groups",
    "text": "Different models for diff groups\n\\[\nGPA_i =\\beta_0+\\beta_1  SAT_i +\\beta_2  hsrankperc_i +\\beta_3  tothrs_i +u_i\n\\]\n\nFor any of the slopes to depend on gender, we simply interact it with \\(female_i\\), and include it\nTo test if the model is different between men and women, then we need a model where the intercept and all slopes can be different across the two groups\n\n\\[\n\\begin{aligned}\nGPA_i = & \\beta_0+\\beta_1  sat_i +\\beta_2  hsperc_i   +\\beta_3  tothrs_i \\\\\n& +\\delta_0  female_i  +\\delta_1  female_i  *  sat_i +\\delta_2  female_i  *  hsperc_i +\\delta_3  female_i  *  tothrs_i  \\\\\n& +u_i\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#section",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#section",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "",
    "text": "summary(lm(cumgpa ~ sat + hsperc + tothrs, data = gpa3))\n\n\nCall:\nlm(formula = cumgpa ~ sat + hsperc + tothrs, data = gpa3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01959 -0.42768  0.04212  0.45355  2.90131 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.9291105  0.2285515   4.065 5.32e-05 ***\nsat          0.0009028  0.0002079   4.343 1.60e-05 ***\nhsperc      -0.0063791  0.0015678  -4.069 5.24e-05 ***\ntothrs       0.0119779  0.0009314  12.860  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8671 on 728 degrees of freedom\nMultiple R-squared:  0.2354,    Adjusted R-squared:  0.2323 \nF-statistic: 74.72 on 3 and 728 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nsummary(lm(cumgpa ~ sat + hsperc + tothrs + female + I(sat*female) + I(hsperc*female) + I(tothrs*female), data = gpa3)) \n\n\nCall:\nlm(formula = cumgpa ~ sat + hsperc + tothrs + female + I(sat * \n    female) + I(hsperc * female) + I(tothrs * female), data = gpa3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.08519 -0.39944  0.05277  0.45862  2.73325 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         1.214e+00  2.648e-01   4.584 5.37e-06 ***\nsat                 6.113e-04  2.350e-04   2.601 0.009484 ** \nhsperc             -5.967e-03  1.776e-03  -3.359 0.000823 ***\ntothrs              1.030e-02  1.093e-03   9.425  &lt; 2e-16 ***\nfemale             -1.114e+00  5.285e-01  -2.107 0.035460 *  \nI(sat * female)     1.117e-03  5.000e-04   2.233 0.025832 *  \nI(hsperc * female)  5.076e-05  4.103e-03   0.012 0.990132    \nI(tothrs * female)  5.560e-03  2.070e-03   2.686 0.007386 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8591 on 724 degrees of freedom\nMultiple R-squared:  0.2537,    Adjusted R-squared:  0.2464 \nF-statistic: 35.15 on 7 and 724 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#heteroskedasticity-to-be-covered-by-zeyi-in-the-lab",
    "href": "teachingmaterials/UG_intro_metrics/06_mlrvariants.html#heteroskedasticity-to-be-covered-by-zeyi-in-the-lab",
    "title": "Econ 265: Introduction to Econometrics",
    "section": "Heteroskedasticity to be covered by Zeyi in the lab",
    "text": "Heteroskedasticity to be covered by Zeyi in the lab"
  }
]