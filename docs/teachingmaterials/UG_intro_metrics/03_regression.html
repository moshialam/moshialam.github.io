<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Moshi Alam">
  <title>Moshi Alam – Econ 265: Introduction to Econometrics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-a527665ed01beaa5bc5d6c6d96bbc18d.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Econ 265: Introduction to Econometrics</h1>
  <p class="subtitle">Topic 3: Simple Linear Regression</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Moshi Alam 
</div>
</div>
</div>

</section>
<section id="introduction" class="title-slide slide level1 smaller center">
<h1>Introduction</h1>
<ul>
<li>With regressions we want to make statistical associations between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>’s in the <em>population</em> using <em>sample</em></li>
<li>You have learnt the fundamentals in Econ 160</li>
<li>Here in addition, we will be
<ul>
<li>more formal</li>
<li>apply in code</li>
</ul></li>
<li>First, we will formalize some fundamental probabilistic concepts:
<ul>
<li>Expectations</li>
<li>Covariances</li>
</ul></li>
<li>Readings: Ch-2 of Wooldridge</li>
</ul>
</section>

<section>
<section id="fundamentals-expectation-and-covarainces" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Fundamentals: Expectation and Covarainces</h1>

</section>
<section id="expectation-and-covariances" class="slide level2">
<h2>Expectation and Covariances</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Expectation Primer</a></li><li><a href="#tabset-1-2">Properties</a></li><li><a href="#tabset-1-3">Covariance Primer</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<ul>
<li><em>Expected Value</em> of a random variable (r.v.) is the average of the r.v. in the <strong>population</strong> a.k.a <strong>the true mean</strong>
<ul>
<li>Population parameter, different from <em>sample average</em></li>
</ul></li>
<li>What we “expect” to see most often using averages in <span style="color:red;">large representative samples</span></li>
<li>I love the visualization in <a href="https://seeing-theory.brown.edu/basic-probability/index.html"><em>Seeing Theory</em></a></li>
</ul>
<p>For a discrete random variable <span class="math inline">\(X\)</span> with possible values <span class="math inline">\(x_i\)</span> and probabilities <span class="math inline">\(p_i\)</span>:</p>
<p><span class="math display">\[\mathbb{E}[X] = \sum_{i=1}^n x_i p_i\]</span></p>
<p>For a continuous random variable <span class="math inline">\(X\)</span> defined over <span class="math inline">\((-\infty, \infty)\)</span> with probability density function <span class="math inline">\(f(x)\)</span>:</p>
<p><span class="math display">\[\mathbb{E}[X] = \int_{-\infty}^{\infty} \quad x \quad f(x) \quad dx\]</span></p>
</div>
<div id="tabset-1-2">
<ul>
<li><em>Additive separability:</em> <span class="math inline">\(\mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[Y]\)</span></li>
<li><em>Linearity</em>: <span class="math inline">\(\mathbb{E}[aX + b] = a\mathbb{E}[X] + b\)</span></li>
<li>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent: <span class="math inline">\(\mathbb{E}[XY] = \mathbb{E}[X]\mathbb{E}[Y]\)</span></li>
</ul>
</div>
<div id="tabset-1-3">
<ul>
<li>Covariance measures how two variables move together: co-vary</li>
<li>Formula: <span class="math inline">\(Cov(x,y) = E[(x - E(x))(y - E(y))]\)</span></li>
<li>Can be rewritten as: <span class="math inline">\(Cov(x,y) = E(xy) - E(x)E(y)\)</span></li>
<li>Properties:
<ul>
<li>If x,y independent: <span class="math inline">\(Cov(x,y) = 0\)</span></li>
<li>If <span class="math inline">\(Cov(x,y) = 0\)</span>: x,y are uncorrelated</li>
</ul></li>
<li>If we replace y with x, <span class="math inline">\(Cov(x,x) = Var(x) = E[(x - E(x))]^2\)</span></li>
</ul>
</div>
</div>
</div>
<!--
## Simple Example: {.smaller}

::: {.cell}

```{.r .cell-code}
# Rolling a fair six-sided die
die_outcomes <- 1:6
# Probability of each outcome
prob <- rep(1/6, 6)

# Expected value
E_die <- sum(die_outcomes * prob)
cat("Expected value of rolling a die:", E_die)
```

::: {.cell-output .cell-output-stdout}

```
Expected value of rolling a die: 3.5
```


:::

```{.r .cell-code}
# Simulate 1000 die rolls
set.seed(123)
rolls <- sample(die_outcomes, size=1000, replace=TRUE)
mean(rolls)
```

::: {.cell-output .cell-output-stdout}

```
[1] 3.457
```


:::

```{.r .cell-code}
# Visualize
hist(rolls, breaks=seq(0.5, 6.5, 1), 
     main="Distribution of 1000 Die Rolls",
     xlab="Outcome",
     col="lightblue")
abline(v=E_die, col="red", lwd=2)
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}
:::
:::
-->
</section>
<section id="notation" class="slide level2 smaller">
<h2>Notation</h2>
<p>Note that in this course for the most part we will be using a <em>single cross-sectional data</em></p>
<ol type="1">
<li>Observations and Indices:
<ul>
<li>i: Index for a unit of observation (i = 1, …, n)
<ul>
<li>Could be individual, city, firm</li>
</ul></li>
<li>n: Sample size</li>
<li><span class="math inline">\(\sum_{i=1}^n\)</span>: Sum over all observations</li>
</ul></li>
<li>Variables:
<ul>
<li>y: Outcome/dependent variable (what we want to explain)</li>
<li>x: Independent/explanatory variable(s) (what helps explain y)</li>
<li>yᵢ: The i-th observation of y</li>
<li>xᵢ: The i-th observation of x</li>
</ul></li>
</ol>
<!--
##  {.smaller}

| Population Parameters (Greek Letters)   | Sample (Roman Letters)              |
|:------------------------------------|:----------------------------------|
| β₀,β₁: Population intercept & slope     | b₀, b₁: Estimated intercept & slope |
| ε (epsilon) or u: Error term            | ȳ, x̄: Sample mean of y & x          |
| σ² (sigma squared): Population variance | s²: Sample variance                 |
| μ (mu): Population mean                 |                                     |

::: callout-tip
Remember: Greek letters (β, σ, μ) typically represent unknown population parameters, while Roman letters (b, s, m) represent sample statistics we can calculate.
:::
-->
</section></section>
<section>
<section id="foundations-of-regression-analysis" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Foundations of Regression Analysis</h1>

</section>
<section id="population-vs.-sample" class="slide level2 smaller">
<h2>Population vs.&nbsp;Sample</h2>
<p>Simple linear regression model (SLRM): studies how <span class="math inline">\(y\)</span> changes with changes in <span class="math inline">\(x\)</span></p>
<div class="columns">
<div class="column" style="width:50%;">
<p>Population Model: <span class="math display">\[y_i = β₀ + β₁x_i + u_i\]</span></p>
<ul>
<li>β₀: Population intercept</li>
<li>β₁: Population slope</li>
<li><span class="math inline">\(u_i\)</span>: Error term (unobserved factors)</li>
</ul>
</div><div class="column" style="width:50%;">
<p>Estimation from a sample gives: <span class="math display">\[\hat{y_i} = \widehat{\beta_0} + \widehat{\beta_1} x_i\]</span></p>
<ul>
<li><span class="math inline">\(\widehat{\beta_0}\)</span>: estimated intercept</li>
<li><span class="math inline">\(\widehat{\beta_1}\)</span>: estimated slope</li>
<li><span class="math inline">\(\hat{u_i}\)</span>: Residuals = <span class="math inline">\(\hat{y_i} - y_i\)</span></li>
</ul>
</div></div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<ul>
<li>“hats” refer to estimates</li>
<li>If I write <span class="math inline">\(y\)</span> instead of <span class="math inline">\(y_i\)</span> that means I am referring to the entire vector of all <span class="math inline">\(y_i\)</span>’s</li>
</ul>
</div>
</div>
</div>
</section>
<section id="interpret-parameters" class="slide level2 smaller">
<h2>Interpret parameters</h2>
<p>Population Model: <span class="math display">\[y_i = β₀ + β₁x_i + u_i\]</span></p>
<p>Example: <span class="math display">\[wages_i = β₀ + β₁education_i + u_i\]</span></p>
<ul>
<li>What do β₀,β₁ represent?</li>
</ul>
</section>
<section id="section" class="slide level2 smaller">
<h2></h2>
<p>Population Model: <span class="math display">\[y_i = β₀ + β₁x_i + u_i\]</span></p>
<ul>
<li>If the other unobserved factors in u are held fixed,
<ul>
<li>so that the changes in u is zero,</li>
</ul></li>
<li>then x has a linear effect on y</li>
<li>simply: <span class="math inline">\(\Delta y_i = \beta_1 \Delta x_i\)</span> iff <span class="math inline">\(\Delta u_i = 0\)</span></li>
</ul>
<p>Formally,</p>
<p><span class="math display">\[\frac{\partial y_i}{\partial x_i} = \beta_1 \]</span> iff <span class="math inline">\(\frac{\partial u_i}{\partial x_i} = 0\)</span></p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<ul>
<li>We are imposing an assumption on the relation between <span class="math inline">\(x\)</span> and <span class="math inline">\(u\)</span> to be able to interpret <span class="math inline">\(\beta_1\)</span>. We will formalize this soon.</li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section id="assumptions" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Assumptions</h1>

</section>
<section id="key-assumptions-about-u" class="slide level2 smaller">
<h2>Key Assumptions About <span class="math inline">\(u\)</span></h2>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Assumptions</a></li><li><a href="#tabset-2-2">Why <span class="math inline">\(E(u)=0\)</span> works?</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Zero Mean</strong></p>
<ul>
<li><span class="math inline">\(E(u) = 0\)</span></li>
<li>Simple normalization of unobservables</li>
<li>Can always redefine intercept to make this true</li>
</ul>
<p><strong>Why This Works</strong></p>
<ul>
<li>Requires intercept in the regression</li>
<li>Redefining intercept absorbs any non-zero mean</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Mean Independence</strong></p>
<ul>
<li><span class="math inline">\(E(u|x) = E(u)\)</span></li>
<li>Average error same across all x-values</li>
<li>Stronger than zero correlation</li>
<li>Very strong assumption</li>
</ul>
<p><strong>Key Implications</strong></p>
<ul>
<li>Combines with first assumption to give:</li>
<li><span class="math inline">\(E(u|x) = 0\)</span> (Zero Conditional Mean)</li>
<li>Essential for interpreting <span class="math inline">\(\beta_1\)</span> as causal effect</li>
</ul>
</div></div>
</div>
<div id="tabset-2-2">
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Original Model</strong></p>
<p><span class="math inline">\(wage_i = \beta_0 + \beta_1educ_i + u_i\)</span></p>
<p>Where <span class="math inline">\(u\)</span> includes ability:</p>
<ul>
<li>Average ability = 100 (IQ points)</li>
<li>So <span class="math inline">\(E(u) = 100 \neq 0\)</span></li>
</ul>
<p>This means: <span class="math inline">\(wage = \beta_0 + \beta_1educ + 100 + \tilde{u}\)</span></p>
</div><div class="column" style="width:50%;">
<p><strong>Rewritten Model</strong></p>
<p><span class="math inline">\(wage_i = (\beta_0 + 100) + \beta_1educ_i + \tilde{u_i}\)</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\tilde{u} = u - 100\)</span> is deviation from mean</li>
<li>Now <span class="math inline">\(E(\tilde{u}) = 0\)</span></li>
<li>New intercept = <span class="math inline">\(\beta_0 + 100\)</span></li>
<li>Same model, different parameterization</li>
</ul>
</div></div>
<p><strong>Key Insight</strong></p>
<ul>
<li>Original error (<span class="math inline">\(u\)</span>): Ability with mean 100</li>
<li>New error (<span class="math inline">\(\tilde{u}\)</span>): Deviation from average ability</li>
<li>Slopes (<span class="math inline">\(\beta_1\)</span>) identical in both models</li>
<li>Only intercept changes to absorb the mean</li>
</ul>
</div>
</div>
</div>
</section>
<section id="what-about-eu-mid-x-0" class="slide level2">
<h2>What about <span class="math inline">\(E(u \mid x) = 0\)</span>?</h2>
<ul>
<li>Let us go back to the wage and education example</li>
</ul>
<p><span class="math display">\[ wage_i = \beta_0 + \beta_1 education_i + u_i \]</span></p>
<ul>
<li>what does mean independence /zero conditional mean, mean here?</li>
<li>is it too strong an assumption?</li>
</ul>
</section>
<section id="population-regression-function" class="slide level2 smaller">
<h2>Population Regression Function</h2>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">Population Regression Function</a></li><li><a href="#tabset-3-2">Visualization</a></li><li><a href="#tabset-3-3">Components of y</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div class="columns">
<div class="column" style="width:50%;">
<p>Zero conditional mean implies:</p>
<p><span class="math inline">\(E(y_i|x_i) = \beta_0 + \beta_1x_i\)</span></p>
<p><strong>Interpretation</strong></p>
<ul>
<li>Linear function of x</li>
<li>1 unit <span class="math inline">\(\uparrow\)</span> in x changes <span class="math inline">\(E(y)\)</span> by <span class="math inline">\(\beta_1\)</span></li>
<li>Given x, distribution of y centered around <span class="math inline">\(E(y|x)\)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong><code>gpa1</code> data</strong></p>
<p><span class="math inline">\(E(colGPA|hsGPA) = 1.5 + 0.5 \, hsGPA\)</span></p>
<p>For <span class="math inline">\(hsGPA = 3.6\)</span>:</p>
<ul>
<li>Average <span class="math inline">\(colGPA = 1.5 + 0.5(3.6) = 3.3\)</span></li>
<li>Not every student gets 3.3</li>
<li>Some higher, some lower</li>
<li>Depends on unobserved factors (u)</li>
</ul>
</div></div>
</div>
<div id="tabset-3-2">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a><span class="fu">library</span>(wooldridge)</span>
<span id="cb1-2"><a></a></span>
<span id="cb1-3"><a></a><span class="co"># gpa_model &lt;- lm(gpa1$colGPA ~ gpa1$hsGPA)</span></span>
<span id="cb1-4"><a></a><span class="co"># summary(gpa_model)</span></span>
<span id="cb1-5"><a></a></span>
<span id="cb1-6"><a></a></span>
<span id="cb1-7"><a></a><span class="fu">plot</span>(gpa1<span class="sc">$</span>hsGPA, gpa1<span class="sc">$</span>colGPA,</span>
<span id="cb1-8"><a></a>     <span class="at">xlab =</span> <span class="st">"High school  GPA"</span>,</span>
<span id="cb1-9"><a></a>     <span class="at">ylab =</span> <span class="st">"College GPA"</span>,</span>
<span id="cb1-10"><a></a>     <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb1-11"><a></a><span class="fu">abline</span>(<span class="fu">lm</span>(gpa1<span class="sc">$</span>colGPA <span class="sc">~</span> gpa1<span class="sc">$</span>hsGPA), <span class="at">col =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="03_regression_files/figure-revealjs/unnamed-chunk-2-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-3-3">
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Systematic Part</strong></p>
<ul>
<li><span class="math inline">\(\beta_0 + \beta_1x = E(y|x)\)</span></li>
<li>Explained by x</li>
<li>Population regression line</li>
<li>Blue line shows <span class="math inline">\(E(y|x)\)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Unsystematic Part</strong></p>
<ul>
<li>u = Deviation from <span class="math inline">\(E(y|x)\)</span></li>
<li>Not explained by x</li>
<li>Zero mean at each x <span class="math inline">\(E(u \mid x) = 0\)</span></li>
</ul>
</div></div>
</div>
</div>
</div>
</section></section>
<section>
<section id="deriving-the-ols-estimator" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Deriving the OLS estimator</h1>

</section>
<section id="section-1" class="slide level2 smaller">
<h2></h2>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">Starting assumption to deriving OLS estimators</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<p>We start with two key assumptions:</p>
<ol type="1">
<li><span class="math inline">\(E(u) = 0\)</span></li>
<li><span class="math inline">\(E(u \mid x) = 0\)</span> (zero conditional mean)</li>
</ol>
<p>This implies:</p>
<ul>
<li><span class="math inline">\(Cov(x,u) = E(xu) - E(x)E(u)\)</span></li>
<li>Since <span class="math inline">\(E(u) = 0\)</span>:
<ul>
<li><span class="math inline">\(Cov(x,u) = E(xu) - E(x) \cdot 0 = E(xu)\)</span></li>
</ul></li>
<li>Therefore: <span class="math inline">\(Cov(x,u) = 0 \iff E(xu) = 0\)</span></li>
</ul>
</div>
</div>
</div>
</section>
<section id="derivation" class="slide level2 smaller">
<h2>Derivation</h2>
<p>Population Model: <span class="math display">\[y_i = β₀ + β₁x_i + u_i\]</span></p>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><strong>Assumptions on the population</strong>:
<ul>
<li><span class="math inline">\(E(u) = 0\)</span></li>
<li>Covariance between <span class="math inline">\(x\)</span> and <span class="math inline">\(u\)</span> is zero: <span class="math inline">\(\text{Cov}(x,u) = 0\)</span>
<ul>
<li>These imply: <span class="math inline">\(E(xu) = 0\)</span></li>
</ul></li>
</ul></li>
<li><strong>Implications</strong>:
<ul>
<li>In terms of observable variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:
<ul>
<li><span class="math inline">\(E(y - \beta_0 - \beta_1x) = 0\)</span></li>
<li><span class="math inline">\(E[x(y - \beta_0 - \beta_1x)] = 0\)</span></li>
</ul></li>
<li>Assumptions give us these <em>moment conditions</em></li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Sample counterparts</strong></p>
<ul>
<li>Given a sample of data</li>
<li>estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> solve the sample counterparts of the moment conditions,
<ul>
<li>leading to equations:</li>
</ul></li>
</ul>
<p><span class="math display">\[n^{-1} \sum_{i=1}^{n}(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\]</span></p>
<p><span class="math display">\[n^{-1} \sum_{i=1}^{n}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\]</span></p>
<ul>
<li>These equations can be solved for <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span>.</li>
</ul>
</div></div>
</section>
<section id="section-2" class="slide level2 smaller">
<h2></h2>
<p>Now, <span class="math inline">\(n^{-1} \sum_{i=1}^{n}(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\)</span>, simplifies to</p>
<p><span class="math display">\[\bar{y_i} = \hat{\beta_0} + \hat{\beta_1}\bar{x_i}\]</span></p>
<p>Where <span class="math inline">\(\bar{y_i} = n^{-1} \sum_{i=1}^{n}y_i\)</span> is the sample average of the <span class="math inline">\(y_i\)</span>.</p>
<p>Thus,</p>
<p><span class="math display">\[\hat{\beta_0} = \bar{y_i}  - \hat{\beta_1}\bar{x_i}\]</span></p>
<p>Plug in <span class="math inline">\(\hat{\beta_0}\)</span> into: <span class="math inline">\(n^{-1} \sum_{i=1}^{n}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\)</span> and simplifying gives us the slope coefficient <span class="math inline">\(\hat{\beta_1}\)</span>:</p>
<p><span class="math display">\[\hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\]</span></p>
<p>provided, <span class="math inline">\(\sum_{i=1}^{n}(x_i - \bar{x})^2 &gt; 0\)</span>. What’s this?</p>
</section>
<section id="section-3" class="slide level2 smaller">
<h2></h2>
<p>Note that <span class="math inline">\(\hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\)</span> is nothing but</p>
<p>the <em>sample covariance</em> divided by the <em>sample variance</em>,</p>
<p>which can be written as,</p>
<p><span class="math display">\[\hat{\beta}_1=\hat{\rho}_{x y} \cdot\left(\frac{\hat{\sigma_y}}{\hat{\sigma_x}}\right)\]</span></p>
<p>since,</p>
<ul>
<li>sample covariance <span class="math inline">\(= \hat{\rho}_{x y} \cdot \hat{\sigma_y}\hat{\sigma_x}\)</span></li>
<li>correlation coeff: <span class="math inline">\(\hat{\rho}_{x y}\)</span></li>
<li>sample variance <span class="math inline">\(= \hat{\sigma_x}^2\)</span></li>
</ul>
</section>
<section id="fitted-values-and-residual" class="slide level2 smaller">
<h2>Fitted values and residual</h2>
<ul>
<li>The estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> thus obtained are called OLS</li>
<li>Can obtain “fitted values” of <span class="math inline">\(y_i\)</span>: <span class="math display">\[\hat{y_i} = \beta_0 + \beta_1 x_i\]</span></li>
<li>Obtain residuals: <span class="math inline">\(\hat{u_i} = y_i - \hat{y_i} = y_i - \hat{\beta_0} - \hat{\beta_1} x_i\)</span></li>
</ul>

<img data-src="03_regression_files/figure-revealjs/unnamed-chunk-3-1.png" width="960" class="r-stretch"></section>
<section id="interestingly" class="slide level2 smaller">
<h2>Interestingly</h2>
<ul>
<li><p>the line (characterized by an intercept and a slope) that minimizes: <span class="math display">\[\sum_{i=1}^n \hat{u}_i^2= \underbrace{\sum_{i=1}^n\left(y_i-\hat{\beta}_0-\hat{\beta}_1 x_i\right)^2}_{\text{SSR: Squared Sum of Residuals}}\]</span></p></li>
<li><p>lead to FOC’s that are same as what we obtained as the sample counterparts of the moment conditions</p>
<ul>
<li><span class="math inline">\(n^{-1} \sum_{i=1}^{n}(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\)</span></li>
<li><span class="math inline">\(n^{-1} \sum_{i=1}^{n}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0\)</span></li>
</ul></li>
<li><p>that we used to derive the OLS estimates</p></li>
<li><p>OLS chooses <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> to minimize SSR</p></li>
<li><p>Let us implement in R and test with the lm package</p></li>
</ul>
<!--
##

::: {.cell}
::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}
:::
:::
-->
</section></section>
<section>
<section id="statistical-properties-of-ols" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Statistical properties of OLS</h1>

</section>
<section id="properties-1" class="slide level2 smaller">
<h2>Properties</h2>
<ul>
<li>Mean of residuals is zero</li>
<li>Sample mean of x and y, i.e., the point <span class="math inline">\((\bar{x}, \bar{y})\)</span> lies on the regression line</li>
<li>The sample covariance between the regressors and the OLS residuals is zero</li>
<li>Predictions and residuals are uncorrelated</li>
</ul>
<p>Try testing these out with this generated data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb2-2"><a></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb2-3"><a></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">20</span>) <span class="co">#DGP</span></span>
<span id="cb2-4"><a></a><span class="fu">plot</span>(x, y, <span class="at">main=</span><span class="st">"Linear Relationship Example"</span>)</span>
<span id="cb2-5"><a></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">col=</span><span class="st">"red"</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="03_regression_files/figure-revealjs/unnamed-chunk-5-1.png" width="960" class="r-stretch"></section>
<section id="decomposition" class="slide level2 smaller">
<h2>Decomposition</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><p><strong>Total Sum of Squares (SST)</strong>: <span class="math display">\[
\text{SST} \equiv \sum_{i=1}^{n}(y_i - \bar{y})^2
\]</span></p></li>
<li><p><strong>Explained Sum of Squares (SSE)</strong>: <span class="math display">\[
\text{SSE} \equiv \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2
\]</span></p></li>
<li><p><strong>Residual Sum of Squares (SSR)</strong>: <span class="math display">\[
\text{SSR} \equiv \sum_{i=1}^{n}\hat{u}_i^2
\]</span></p></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Relationship Between Sums of Squares</strong></p>
<p>Total variation in <span class="math inline">\(y\)</span> can be expressed as:</p>
<p><span class="math display">\[
\text{SST} = \text{SSE} + \text{SSR}
\]</span></p>
<p><strong>Proof Outline</strong> To prove this relationship, we can write:</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}[(\hat{y}_i - \bar{y}) + (y_i - \hat{y}_i)]^2
\]</span> <span class="math display">\[
= \sum_{i=1}^{n}(\hat{u}_i + (y_i - \bar{y}))^2
\]</span> <span class="math display">\[
= \text{SSR} + 2\sum_{i=1}^{n}\hat{u}_i(y_i - \bar{y}) + \text{SSE}
\]</span></p>
</div></div>
</section>
<section id="r-squared" class="slide level2 smaller">
<h2>R-squared</h2>
<ul>
<li>Measures goodness of fit <span class="math display">\[R^2 = \frac{SSE}{SST} = 1 - \frac{SSR}{SST}\]</span></li>
<li>Ranges from 0 to 1</li>
<li>Interpretation: Proportion of variance explained by model</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a><span class="co"># Calculate R-squared</span></span>
<span id="cb3-2"><a></a><span class="fu">summary</span>(model)<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4923586</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a><span class="co"># Decomposition of variance</span></span>
<span id="cb5-2"><a></a><span class="fu">anova</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value  Pr(&gt;F)  
x          1 42.639  42.639  6.7893 0.03514 *
Residuals  7 43.962   6.280                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section></section>
<section>
<section id="scaling-and-transformations" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Scaling and Transformations</h1>

</section>
<section id="the-four-types" class="slide level2 smaller">
<h2>The Four Types</h2>
<ol type="1">
<li>Level-level: <span class="math inline">\(y = b_0 + b_1x\)</span></li>
<li>Level-log: <span class="math inline">\(y = b_0 + b_1\log(x)\)</span></li>
<li>Log-level: <span class="math inline">\(\log(y) = b_0 + b_1x\)</span></li>
<li>Log-log: <span class="math inline">\(\log(y) = b_0 + b_1\log(x)\)</span></li>
</ol>
</section>
<section id="interpreting-log-specifications" class="slide level2 smaller">
<h2>Interpreting Log Specifications</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Specification</th>
<th>Change in x</th>
<th>Effect on y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Level-level</td>
<td>+1 unit</td>
<td>+<span class="math inline">\(b_1\)</span> units</td>
</tr>
<tr class="even">
<td>Level-log</td>
<td>+1%</td>
<td>+<span class="math inline">\(\frac{b_1}{100}\)</span> units</td>
</tr>
<tr class="odd">
<td>Log-level</td>
<td>+1 unit</td>
<td>+<span class="math inline">\((100 \times b_1)\%\)</span></td>
</tr>
<tr class="even">
<td>Log-log</td>
<td>+1%</td>
<td>+<span class="math inline">\(b_1\%\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="why-use-logs" class="slide level2 smaller">
<h2>Why Use Logs?</h2>
<ol type="1">
<li>Normalize skewed distributions</li>
<li>Reduce impact of outliers</li>
<li>Interpret coefficients as elasticities</li>
<li>Transform multiplicative relationships to additive</li>
</ol>
</section>
<section id="example-ceo-salaries" class="slide level2 smaller">
<h2>Example: CEO Salaries</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a></a><span class="fu">data</span>(<span class="st">"ceosal1"</span>, <span class="at">package =</span> <span class="st">"wooldridge"</span>)</span>
<span id="cb7-2"><a></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb7-3"><a></a><span class="fu">plot</span>(salary <span class="sc">~</span> sales, <span class="at">data =</span> ceosal1, </span>
<span id="cb7-4"><a></a>     <span class="at">main =</span> <span class="st">"Raw Values"</span>)</span>
<span id="cb7-5"><a></a><span class="fu">plot</span>(<span class="fu">log</span>(salary) <span class="sc">~</span> <span class="fu">log</span>(sales), <span class="at">data =</span> ceosal1, </span>
<span id="cb7-6"><a></a>     <span class="at">main =</span> <span class="st">"Log Transformed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="03_regression_files/figure-revealjs/unnamed-chunk-7-1.png" width="960" class="r-stretch"></section>
<section id="non-linear-relationships" class="slide level2 smaller">
<h2>Non-Linear Relationships</h2>
<ul>
<li>Not all relationships are linear</li>
<li>Can add polynomial terms: <span class="math inline">\(y_i = \beta_0 + \beta_1x_i^2 + u_i\)</span></li>
<li>Visual inspection is crucial</li>
<li>Always plot your data first!</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Linear in linear regression means linear in parameters not variables</p>
</div>
</div>
</div>
</section></section>
<section>
<section id="expected-values-and-variances-of-the-ols-estimator" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Expected Values and Variances of the OLS Estimator</h1>

</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li>For any estimator we want to know two important things
<ul>
<li>Whether we are getting unbiased estimates</li>
<li>If yes, how precisely can we obtain those estimates</li>
</ul></li>
<li>Will require assumptions</li>
<li>For OLS, we have 5 of them, which will constitute the Gauss-Markov assumptions</li>
</ul>
</section></section>
<section>
<section id="expected-value-of-the-ols-estimator" class="title-slide slide level1 center">
<h1>Expected Value of the OLS Estimator</h1>

</section>
<section id="unbiasedness-of-an-estimator" class="slide level2 smaller">
<h2>Unbiasedness of an estimator</h2>
<p>An estimator is <strong>unbiased</strong> if, on average, it produces estimates that are equal to the true value of the parameter being estimated.</p>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definition</strong></p>
</div>
<div class="callout-content">
<p>An estimator producing an estimate <span class="math inline">\(\hat{\theta}\)</span> for a parameter <span class="math inline">\(\theta\)</span> is considered unbiased if: <span class="math display">\[
\mathbb{E}(\widehat{\theta}) = \theta
\]</span></p>
</div>
</div>
</div>
<p>Basically means that the sampling distribution of <span class="math inline">\(\hat{\theta}\)</span> is centered around the true <span class="math inline">\(\theta\)</span> <strong>on average</strong></p>
<p>We will now show that the OLS estimator for a SLR model’s parameters <span class="math inline">\((\beta_0, \beta_1)\)</span> is unbiased</p>
</section>
<section id="assumptions-to-prove-unbiasedness-of-ols" class="slide level2 smaller">
<h2>Assumptions to prove unbiasedness of OLS</h2>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-5-1">SLR 1 - 4</a></li><li><a href="#tabset-5-2">SLR1</a></li><li><a href="#tabset-5-3">SLR2</a></li><li><a href="#tabset-5-4">SLR3</a></li><li><a href="#tabset-5-5">SLR4</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1">
<ol type="1">
<li>Linear in parameters</li>
<li>Random sampling</li>
<li>Sample Variation in X</li>
<li>Zero Conditional mean</li>
</ol>
</div>
<div id="tabset-5-2">
<ol type="1">
<li><p><em>Linear in parameters:</em></p>
<p>In the population model, the dependent variable, <span class="math inline">\(y\)</span>, is related to the independent variable, <span class="math inline">\(x\)</span>, and the error (or disturbance), <span class="math inline">\(u\)</span>, as: <span class="math display">\[
y=\beta_0+\beta_1 x+u
\]</span> where <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are the population intercept and slope parameters, respectively.</p></li>
</ol>
</div>
<div id="tabset-5-3">
<ol start="2" type="1">
<li><p><em>Random Sampling</em></p>
<p>We have a random sample of size n,<span class="math inline">\(\left\{\left(x_i, y_i\right): i=1,2, \ldots, n\right\}\)</span> in the population model</p></li>
</ol>
</div>
<div id="tabset-5-4">
<ol start="3" type="1">
<li><p><em>Sample variation in X</em></p>
<p>The sample explanatory x variable, namely, <span class="math inline">\(x_i\)</span> , <span class="math inline">\(i \in \{1, \cdots, n\}\)</span> , are not all the same value <span class="math display">\[\widehat{Var}(x_i) &gt; 0\]</span></p></li>
</ol>
</div>
<div id="tabset-5-5">
<ol start="4" type="1">
<li><em>Zero conditional mean</em></li>
</ol>
<p>The error <span class="math inline">\(u\)</span> has an expected value of zero given any value of the explanatory variable. In other words, <span class="math display">\[E(u \mid x)=0\]</span> .</p>
</div>
</div>
</div>
</section>
<section id="theorem" class="slide level2">
<h2>Theorem</h2>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem: Unbiasedness of the OLS estimator</strong></p>
</div>
<div class="callout-content">
<p>Using Assumptions SLR. 1 through SLR.4,</p>
<p><span class="math display">\[
\mathrm{E}\left(\hat{\beta}_0\right)=\beta_0 \text { and } \mathrm{E}\left(\hat{\beta}_1\right)=\beta_1
\]</span></p>
</div>
</div>
</div>
<ul>
<li>In other words, <span class="math inline">\(\hat{\beta}_0\)</span> is unbiased for <span class="math inline">\(\beta_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> is unbiased for <span class="math inline">\(\beta_1\)</span>.</li>
<li>Let us prove it using our assumptions!</li>
<li>In doing so, we will learn some tricks, and I want you to learn the tricks and observe the patterns in the art of going about an econoemtric proof.</li>
</ul>
</section>
<section id="please-make-sure-you-go-through-all-of-math-refresher-a-and-b" class="slide level2 smaller">
<h2>Please make sure you go through all of Math Refresher A and B</h2>
<h3 id="b-4f-properties-of-conditional-expectation">B-4f Properties of Conditional Expectation</h3>
<ul>
<li><span class="math inline">\(\text {CE.1: } \mathrm{E}[c(X) \mid X]=c(X) \text {, for any function } c(X)\)</span></li>
<li><span class="math inline">\(\text {CE.2: For functions } a(X) \text { and } b(X) \text {, } \mathrm{E}[a(X) Y+b(X) \mid X]=a(X) \mathrm{E}(Y \mid X)+b(X)\)</span></li>
<li><span class="math inline">\(\text {CE. 3: If } X \text { and } Y \text { are independent, then } \mathrm{E}(Y \mid X)=\mathrm{E}(Y)\)</span></li>
<li><span class="math inline">\(\text {CE. 4:} \mathrm{E}[\mathrm{E}(Y \mid X)]=\mathrm{E}(Y)\)</span> <em>[Law of Iterated Expectations]</em></li>
<li><span class="math inline">\(\text {CE. } 4^{\prime}: \mathrm{E}(Y \mid X)=\mathrm{E}[\mathrm{E}(Y \mid X, Z) \mid X]\)</span> <em>[Generalized Law of Iterated Expectations]</em></li>
<li><span class="math inline">\(\text {CE. } 5: \mathrm{E}(Y \mid X)=\mathrm{E}(Y)\)</span> then <span class="math inline">\(cov(X, Y)=0\)</span></li>
</ul>
</section>
<section id="key-patterns-in-the-proof" class="slide level2 smaller">
<h2>Key patterns in the proof</h2>
<ul>
<li>Start with the OLS estimate <span class="math inline">\(\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\)</span> and <span class="math inline">\(\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\bar{x}\)</span></li>
<li>Write the OLS estimator in terms of the population parameters
<ul>
<li>To do this we have to bring in <span class="math inline">\(y_i\)</span> (population model) and not <span class="math inline">\(\hat{y_i}\)</span>
<ul>
<li>This is what brings in the population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> on the RHS</li>
</ul></li>
<li>Tricks to bring in <span class="math inline">\(y_i\)</span> in the OLS estimator:
<ul>
<li><strong>Without any assumptions</strong> we showed and used:</li>
<li><span class="math inline">\(\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y}) = \sum_{i=1}^n(x_i - \bar{x})y_i\)</span>
<ul>
<li>Could have written this as <span class="math inline">\(\sum_{i=1}^n(y_i - \bar{y})x_i\)</span> but did not <strong>to bring in</strong> <span class="math inline">\(y_i\)</span></li>
</ul></li>
</ul></li>
<li>Other tricks: <strong>Without any assumptions</strong>
<ul>
<li><span class="math inline">\(\sum_{i=1}^n(x_i - \bar{x}) = 0\)</span></li>
<li><span class="math inline">\(\sum_{i=1}^n(x_i - \bar{x})x_i = \sum_{i=1}^n(x_i - \bar{x})^2\)</span></li>
</ul></li>
</ul></li>
<li>Take the expectation conditional on <span class="math inline">\(x_i\)</span>
<ul>
<li>impose the SLR assumptions on zero mean and zero conditional mean</li>
<li>use LIE</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="variance-of-the-ols-estimators" class="title-slide slide level1 center" data-background-color="#1c5253">
<h1>Variance of the OLS Estimators</h1>

</section>
<section id="slr-5-homoskedasticity-assumption" class="slide level2 smaller">
<h2>SLR 5: Homoskedasticity assumption</h2>
<p>The population error <span class="math inline">\(u_i\)</span> has the same variance given any value of <span class="math inline">\(x_i\)</span>, i.e.,</p>
<p><span class="math display">\[
Var(u \mid x) = \sigma^2
\]</span></p>
<p>SLR 5 further implies that <span class="math inline">\(\sigma^2\)</span> is also the unconditional variance of <span class="math inline">\(u\)</span>.</p>
<p><span class="math display">\[\operatorname{Var}(u \mid x)=\mathrm{E}\left(u^2 \mid x\right)-[\mathrm{E}(u \mid x)]^2\]</span></p>
<p><span class="math display">\[ \text { and since } \mathrm{E}(u \mid x)=0, \sigma^2=\mathrm{E}\left(u^2 \mid x\right)\]</span></p>
</section>
<section id="now-we-have-var-y-mid-x" class="slide level2">
<h2>Now we have <span class="math inline">\(Var( y \mid x)\)</span></h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>using Assumptions SLR. 4 and SLR. 5 we can derive the conditional variance of <span class="math inline">\(y\)</span> :</p>
<p><span class="math display">\[
\begin{gathered}
\mathrm{E}(y \mid x)=\beta_0+\beta_1 x \\
\operatorname{Var}(y \mid x)=\sigma^2
\end{gathered}
\]</span></p>
<p>From here we can get <span class="math inline">\(Var(u \mid x)\)</span></p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="homoskedasticity.png"></p>
<figcaption>Homoskedasticity</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="theorem-1" class="slide level2 smaller">
<h2>Theorem</h2>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Sampling variance of OLS estimators</strong></p>
</div>
<div class="callout-content">
<p>Under Assumptions SLR. 1 through SLR.5,</p>
<p><span class="math display">\[
\operatorname{Var}\left(\hat{\beta}_1\right)=\frac{\sigma^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2} = \frac{\sigma^2}{\mathrm{SST}_x},
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\operatorname{Var}\left(\hat{\beta}_0\right)=\frac{\sigma^2 \frac{1}{n} \sum_{i=1}^n x_i^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2} = \frac{\sigma^2 \frac{1}{n} \sum_{i=1}^n x_i^2}{\mathrm{SST}_x}
\]</span></p>
<p>where these are conditional on the sample values <span class="math inline">\(\left\{x_1, \ldots, x_n\right\}\)</span>.</p>
</div>
</div>
</div>
<ul>
<li>Let us prove this!</li>
</ul>
</section>
<section id="proof-of-operatornamevarlefthatbeta_1right" class="slide level2 smaller">
<h2>Proof of <span class="math inline">\(\operatorname{Var}\left(\hat{\beta}_1\right)\)</span></h2>
<ul>
<li>Let us work with <span class="math inline">\(\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\)</span> <span class="math inline">\(\implies\)</span> <span class="math inline">\(\hat{\beta}_1 = \beta_1 + \frac{\sum_{i=1}^{n}(x_i - \bar{x})u_i}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\)</span></li>
<li>Denote <span class="math inline">\((x_i - \bar{x})\)</span> as <span class="math inline">\(d_i\)</span>. So <span class="math inline">\(\hat{\beta}_1 = \beta_1 + \frac{\sum_{i=1}^{n} d_iu_i}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\)</span></li>
<li>Now take the variance of <span class="math inline">\(\hat{\beta}_1\)</span> conditional on the sample values <span class="math inline">\(x_i\)</span></li>
</ul>
<p><span class="math display">\[\begin{align*}
    \operatorname{Var}\left(\hat{\beta}_1\right) &amp; = \operatorname{Var}\left(\beta_1 + \frac{\sum_{i=1}^{n} d_iu_i}{SST_x}\right) \\
    &amp; = \operatorname{Var}\left(\frac{\sum_{i=1}^{n} d_iu_i}{SST_x}\right) \quad \text{skipping 2 steps} \\
    &amp; = \frac{1}{\left(SST_x\right)^2} \sum_{i=1}^{n} d_i^2 \operatorname{Var}(u_i) \quad \text{skipping 3 steps} \\
    &amp; = \frac{\sigma^2}{SST_x}
\end{align*}\]</span></p>
</section>
<section id="measure-of-precision-of-hatbeta_1" class="slide level2 smaller">
<h2>Measure of precision of <span class="math inline">\(\hat{\beta_1}\)</span></h2>
<div>
<ul>
<li class="fragment"><span class="math inline">\(sd(\hat{\beta}_1) = \sqrt{\operatorname{Var}\left(\hat{\beta}_1\right)}\)</span> gives a measure of the precision of <span class="math inline">\(\hat{\beta}_1\)</span></li>
<li class="fragment">But we do not know <span class="math inline">\(\sigma^2\)</span> so we do not know <span class="math inline">\(sd(\hat{\beta}_1)\)</span></li>
<li class="fragment">So we have to estimate <span class="math inline">\(\sigma^2\)</span> to get an estimate of <span class="math inline">\(sd(\hat{\beta}_1)\)</span></li>
<li class="fragment">The estimate of the <span class="math inline">\(sd(\hat{\beta}_1)\)</span> is called the standard error of <span class="math inline">\(\hat{\beta}_1\)</span></li>
</ul>
</div>
<!--
## What do we have so far {.smaller}
-   We have shown under SLR 1-5 that the OLS estimators are unbiased
-   We have also shown that the variance of the OLS estimators can be written as:
    -   $\operatorname{Var}\left(\hat{\beta}_1\right)=\frac{\sigma^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2} = \frac{\sigma^2}{\mathrm{SST}_x}$
    -   $\operatorname{Var}\left(\hat{\beta}_0\right)=\frac{\sigma^2 \frac{1}{n} \sum_{i=1}^n x_i^2}{\mathrm{SST}_x}$
-   To wrap up SLR we need to know how precise are the estimates
-   If we knew $\sigma^2$ we would be done, because then
    -   $\sqrt{\operatorname{Var}\left(\hat{\beta}_1\right)}$ and $\sqrt{\operatorname{Var}\left(\hat{\beta}_0\right)}$ would be the standard errors of the OLS estimators
-   We will estimate $\sigma^2$ using the residuals to get $\hat{\sigma}^2$ and then use that to get the standard errors of the OLS estimators
-   This estimate $\hat{\sigma}^2$ also has to be s.t. it is **unbiased**
-->
</section>
<section id="theorem-2" class="slide level2 smaller">
<h2>Theorem</h2>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Unbiased estimation of <span class="math inline">\(\sigma^2\)</span></strong></p>
</div>
<div class="callout-content">
<p>Under Assumptions SLR. through SLR.5,</p>
<p><span class="math display">\[\mathrm{E}\left(\hat{\sigma}^2\right)=\sigma^2\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}^2=\frac{1}{n-2} \sum_{i=1}^n \hat{u}_i^2\)</span>, where <span class="math inline">\(\hat{u}_i=y_i-\hat{\beta}_0-\hat{\beta}_1 x_i\)</span></p>
</div>
</div>
</div>
<ul>
<li>Study the proof from 2-5c</li>
<li>Try to observe the patterns in the proof similar to the unbiasedness proof of the OLS estimates</li>
</ul>
</section>
<section id="in-essence-we-have-shown" class="slide level2 smaller">
<h2>In essence we have shown</h2>
<div>
<p>Assuming SLR 1-5, and conditional on the sample values <span class="math inline">\(\left\{x_1, \ldots, x_n\right\}\)</span>, we have shown that:</p>
<ul>
<li class="fragment">The OLS estimators are unbiased
<ul>
<li class="fragment"><span class="math inline">\(\mathrm{E}\left(\hat{\beta}_0\right)=\beta_0\)</span> and <span class="math inline">\(\mathrm{E}\left(\hat{\beta}_1\right)=\beta_1\)</span></li>
</ul></li>
<li class="fragment">We can obtain the variance of the OLS estimators
<ul>
<li class="fragment"><span class="math inline">\(\operatorname{Var}\left(\hat{\beta}_1\right)=\frac{\sigma^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2} = \frac{\sigma^2}{\mathrm{SST}_x}\)</span></li>
<li class="fragment"><span class="math inline">\(\operatorname{Var}\left(\hat{\beta}_0\right)=\frac{\sigma^2 \frac{1}{n} \sum_{i=1}^n x_i^2}{\mathrm{SST}_x}\)</span></li>
</ul></li>
<li class="fragment">But we do not know <span class="math inline">\(\sigma^2\)</span>
<ul>
<li class="fragment">The residual variance <span class="math inline">\(\hat{\sigma}^2\)</span> is unbiased for the variance of the population errror <span class="math inline">\(\sigma^2\)</span></li>
<li class="fragment"><span class="math inline">\(\mathrm{E}\left(\hat{\sigma}^2\right)=\sigma^2\)</span></li>
</ul></li>
<li class="fragment">And we learnt a lot of tricks and pattern recognition in the process</li>
<li class="fragment">And some stuff about how to work with data</li>
</ul>
</div>
</section>
<section id="remaining-things-for-you-to-sudy" class="slide level2 smaller">
<h2>Remaining things for you to sudy</h2>
<ul>
<li>Read up on the properties of the conditional expectation in Math Refresher B</li>
<li>Read up:
<ul>
<li>2-6: Regression through the Origin and Regression on a Constant</li>
<li>2-7: Regression on a Binary Explanatory Variable</li>
</ul></li>
<li>Again: Make sure you go through all of Math Refresher A and B</li>
</ul>
<p>next class we will start chapter 3</p>
<!--

## The Simple Linear Regression Model {.smaller}

::: columns
::: {.column width="50%"}
Key Assumptions (SLR.1 - SLR.5):

1.  Linear in Parameters
2.  Random Sampling
3.  Sample Variation in X
4.  Zero Conditional Mean: E(u\|x) = 0
5.  Homoskedasticity: Var(u\|x) = σ²
:::

::: {.column width="50%"}
::: {.cell}

```{.r .cell-code}
# Demonstrate linear relationship
set.seed(123)
x <- seq(1, 100, length.out = 50)
y <- 2 + 3*x + rnorm(50, 0, 20)
plot(x, y, main="Linear Relationship Example")
abline(lm(y ~ x), col="red", lwd=2)
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}
:::
:::
:::

:::



## Zero Conditional Mean {.smaller}

Important implications:

1.  X and u are uncorrelated
2.  Regression line passes through (x̄, ȳ)
3.  Mean of residuals is zero

::: {.cell}

```{.r .cell-code}
model <- lm(y ~ x)
# Show mean of residuals
mean(residuals(model))
```

::: {.cell-output .cell-output-stdout}

```
[1] 9.370282e-16
```


:::

```{.r .cell-code}
# Plot residuals against X
plot(x, residuals(model), 
     main="Residuals vs. X",
     ylab="Residuals")
abline(h=0, col="red", lty=2)
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}
:::
:::

# OLS Estimation {background-color="#1c5253"}

## The OLS Objective Function {.smaller}

Minimizing Sum of Squared Residuals (SSR):

$$ SSR = \sum_{i=1}^n (y_i - b_0 - b_1x_i)^2 $$

::: {.cell}

```{.r .cell-code}
# Demonstrate OLS fitting
model_summary <- summary(model)
# Show SSR
sum(residuals(model)^2)
```

::: {.cell-output .cell-output-stdout}

```
[1] 16794.14
```


:::
:::

## OLS Estimators {.smaller}

Sample statistics:

$$ b_1 = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} $$

$$ b_0 = \bar{y} - b_1\bar{x} $$

::: {.cell}

```{.r .cell-code}
# Manual calculation of slope
x_centered <- x - mean(x)
y_centered <- y - mean(y)
b1_manual <- sum(x_centered * y_centered) / sum(x_centered^2)
b0_manual <- mean(y) - b1_manual * mean(x)

# Compare with lm()
coef(model)
```

::: {.cell-output .cell-output-stdout}

```
(Intercept)           x 
   3.366618    2.986563 
```


:::
:::

# Statistical Properties {background-color="#1c5253"}

## Sampling Distribution {.smaller}

Under classical assumptions:

1.  Unbiasedness: E(b₁) = β₁
2.  Variance: Var(b₁) = σ²/SST_x
3.  Normal distribution (if u is normal)

::: {.cell}

```{.r .cell-code}
# Standard error of slope
coef(summary(model))["x", "Std. Error"]
```

::: {.cell-output .cell-output-stdout}

```
[1] 0.09072805
```


:::

```{.r .cell-code}
# Confidence interval
confint(model)
```

::: {.cell-output .cell-output-stdout}

```
                2.5 %    97.5 %
(Intercept) -7.270789 14.004024
x            2.804142  3.168984
```


:::
:::

## The Gauss-Markov Theorem {.smaller}

OLS estimators are BLUE: - Best - Linear - Unbiased - Estimator

Implications: - Smallest variance among linear unbiased estimators - Efficient estimation

# Inference and Testing {background-color="#1c5253"}

## t-Statistics and Confidence Intervals {.smaller}

Testing H₀: β₁ = 0

$$ t = \frac{b_1 - 0}{se(b_1)} $$

::: {.cell}

```{.r .cell-code}
# t-test for slope
coef(summary(model))["x", "t value"]
```

::: {.cell-output .cell-output-stdout}

```
[1] 32.91775
```


:::

```{.r .cell-code}
coef(summary(model))["x", "Pr(>|t|)"]
```

::: {.cell-output .cell-output-stdout}

```
[1] 1.347241e-34
```


:::

```{.r .cell-code}
# 95% CI
confint(model, level = 0.95)
```

::: {.cell-output .cell-output-stdout}

```
                2.5 %    97.5 %
(Intercept) -7.270789 14.004024
x            2.804142  3.168984
```


:::
:::

## R² and Goodness of Fit {.smaller}

$$ R^2 = 1 - \frac{SSR}{SST} = \frac{SSE}{SST} $$


::: {.cell}

```{.r .cell-code}
# Calculate R-squared
summary(model)$r.squared
```

::: {.cell-output .cell-output-stdout}

```
[1] 0.9575814
```


:::

```{.r .cell-code}
# Decomposition of variance
anova(model)
```

::: {.cell-output .cell-output-stdout}

```
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value    Pr(>F)    
x          1 379120  379120  1083.6 < 2.2e-16 ***
Residuals 48  16794     350                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


:::
:::

# Regression Analysis in Practice {background-color="#1c5253"}

## Economic Example: Wage Determination {.smaller}

::: {.cell}

```{.r .cell-code}
# Create wage-education data
set.seed(456)
education <- rnorm(100, mean=16, sd=2)
wage <- 10000 + 5000*education + rnorm(100, 0, 10000)

# Estimate wage equation
wage_model <- lm(wage ~ education)
summary(wage_model)
```

::: {.cell-output .cell-output-stdout}

```

Call:
lm(formula = wage ~ education)

Residuals:
     Min       1Q   Median       3Q      Max 
-22154.8  -8126.6   -491.4   9153.1  19131.1 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  10175.5     8015.4   1.269    0.207    
education     4917.3      489.9  10.038   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 9763 on 98 degrees of freedom
Multiple R-squared:  0.507, Adjusted R-squared:  0.5019 
F-statistic: 100.8 on 1 and 98 DF,  p-value: < 2.2e-16
```


:::

```{.r .cell-code}
# Plot
plot(education, wage,
     main="Education vs. Wage",
     xlab="Years of Education",
     ylab="Annual Wage ($)")
abline(wage_model, col="blue", lwd=2)
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}
:::
:::

## Interpreting Economic Results {.smaller}

Key interpretations: 1. Marginal effect 2. Statistical significance 3. Economic significance 4. Prediction intervals

::: {.cell}

```{.r .cell-code}
# Marginal effect of education
coef(wage_model)["education"]
```

::: {.cell-output .cell-output-stdout}

```
education 
 4917.332 
```


:::

```{.r .cell-code}
# Prediction for new values
new_edu <- data.frame(education = c(12, 16, 20))
predict(wage_model, new_edu, interval="prediction")
```

::: {.cell-output .cell-output-stdout}

```
        fit      lwr       upr
1  69183.52 49280.53  89086.51
2  88852.85 69380.14 108325.56
3 108522.18 88710.99 128333.36
```


:::
:::

# Advanced Topics {background-color="#1c5253"}

## Functional Forms {.smaller}

Common specifications: 1. Level-Level 2. Log-Level 3. Level-Log 4. Log-Log (elasticity)

::: {.cell}

```{.r .cell-code}
# Log-log example
log_wage_model <- lm(log(wage) ~ log(education))
summary(log_wage_model)
```

::: {.cell-output .cell-output-stdout}

```

Call:
lm(formula = log(wage) ~ log(education))

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32326 -0.08414  0.00037  0.09906  0.17465 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)     8.92208    0.25300  35.265  < 2e-16 ***
log(education)  0.88988    0.09092   9.788  3.5e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1134 on 98 degrees of freedom
Multiple R-squared:  0.4943,    Adjusted R-squared:  0.4892 
F-statistic:  95.8 on 1 and 98 DF,  p-value: 3.501e-16
```


:::
:::

## Regression Diagnostics {.smaller}

Key diagnostic plots:

::: {.cell}

```{.r .cell-code}
par(mfrow=c(2,2))
plot(wage_model)
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}
:::
:::

# Practice Problems {background-color="#1c5253"}

## Exercise 1: Wage Analysis

Using provided data: 1. Test for education premium 2. Calculate confidence intervals 3. Interpret R² 4. Check assumptions

## Exercise 2: Model Specification

1.  Compare different functional forms
2.  Test for nonlinearity
3.  Analyze residuals
4.  Make predictions

## Exercise 3: Hypothesis Testing

1.  Conduct t-tests
2.  Calculate F-statistics
3.  Test economic hypotheses
4.  Interpret p-values

# Additional Resources {background-color="#1c5253"}

## Key References

-   Wooldridge, "Introductory Econometrics"
-   Stock & Watson, "Introduction to Econometrics"
-   Greene, "Econometric Analysis"

## Statistical Software

-   R packages:
    -   lmtest
    -   sandwich
    -   car
    -   stargazer

## Expected Value and Sample Size {.smaller}

::: {.cell}

```{.r .cell-code}
# Create population of college graduates' wages
set.seed(456)
population_size <- 100000
population_wages <- rnorm(population_size, mean=55000, sd=8000)

E_population <- mean(population_wages)
cat("True population mean (expected value):", round(E_population, 2))
```

::: {.cell-output .cell-output-stdout}

```
True population mean (expected value): 55045.13
```


:::
:::

::: {.cell}

```{.r .cell-code}
# Sample sizes to try
sample_sizes <- c(10, 100, 1000, 10000)

# Function to draw samples and calculate means
par(mfrow=c(2,2))
for(n in sample_sizes) {
    # Draw random sample
    sample_wages <- sample(population_wages, size=n)
    sample_mean <- mean(sample_wages)
    
    # Plot histogram
    hist(sample_wages, 
        main=paste("Sample Size:", n),
        xlab="Annual Wage ($)",
        col="lightblue",
        breaks=30)
    abline(v=E_population, col="red", lwd=2, lty=2)  # Population mean
    abline(v=sample_mean, col="blue", lwd=2)  # Sample mean
    legend("topright", 
        legend=c("Population Mean", "Sample Mean"),
        col=c("red", "blue"),
        lty=c(2, 1),
        lwd=2,
        cex=0.7)
}
```

::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}
:::

```{.r .cell-code}
# Print results
cat("\nPopulation mean (Expected Value):", round(E_population, 2))
```

::: {.cell-output .cell-output-stdout}

```

Population mean (Expected Value): 55045.13
```


:::

```{.r .cell-code}
cat("\n\nSample means by sample size:")
```

::: {.cell-output .cell-output-stdout}

```


Sample means by sample size:
```


:::

```{.r .cell-code}
for(n in sample_sizes) {
    sample_mean <- mean(sample(population_wages, size=n))
    cat(sprintf("\nn = %5d: %8.2f (diff: %6.2f)", 
                n, sample_mean, sample_mean - E_population))
}
```

::: {.cell-output .cell-output-stdout}

```

n =    10: 52056.66 (diff: -2988.46)
n =   100: 53825.36 (diff: -1219.77)
n =  1000: 54812.99 (diff: -232.14)
n = 10000: 55103.38 (diff:  58.25)
```


:::
:::

## Dice Simulation {.smaller}

::: columns
::: {.column width="50%"}
::: {.cell}
::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}
:::
:::
:::

::: {.column width="50%"}
::: {.cell}
::: {.cell-output-display}
![](03_regression_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}
:::
:::
:::
:::

-->


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>