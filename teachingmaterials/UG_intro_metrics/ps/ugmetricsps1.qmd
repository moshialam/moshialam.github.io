---
title: "Econometrics PS 1"
author: "Prof Alam"
format: html
editor: visual
theme: flatly
toc: true
code-fold: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 6)
library(wooldridge)
library(ggplot2)
library(knitr)
```

**Follow the instructions of completing your problem set detailed in the syllabus**

# Question 1

Observe the following population regression models of $y_1$ on $x$ and $y_2$ on $x$ where $y_1 = 2 + 3x + u_1$ and $y_2 = 2 + 3x + u_2$. Observe how the error terms $u_1$ and $u_2$ are generated for 10000 observations.

```{r}
set.seed(123)
n <- 10000
x <- sin(seq(-5, 5, length.out=n))
u1 <- rnorm(n, mean=0.0, sd=0.1)
u2 <- x + rnorm(n, mean=0, sd=0.1)

y1 <- 2 + 3*x + u1
y2 <- 2 + 3*x + u2

```

(a) Plot the error terms $u_1$ and $u_2$ against $x$. What do you observe?
(b) Before running the regressions, which OLS estimates will produce unbiased estimates? Prove your answer.
(c) Use the code above to generate the data $y_1$, $y_2$ and $x$. Then run the two regressions and explain the results.
(d) Now consider a wage equation: $wage_i= β_0+ β_1 education_i + u_i$. Suppose unobserved ability is positively correlated with education and affects wages positively. Explain intuitively why $E(u | education) \ne 0$ in this case. Will OLS overestimate or ̸ underestimate the true return to education? Justify your answer.

------------------------------------------------------------------------

# Question 2

Consider two researchers studying the same population and estimating the population model $y = \beta_0 + \beta_1 x + u$ with $Var(u) = 1$. Assume SLR.1-4 hold. The two researchers collect different samples:

-   Researcher A collects a random sample with 100 observations where it turns out that $x_i \in [45, 55]$ uniformly distributed
-   Researcher B collects a random sample with 100 observations where it turns out that $x_i \in [0, 100]$ uniformly distributed

Without doing exact calculations, explain which researcher will likely obtain a more precise estimate of $\beta_1$.

------------------------------------------------------------------------

# Question 3

For this problem, you will use the `wage2` dataset from the `wooldridge` package. This dataset contains information on monthly earnings and various characteristics of workers.

## Q 3.1

a.  Load the data and create a scatter plot of monthly wages (`wage`) against years of education (`educ`). What do you observe about the relationship? Are there any concerning patterns?

b.  Calculate and report the sample correlation between wages and education. Then manually calculate $\hat{\beta}_1$ using the formula: $\hat{\beta}_1 = \hat{\rho}_{xy} \cdot \left(\frac{\hat{\sigma}_y}{\hat{\sigma}_x}\right)$ by computing each component separately. Show that this matches the OLS estimate from `lm()`.

c.  Estimate the simple linear regression:

$$
wage_i = \beta_0 + \beta_1 \, educ_i + u_i
$$

Report and interpret both coefficients. Is the intercept meaningful in this context?

d.  Calculate the fitted values and residuals manually (without using `fitted()` or `residuals()`). Verify that:

-   The mean of residuals equals zero\
-   The point $(\bar{educ}, \bar{wage})$ lies on the regression line\
-   The sample covariance between education and residuals is zero

## Q 3.2

a.  Estimate:

$$
\log(wage_i) = \beta_0 + \beta_1 \, educ_i + u_i
$$

b.  Using the log-level specification:

-   Calculate the exact percentage return to one additional year of education\
-   Predict the percentage wage difference between workers with 12 and 16 years of education\
    <!-- - Test whether the return to education is significantly different from 10% at the 5% level   -->

c.  Create histograms of `wage` and `log(wage)`. Which estimation would you prefer to run: level-level or log-level? Justify your choice.

## Q 3.3

a.  Create a residual plot (residuals vs. fitted values) for your log-level specification. Do you see evidence of heteroskedasticity? Explain what pattern you would look for.

b.  Group the data into three education categories: low ($educ < 12$), medium ($12 \leq educ < 16$), and high ($educ \geq 16$).

```{r}
wage2$educ_group <- cut(wage2$educ, 
                        breaks = c(-Inf, 12, 16, Inf),
                        labels = c("Low (<12)", "Medium (12-16)", "High (≥16)"),
                        right = FALSE)
```

Calculate the variance of residuals within each group. What do these variances suggest about the homoskedasticity assumption?

c.  If heteroskedasticity is present, what are the consequences for the unbiasedness of $\hat{\beta}_1$?

<!-- --- -->

<!-- ## (10 points) -->

<!-- a. (5 points) Now include experience (`exper`) in your analysis. First, examine the correlation between education and experience. What does this suggest about potential omitted variable bias in your simple regression? -->

<!-- b. (5 points) Consider the thought experiment: If you could randomly assign education levels to workers (holding everything else constant), would you expect to get the same estimate of $\beta_1$ as in your simple regression? Explain your reasoning, relating it to the zero conditional mean assumption. -->